# 数据仓库的介绍

## 一、数据仓库的基本概念

数据仓库，英文名称为Data Warehouse，可简写为DW或DWH。数据仓库顾名思义，是一个很大的[数据存储](https://cloud.tencent.com/product/cdcs?from=10680)集合，出于企业的分析性报告和决策支持目的而创建，对多样的业务数据进行筛选与整合。它为企业提供一定的[BI](https://cloud.tencent.com/product/bi?from=10680)（商业智能）能力，指导业务流程改进、监视时间、成本、质量以及控制。

数据仓库的输入方是各种各样的数据源，最终的输出用于企业的数据分析、数据挖掘、数据报表等方向。

![img](https://ask.qcloudimg.com/http-save/yehe-1159019/df5ebecbe13224743e4dd0c55bde22b2.png?imageView2/2/w/1620)

## 二、数据仓库的主要特征

数据仓库是面向主题的（Subject-Oriented ）、集成的（Integrated）、稳定的（Non-Volatile）和时变的（Time-Variant ）数据集合，用以支持管理决策。

### 1.主题性

不同于传统数据库对应于某一个或多个项目，数据仓库根据使用者实际需求，将不同数据源的数据在一个较高的抽象层次上做整合，所有数据都围绕某一主题来组织。

这里的主题怎么来理解呢？比如对于城市，“天气湿度分析”就是一个主题，对于淘宝，“用户点击行为分析”就是一个主题。

### 2.集成性

数据仓库中存储的数据是来源于多个数据源的集成，原始数据来自不同的数据源，存储方式各不相同。要整合成为最终的数据集合，需要从数据源经过一系列抽取、清洗、转换的过程。

### 3.稳定性

数据仓库中保存的数据是一系列历史快照，不允许被修改。用户只能通过分析工具进行查询和分析。这里说明一点，数据仓库基本上是不许允许用户进行修改，删除操作的。大多数的场景是用来查询分析数据。

### 4.时变性

数据仓库会定期接收新的集成数据，反应出最新的数据变化。这和稳定特点并不矛盾。

## 三、数据仓库与数据库区别 

### 1、数据库

数据库是面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对记录进行查询、修改。用户较为关心操作的响应时间、数据的安全性、完整性和并发支持的用户数等问题。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理，也被称为联机事务处理 OLTP（On-Line Transaction Processing）。

### 2、数据仓库

数据仓库一般针对某些主题的历史数据进行分析，支持管理决策，又被称为联机分析处理 OLAP（On-Line Analytical Processing）。

首先要明白，数据仓库的出现，并不是要取代数据库。

### 3、两者区别

- 数据库是面向事务的设计，数据仓库是面向主题设计的。
- 数据库一般存储业务数据，数据仓库存储的一般是历史数据。
- 数据库设计是尽量避免冗余，一般针对某一业务应用进行设计，比如一张简单的User表，记录用户名、密码等简单数据即可，符合业务应用，但是不符合分析。数据仓库在设计是有意引入冗余，依照分析需求，分析维度、分析指标进行设计。
- 数据库是为捕获数据而设计，数据仓库是为分析数据而设计。

以银行业务为例。数据库是事务系统的数据平台，客户在银行做的每笔交易都会写入数据库，被记录下来，这里，可以简单地理解为用数据库记账。

数据仓库是分析系统的数据平台，它从事务系统获取数据，并做汇总、加工，为决策者提供决策的依据。比如，某银行某分行一个月发生多少交易，该分行当前存款余额是多少。如果存款又多，消费交易又多，那么该地区就有必要设立ATM了。

显然，银行的交易量是巨大的，通常以百万甚至千万次来计算。事务系统是实时的，这就要求时效性，客户存一笔钱需要几十秒是无法忍受的，这就要求数据库只能存储很短一段时间的数据。而分析系统是事后的，它要提供关注时间段内所有的有效数据。这些数据是海量的，汇总计算起来也要慢一些，但是，只要能够提供有效的分析数据就达到目的了。

数据仓库，是在数据库已经大量存在的情况下，为了进一步挖掘数据资源、为了决策需要而产生的，它决不是所谓的“大型数据库”。

### 4、数据仓库分层架构

按照数据流入流出的过程，数据仓库架构可分为三层——源数据、数据仓库、数据应用。

![img](https://ask.qcloudimg.com/http-save/yehe-1159019/57958d7469f8c01955b4e6395d00ad3a.png?imageView2/2/w/1620)

数据仓库的数据来源于不同的源数据，并提供多样的数据应用，数据自下而上流入数据仓库后向上层开放应用，而数据仓库只是中间集成化数据管理的一个平台。

- 源数据层（ODS）: 操作性数据(Operational Data Store) ，是作为数据库到数据仓库的一种过渡，ODS的数据结构一般与数据来源保持一致，而且ODS的数据周期一般比较短。ODS的数据为后一步的数据处理做准备。
- 数据仓库层（DW）：数据仓库(Data Warehouse)，是数据的归宿，这里保持这所有的从ODS到来的数据，并长期报错，而且这些数据不会被修改,DW层的数据应该是一致的、准确的、干净的数据，即对源系统数据进行了清洗（去除了杂质）后的数据。
- 数据应用层（DA）：数据应用(Data Application),为了特定的应用目的或应用范围，而从数据仓库中独立出来的一部分数据，也可称为部门数据或主题数据，该数据面向应用。如根据报表、专题分析需求而计算生成的数据。

### 5、数据仓库之ETL

ETL，是英文Extract-Transform-Load的缩写，用来描述将数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目的端的过程。ETL是将业务系统的数据经过抽取、清洗、转换之后加载到数据仓库的过程，目的是将企业中分散、零乱、标准不统一的数据整合到一起。

ETL是数据仓库的流水线，也可以认为是数据仓库的血液，它维系着数据仓库中数据的新陈代谢，而数据仓库日常的管理和维护工作的大部分精力就是保持ETL的正常和稳定。

![img](https://ask.qcloudimg.com/http-save/yehe-1159019/5a5545a084119a45307fdefc22b6fe28.png?imageView2/2/w/1620)

## 四、为什么要数据仓库进行分层

在探讨数据仓库应该如何分层前 , 需要先思考另一个问题 : 数据仓库为什么要分层 ?

数据分层的根本原因 , 用互联网黑话说 , 其底层逻辑 , 就两个字 : 解耦 . 数据解耦的逻辑就是数据分层的逻辑 . 在解耦的底层逻辑上 , 可以大致归纳为以下3点原因 :

1. 把复杂的问题简单化

    数据建设的根本原因是解决业务问题 , 而数据分层则是把复杂问题的解决步骤拆分 , 每层解决一部分

2. 结构更清晰

    分层的好处也表现为数据的结构层次更为清晰 , 每一层做什么事情一目了然 , 数据管理也很方便

3. 数据重复使用


## 五、数据仓库元数据的管理

元数据（Meta Date），主要记录数据仓库中模型的定义、各层级间的映射关系、监控数据仓库的数据状态及ETL的任务运行状态。一般会通过元数据资料库（Metadata Repository）来统一地存储和管理元数据，其主要目的是使数据仓库的设计、部署、操作和管理能达成协同和一致。

元数据是数据仓库管理系统的重要组成部分，元数据管理是企业级数据仓库中的关键组件，贯穿数据仓库构建的整个过程，直接影响着数据仓库的构建、使用和维护。

```go
构建数据仓库的主要步骤之一是ETL。这时元数据将发挥重要的作用，它定义了源数据系统到数据仓库的映射、数据转换的规则、数据仓库的逻辑结构、数据更新的规则、数据导入历史记录以及装载周期等相关内容。数据抽取和转换的专家以及数据仓库管理员正是通过元数据高效地构建数据仓库。

用户在使用数据仓库时，通过元数据访问数据，明确数据项的含义以及定制报表。

数据仓库的规模及其复杂性离不开正确的元数据管理，包括增加或移除外部数据源，改变数据清洗方法，控制出错的查询以及安排备份等。
```

元数据可分为技术元数据和业务元数据。技术元数据为开发和管理数据仓库的IT 人员使用，它描述了与数据仓库开发、管理和维护相关的数据，包括数据源信息、数据转换描述、数据仓库模型、数据清洗与更新规则、数据映射和访问权限等。而业务元数据为管理层和业务分析人员服务，从业务角度描述数据，包括商务术语、数据仓库中有什么数据、数据的位置和数据的可用性等，帮助业务人员更好地理解数据仓库中哪些数据是可用的以及如何使用。

由上可见，元数据不仅定义了数据仓库中数据的模式、来源、抽取和转换规则等，而且是整个数据仓库系统运行的基础，元数据把数据仓库系统中各个松散的组件联系起来，组成了一个有机的整体。

# 实时数仓和离线数仓的区别

## 一、实时与离线的区别

在数据处理时，如果数据是有界的，便是离线处理；如果数据是无界的，便是实时处理。

基本释义：

大多数人对离线处理和实时处理的区分，是用很感官的“快”、“慢”来完成。实际上，数据量小的情况下，离线处理也可以很快；数据量大的情况下，实时处理也可能很慢。

对于离线和实时处理的定义，严格来说，在数据处理时，如果数据是有界的，便是离线处理；如果数据是无界的，便是实时处理。

如果数据集在被程序处理时，总大小是固定的，那它就是有界数据。数据被处理完成后，计算任务就可以释放掉了。所以批处理方式是更加适合的。

如果数据集在被程序处理时，数量和大小是无法确定的（数据在源源不断产生），那它就是无界数据。此时计算任务需要持续运行，等待实时产生的数据从而完成处理，所以流处理方式是更加适合的。



## 二、处理技术有何差异

### 1. 离线数据处理

离线数据处理也称之为“批处理”，数据产生之后，不会立即进行清洗，而是在固定的周期进行ETL，例如每天在凌晨12：00之后，处理前一天产生的数据。上大学的时候，有的舍友喜欢将袜子攒起来，一个星期洗一次，这就是批处理的思想。

离线数据处理技术是大数据发展更早，目前已经非常成熟的一套体系，最常见是Hadoop，它是一个能够对大量数据进行分布式处理的软件框架。以一种可靠、高效、可伸缩的方式进行数据处理。核心组件是HDFS、MapReduce、Hive。以HDFS进行数据存储，Mapreduce计算，Hive进行数据仓库建设或者基于HiveSQL进行数据查询。



主要优点是：

能够处理的数据量巨大，从企业成立以来的历史数据，都可以存储、计算处理、分析应用。

数据更准确，对于一些交易类的业务，存在订单状态流转，例如酒店，用户早上下了订单，但是下午有突发情况行程有变，取消了。在离线数据处理时，取当天订单成功状态，就不会计算在内。但对于数据漂移，即12点前下单，12点后取消的情况，就也无法统计到了，这种情形，在数据清洗任务处理时，可以采用全量更新的方式，每日更新全部数据，取最终的订单状态。

缺点：

离线数据的缺点也很明显，就是慢。今天的数据，要隔天（明天）才能看得到。



### 2. 实时数据处理技术

实时数据处理，也称之为“流式”数据处理，数据像水流一样每时每刻源源不断地产生后，就立即被清洗处理。这就好比，穿的袜子脏了就洗，今日事今日毕，而不是都攒着。

实时数据一般是业务端即席产生（水源），通过Kafka等消息通道（水流管道）进行传输，利用Storm或flink等实时组件进行消费处理。例如，双十一统计每秒钟的订单数。

主要优点:

数据时效性强，可以做到秒级或者毫秒级时延，“所见即所得”。

缺点

需要不停地进行数据计算，即每秒钟或者每分钟进行数据清洗和计算，集群资源消耗大。离线数据处理，任务一天跑一次，一次1小时，实时数据处理每分钟跑一次，一天24小时都在跑。

数据周期短，由于是流式处理的方式，相应的组件在实时处理方面能力强，但是没办法存储太长时间的数据，如果容器只进不出，水终究会溢出。因此，一般数据计算的周期会限定在一周内居多。





# 数据仓库的建模

数据仓库的建设的最重要的核心核心之一就是数仓模型的设计和构建，这个决定了数仓的复用和性能，本文将介绍四种建模的理论：维度建模、关系建模、Data Vault建模、Anchor模型建模，文后也介绍几种常见的数仓建模工具。

## 一、数仓建模的目标

在了解数仓建模理论方法前，要先清楚我们建模的目的是什么，目标又在哪里，建模要到达什么样的效果？ 

- 访问性能：能够快速查询所需的数据，减少数据I/O。
- 数据成本：减少不必要的数据冗余，实现计算结果数据复用，降低大数据系统中的存储成本和计算成本。
- 使用效率：改善用户应用体验，提高使用数据的效率。
- 数据质量：改善数据统计口径的不一致性，减少数据计算错误的可能性，提供高质量的、一致的数据访问平台。

所以，大数据的数仓建模需要通过建模的方法更好的组织、存储数据，以便在性能、成本、效率和数据质量之间找到最佳平衡点。

## 二、关系模式范式理论介绍

关系型数据库设计时，遵照一定的规范要求，目的在于降低数据的冗余性和数据的一致性，目前业界范式有：

第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式（4NF）、第五范式（5NF）。

第一范式（1NF）：

域都是原子性的，即数据库表的每一列都是不可分割的原子数据项。例如下面这张表则不符合：“商品”字段就不是原子性的，可以分割成“4件”和“毛衣”。

```javascript
ID    商品    商家ID    用户ID
1    4件毛衣    B0001    U00001
```

第二范式（2NF）：

在1NF的基础上，实体的属性完全依赖于主关键字，不能存在仅依赖主关键字一部分的属性，也就是不存在局部依赖。例如下面这张表：主键ID为“学生ID，所修课程”，但是字段“所属系”只依赖于“学生ID”，不符合2NF。

```javascript
学生ID    所属系    系主任    所修课程    分数
S001    物理系    张三    C001           90
S001    物理系    张三    C002           100
```



第三范式（3NF）：

在2NF的基础上，任何非主属性不依赖于其它非主属性，也就是不存在传递依赖。例如下面这张表：主键为“订单ID”，但是字段“商品颜色”依赖于“商品ID”，不符合3NF。

```js
订单ID    商品ID    商品颜色    商家ID    用户
IDO00001    G0001    白色    B0001    U00001
```

## 三、建模的方法

### 1、ER实体模型（关系建模）

在信息系统中，将事务抽象为“实体”（Entity）、“属性”（Property）、“关系”（Relationship）来表示数据关联和事物描述，这种对数据的抽象建模通常被称为ER实体关系模型。

1. 实体：通常为参与到过程中的主体，客观存在的，比如商品、仓库、货位、汽车，此实体非数据库表的实体表。
2. 属性：对主体的描述、修饰即为属性，比如商品的属性有商品名称、颜色、尺寸、重量、产地等。
3. 关系：现实的物理事件是依附于实体的，比如商品入库事件，依附实体商品、货位，就会有“库存”的属性产生；用户购买商品，依附实体用户、商品，就会有“购买数量”、“金额”的属性产品。

实体之间建立关系时，存在对照关系：

- 1:1：即1对1的关系1:n：
- 即1对多的关系n:m：
- 即多对多的关系

在日常建模中，“实体”用矩形表示，“关系”用菱形，“属性”用椭圆形。ER实体关系模型也称为E-R关系图。

1.场景

 	学生选课系统，该系统主要用来管理学生和选修课程，其中包括课程选修、学生管理功能，现需要完成数据库逻辑模型设计。
2.实现步骤
①.抽象出主体 —— 学生，课程；
②.梳理主体之间的关系 —— 选修；（学生与选修课程是一个多对多的关系）
③.梳理主体的属性；
④.画出 E-R 关系图； 

![图片](https://mmbiz.qpic.cn/mmbiz_png/UrEB9rwE2dKhmQz4XEDWbOXwnURTDqSloPRSicZ4Fib1Kg7MQ7afxP2MknZVp6uF9WybSyG1uxoicrupaYgMAxtDA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

3.应用场景：

1、ER模型是数据库设计的理论基础，当前几乎所有的OLTP系统设计都采用ER模型建模的方式。
2、Bill Inom提出的数仓理论，推荐采用ER关系模型进行建模。

4.特点介绍：
要采用此方法进行构建，也有其挑战：

- 需要全面了解企业业务和数据
- 实施周期非常长
- 对建模人员的能力要求也非常高

### 2、维度建模

维度建模源自数据集市，主要面向分析场景。Ralph Kimball推崇数据集市的集合为数据仓库，同时也提出了对数据集市的维度建模，将数据仓库中的表划分为事实表、维度表两种类型。 

事实表：

在ER模型中抽象出了有实体、关系、属性三种类别，在现实世界中，每一个操作型事件，基本都是发生在实体之间的，伴随着这种操作事件的发生，会产生可度量的值，而这个过程就产生了一个事实表，存储了每一个可度量的事件。  事实表包含了与各维度表相关联的外键，并通过JOIN方式与维度表关联。事实表的度量通常是数值类型，且记录数会不断增加，表规模迅速增长。

维度表：

维度，顾名思义，看待事物的角度。比如从颜色、尺寸的角度来比较手机的外观，从cpu、内存等角度比较手机性能。

维度表一般为单一主键，在ER模型中，实体为客观存在的事务，会带有自己的描述性属性，属性一般为文本性、描述性的，这些描述被称为维度。

比如商品，单一主键：商品ID，属性包括产地、颜色、材质、尺寸、单价等，但并非属性一定是文本，比如单价、尺寸，均为数值型描述性的，日常主要的维度抽象包括：时间维度表、地理区域维度表等。

维度建模通常又分为星型模型和雪花模型等。

星型模型：


![图片](https://mmbiz.qpic.cn/mmbiz_png/UrEB9rwE2dKhmQz4XEDWbOXwnURTDqSlvibfw0B1icObs3I2BAr1Bn67Cxv3n9Erpk6LGbhHWDXdUQ4iciczAjHWGg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



图中的订单表就是一个事实表，你可以理解他就是在现实中发生的一次操作型事件，我们每完成一个订单，就会在订单中增加一条记录。我们可以回过头再看一下事实表的特征，在维度表里没有存放实际的内容，他是一堆主键的集合，这些ID分别能对应到维度表中的一条记录。

首先，我们想一下，如果我们不这样设计的话，我们一般会怎么做？如果设计下面这张表。你信不信，我能列出来50个字段！

可以看出，星形模式的维度建模由一个事实表和一组维表成，且具有以下特点：

1. 维表只和事实表关联，维表之间没有关联；
2. 每个维表的主码为单列，且该主码放置在事实表中，作为两边连接的外码；
3. 以事实表为核心，维表围绕核心呈星形分布



星型模型由一个事实表和一组维表组成。每个维表都有一个维作为主键，所有这些维的主键组合成事实表的主键。强调的是对维度进行预处理，将多个维度集合到一个事实表，形成一个宽表。这也是我们在使用hive时，经常会看到一些大宽表的原因，大宽表一般都是事实表，包含了维度关联的主键和一些度量信息，而维度表则是事实表里面维度的具体信息，使用时候一般通过join来组合数据，相对来说对OLAP的分析比较方便。 

先说我们的维度模型（一个事实表去关联多个维度表）：

1. 数据冗余小（因为很多具体的信息都存在相应的维度表中了，比如用户信息就只有一份）

2. 结构清晰（表结构一目了然）

3. 便于做OLAP分析（数据分析用起来会很开心）

4. 增加使用成本，比如查询时要关联多张表

5. 数据不一致，比如用户发起购买行为的时候的数据，和我们维度表里面存放的数据不一致


再说我们这张大宽表的优缺点：

1. 业务直观，在做业务的时候，这种表特别方便，直接能对到业务中。
2. 使用方便，写sql的时候很方便。
3. 数据冗余巨大，真的很大，在几亿的用户规模下，他的订单行为会很恐怖
4. 粒度僵硬，什么都写死了，这张表的可复用性太低



雪花模型：

![图片](https://mmbiz.qpic.cn/mmbiz_png/UrEB9rwE2dKhmQz4XEDWbOXwnURTDqSlibJYcmSlMeC9kRzReBhCG61SQNkXfBicFicUmvFZOxfl8AxGr6wZicSctg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/UrEB9rwE2dKhmQz4XEDWbOXwnURTDqSlHHbBYjBk3ybQA9sJ9hJFX2EhzGRibe4ws17rq4h2gkqZ6AgQ9ic8xTicA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)





​    雪花模式(Snowflake Schema)是对星形模式的扩展，每个维表可继续向外连接多个子维表。下图为使用雪花模式进行维度建模的关系结构：这是一个以客户创建为事实表的售前流程的雪花模型。

事实表：客户创建信息表

维度表：销售信息表、店铺信息表、跟进表/约见表/风控通过表/订单表的维度上卷。

以上面的维度模型可以聚合出创建、跟进、风控等各个维度的上层展现的数据

![图片](https://mmbiz.qpic.cn/mmbiz_png/UrEB9rwE2dKhmQz4XEDWbOXwnURTDqSlQnPqPCMc1PA720voTGglRWXruhtz6yjXJPW8oafADKfObGXiaxoByCw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



雪花、星型模型对比：

星型模型和雪花模型的主要区别在于对维度表的拆分，对于雪花模型，维度表的设计更加规范，一般符合3NF；而星型模型，一般采用降维的操作，利用冗余来避免模型过于复杂，提高易用性和分析效率。

1. 冗余：雪花模型符合业务逻辑设计，采用3NF设计，有效降低数据冗余；星型模型的维度表设计不符合3NF，反规范化，维度表之间不会直接相关，牺牲部分存储空间。
2. 性能：雪花模型由于存在维度间的关联，采用3NF降低冗余，通常在使用过程中，需要连接更多的维度表，导致性能偏低；星型模型反三范式，采用降维的操作将维度整合，以存储空间为代价有效降低维度表连接数，性能较雪花模型高。
3. ETL：雪花模型符合业务ER模型设计原则，在ETL过程中相对简单，但是由于附属模型的限制，ETL任务并行化较低；星型模型在设计维度表时反范式设计，所以在ETL过程中整合业务数据到维度表有一定难度，但由于避免附属维度，可并行化处理。
4. 维度建模是面向分析场景而生，针对分析场景构建数仓模型；重点关注快速、灵活的解决分析需求，同时能够提供大规模数据的快速响应性能。针对性强，主要应用于数据仓库构建和 OLAP 引擎低层数据模型。

维度建模的特点如下：

- 不需要完整的梳理企业业务流程和数据；
- 实施周期根据主题边界而定，容易快速实现 demo 。  

维度建模的缺点

- 维度建模之前需要进行大量的数据预处理，因此会导致大量的数据处理工作（ETL）。

- 当业务发生变化，需要重新进行维度的定义时，往往需要重新进行维度数据的预处理。而在这些与处理过程中，往往会导致大量的数据冗余。

- 如果只是依靠单纯的维度建模，不能保证数据来源的一致性和准确性，而且在数据仓库的底层，不是特别适用于维度建模的方法。


  ![图片](https://mmbiz.qpic.cn/mmbiz_png/UrEB9rwE2dKhmQz4XEDWbOXwnURTDqSl3mvoftbvgPFBpDeicCw8lkZiaUw6j8nGJhsFh9icFVWgtKDJnkEJxqJuQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

大数据和传统关系型数据库的计算框架不一样，例如对比Hive和oracle， Hive 的分析通过 MapReduce 实现，在mapreduce里面，每多一个表的关联，就多一个job。对于雪花模型，由于存在着很多维度表之间的关联，这就会导致一次分析对应多个 MapReduce 任务，而星型模型由于不存在维度表的关联，因此一个 MapReduce 就可以实现分析任务。

MapReduce 本身是一个支持高吞吐量的任务，mapreduce的每个任务进来，要申请资源，分配容器，各节点通信等。由于相互关联的维度表本身会很小，join 操作用时很少，有可能YARN调度时长大于任务运行时间（例如调度需要5秒才能申请到资源，而表之间的join只需要2秒）。因此hive优化里面，要尽可能减少job任务数，也就是减少表之间的关联，可以用适当的冗余来避免低效的查询方式，这是和oracle等其他关系型数据库不同的地方。还有一点，雪花模型中拆分出的维度表，每个表对应至少一个文件，这就涉及到 I/O 方面的性能损耗。 

在实际项目中，不会刻意地去考虑雪花模型，而是刻意地去考虑星型模型，特别是大数据领域的建模，倾斜于使用数据冗余来提高查询效率，倾向于星型模型；雪花模型只会应用在一些我们要求模型的灵活性，要求保证模型本身稳定性的场景下，但是雪花模型并不是首选



### 3、Data Vault模型

Data Vault是在ER模型的基础上衍生而来，模型设计的初衷是有效的组织基础数据层，使之易扩展，灵活应对业务变化，同时强调历史性、可追溯性和原子性，不要求对数据进行过度的一致性处理，并非针对分析场景所设计。

Data Vault模型是一种中心辐射式模型，其设计重点围绕着业务键的集成模式。这些业务键是存储在多个系统中的、针对各种信息的键，用于定位和唯一标识记录或数据。

Data Vault模型包含三种基本结构：

1. 中心表-Hub：唯一业务键的列表，唯一标识企业实际业务，企业的业务主体集合。
2. 链接表-Link：表示中心表之间的关系，通过链接表串联整个企业的业务关联关系。
3. 卫星表-Satellite：历史的描述性数据，数据仓库中数据的真正载体。



Data Vault是对ER模型更进一步的规范化，由于对数据的拆解更偏向于基础数据组织，在处理分析类场景时相对复杂，适合数仓底层构建，目前实际应用场景较少。

### 4、Anchor

Anchor是对Data Vault模型做了更进一步的规范化处理，初衷是为了设计高度可扩展的模型，核心思想是所有的扩张只添加而不修改，于是设计出的模型基本变成了K-V结构的模型，模型范式达到了6NF。

由于过度规范化，使用中牵涉到太多的join操作，目前没有实际案例，仅作了解。

### 5.基本建模方法对比

当前主流建模方法为：ER模型、维度建模。

1）ER模型

ER模型常用于OLTP数据库建模，应用到构建数仓时更偏重数据整合，站在企业整体考虑，将各个系统的数据按相似性一致性进行合并处理，为数据分析、决策服务，但并不便于直接用来支持分析。

问题（特点）：
a）需要全面梳理企业所有的业务和数据流；
b）实施周期长；
c）对建模人员要求高。

2）维度模型

维度建模是面向分析场景而生，针对分析场景构建数仓模型，重点关注快速、灵活的解决分析需求，同时能够提供大规模数据的快速响应性能。针对性强，主要应用于数据仓库构建和OLAP引擎底层数据模型。当前很多公司更多的是采用维度建模的方式来进行，以应对快速迭代的业务需求。

模型选择和设计的原则：

1. 数仓模型的选择是灵活的，不局限于某一种模型方法；
2. 数仓模型的设计也是灵活的，以实际需求场景为导向；
3. 模型设计要兼顾灵活性，可扩展，而对终端用户透明性；
4. 模型设计要考虑技术可靠性和实现成本。

## 四、数据库及数据仓库模型设计的三个主要步骤

概念模型设计 , 逻辑模型设计 , 物理模型设计 是数据库及数据仓库模型设计的三个主要步骤

### 1. 概念模型

概念模型就是在了解了用户的需求 , 用户的业务领域工作情况以后 , 经过分析和总结 , 提炼出来的用以描述用户业务需求的一些概念的东西 ; 如销售业务中的 客户 和 定单 , 还有就是 商品 , 业务员 , 用 USE CASE 来描述就是 : 业务员 与 客户 就购买 商品 之事签定下 定单 , 概念模型使用 E-R 图表示 , E-R 图主要是由实体 , 属性和联系三个要素构成的 , 该阶段需完成 :

1. 该系统的商业目的是什么 , 要解决何种业务场景

2. 该业务场景中 , 有哪些人或组织参与 , 角色分别是什么

3. 该业务场景中 , 有哪些物件参与 , 

4. 此外需要具备相关行业经验 , 如核心业务流程 , 组织架构 , 行业术语

5. 5w1h：who ,  what , when , where , why,  how


### 2. 逻辑模型

逻辑模型是将概念模型转化为具体的数据模型的过程 , 即按照概念结构设计阶段建立的基本 E-R 图 , 按选定的管理系统软件支持的数据模型 (层次/网状/关系/面向对象) , 转换成相应的逻辑模型 , 这种转换要符合关系数据模型的原则 ;
还以销售业务为例 : 客户 信息基本上要包括 : 单位名称 , 联系人 , 联系电话 , 地址等属性

商品 信息基本上要包括 : 名称 , 类型 , 规格 , 单价等属性
定单 信息基本上要包括 : 日期和时间属性 ; 并且 定单 要与 客户 , 业务员 和商品 明细关联 , 该阶段需完成 :

1. 分多少个主题 , 每个主题包含的实体

2. 每个实体的属性都有什么

3. 各个实体之间的关系是什么

4. 各个实体间是否有关系约束


### 3. 物理模型

物理模型就是针对上述逻辑模型所说的内容 , 在具体的物理介质上实现出来 , 系统需要建立几个数据表 : 业务员信息表 , 客户信息表 , 商品信息表 , 定单表 ; 系统要包括几个功能 : 业务员信息维护 , 客户信息维护 , 商品信息维护 , 建立销售定单 ; 表 , 视图 , 字段 , 数据类型 , 长度 , 主键 , 外键 , 索引 , 约束 , 是否可为空 , 默认值 , 该阶段需完成 :

1. 类型与长度的定义

2. 字段的其他详细定义 , 非空 , 默认值

3. 却准详细的定义 , 枚举类型字段 , 各枚举值具体含义

4. 约束的定义 , 主键 , 外键


这三个过程 , 就是实现一个数据库设计的三个关键的步骤 , 是一个从抽象到具体的一个不断细化完善的分析 , 设计和开发的过程 ;



## 五、企业建模的三点经验



维度建模就不说了，只要能理解业务过程和其中涉及的相关数据、维度就可以，但自顶向下的关系建模难度很大，以下是关系建模的三个建设要点。

### 1、业务的理解

找到企业内最理解业务和源系统的人，梳理出现状，比如运营商就要深刻理解三域（O/B/M），概念建模的挑战就很大，现在做到B域的概念建模已经很不容易。

![图片](https://mmbiz.qpic.cn/mmbiz_png/hFm2L5m7fBsJsWzxCnPS9nJD8npPXB2ZUdwvKU8u1aSBQEdbpyIfBXac9l4RCFn7PAicq2tOdRibYEVbVH4ibJkEw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

### 2、数据及关系的理解

各个域的系统建设的时候没有统一文档和规范，要梳理出逻辑模型不容易，比如运营商的事件主题下的逻辑模型就非常复杂。

![图片](https://mmbiz.qpic.cn/mmbiz_png/hFm2L5m7fBsJsWzxCnPS9nJD8npPXB2ZMNQbbonMt3Aiaj5lnrk6vDYLIsVkZAb2GKpta3SIfMrmUeSpjsfl2Uw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

### 3、标准化的推进

数据仓库建模的任何实体都需要标准化命名，否则未来的管理成本巨大，也是后续数据有效治理的基础，以下是我们的一个命名规范示例：

![图片](https://mmbiz.qpic.cn/mmbiz_png/hFm2L5m7fBsJsWzxCnPS9nJD8npPXB2Z5slZY9Lceia1ZyarGVmnhnn5Khp7tmWfQ5vTNvn4GkMcjtsbySk5vKA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)





# 数据仓库元数据管理

> 简介： 相信很多朋友都是第一次听说元数据管理系统这个名词，当然，从事非数据仓库工作的人，很少会接触到这个系统，即使是正在从事这方面工作的朋友，可能仍然对它不是很了解，那么今天我来聊一聊元数据管理系统。本文大部分观点与图片汇总字网络，如有不同观点，欢迎留言交流～～ 

## 一、元数据的定义

按照传统的定义，元数据（Metadata）是关于数据的数据。在数据仓库系统中，元数据可以帮助数据仓库管理员和数据仓库的开发人员非常方便地找到他们所关心的数据；元数据是描述数据仓库内数据的结构和建立方法的数据，可将其按用途的不同分为两类：[技术元数据（Technical Metadata）和业务元数据（Business Metadata)]

技术元数据是存储关于数据仓库系统技术细节的数据，是用于开发和管理数据仓库使用的数据，它主要包括以下信息：

- 数据仓库结构的描述，包括仓库模式、视图、维、层次结构和导出数据的定义，以及数据集市的位置和内容；
- 业务系统、数据仓库和数据集市的体系结构和模式
- 汇总用的算法，包括度量和维定义算法，数据粒度、主题领域、聚集、汇总、预定义的查询与报告；
- 由操作环境到数据仓库环境的映射，包括源数据和它们的内容、数据分割、数据提取、清理、转换规则和数据刷新规则、安全（用户授权和存取控制）。

业务元数据从业务角度描述了数据仓库中的数据，它提供了介于使用者和实际系统之间的语义层，使得不懂计算机技术的业务人员也能够“读懂”数据仓库中的数据。业务元数据主要包括以下信息：使用者的业务术语所表达的数据模型、对象名和属性名；访问数据的原则和数据的来源；系统所提供的分析方法以及公式和报表的信息；具体包括以下信息：

- 企业概念模型：这是业务元数据所应提供的重要的信息，它表示企业数据模型的高层信息、整个企业的业务概念和相互关系。以这个企业模型为基础，不懂数据库技术和SQL语句的业务人员对数据仓库中的数据也能做到心中有数。
- 多维数据模型：这是企业概念模型的重要组成部分，它告诉业务分析人员在数据集市当中有哪些维、维的类别、数据立方体以及数据集市中的聚合规则。这里的数据立方体表示某主题领域业务事实表和维表的多维组织形式。
- 业务概念模型和物理数据之间的依赖：以上提到的业务元数据只是表示出了数据的业务视图，这些业务视图与实际的数据仓库或数据库、多维数据库中的表、字段、维、层次等之间的对应关系也应该在元数据知识库中有所体现。

## 二、元数据的作用

与其说数据仓库是软件开发项目，还不如说是系统集成项目，因为它的主要工作是把所需的数据仓库工具集成在一起，完成数据的抽取、转换和加载，OLAP分析和数据挖掘等。如下图所示，它的典型结构由操作环境层、数据仓库层和业务层等组成。

其中，第一层（操作环境层）是指整个企业内有关业务的OLTP系统和一些外部数据源；第二层是通过把第一层的相关数据抽取到一个中心区而组成的数据仓库层；第三层是为了完成对业务数据的分析而由各种工具组成的业务层。图中左边的部分是元数据管理，它起到了承上启下的作用，具体体现在以下几个方面：

### 1.元数据是进行数据集成所必需的

数据仓库最大的特点就是它的集成性。这一特点不仅体现在它所包含的数据上，还体现在实施数据仓库项目的过程当中。一方面，从各个数据源中抽取的数据要按照一定的模式存入数据仓库中，这些数据源与数据仓库中数据的对应关系及转换规则都要存储在元数据知识库中；另一方面，在数据仓库项目实施过程中，直接建立数据仓库往往费时、费力，因此在实践当中，人们可能会按照统一的数据模型，首先建设数据集市，然后在各个数据集市的基础上再建设数据仓库。不过，当数据集市数量增多时很容易形成“蜘蛛网”现象，而元数据管理是解决“蜘蛛网”的关键。如果在建立数据集市的过程中，注意了元数据管理，在集成到数据仓库中时就会比较顺利；相反，如果在建设数据集市的过程中忽视了元数据管理，那么最后的集成过程就会很困难，甚至不可能实现。

### 2.元数据定义的语义层可以帮助用户理解数据仓库中的数据

最终用户不可能象数据仓库系统管理员或开发人员那样熟悉数据库技术，因此迫切需要有一个“翻译”，能够使他们清晰地理解数据仓库中数据的含意。元数据可以实现业务模型与数据模型之间的映射，因而可以把数据以用户需要的方式“翻译”出来，从而帮助最终用户理解和使用数据。

### 3.元数据是保证数据质量的关键

数据仓库或数据集市建立好以后，使用者在使用的时候，常常会产生对数据的怀疑。这些怀疑往往是由于底层的数据对于用户来说是不“透明”的，使用者很自然地对结果产生怀疑。而借助元数据管理系统，最终的使用者对各个数据的来龙去脉以及数据抽取和转换的规则都会很方便地得到，这样他们自然会对数据具有信心；当然也可便捷地发现数据所存在的质量问题。甚至国外有学者还在元数据模型的基础上引入质量维，从更高的角度上来解决这一问题。

### 4.元数据可以支持需求变化

随着信息技术的发展和企业职能的变化，企业的需求也在不断地改变。如何构造一个随着需求改变而平滑变化的软件系统，是软件工程领域中的一个重要问题。传统的信息系统往往是通过文档来适应需求变化，但是仅仅依靠文档还是远远不够的。成功的元数据管理系统可以把整个业务的工作流、数据流和信息流有效地管理起来，使得系统不依赖特定的开发人员，从而提高系统的可扩展性 

## 三、元数据管理现状

 

由以上几节我们了解到元数据几乎可以被称为是数据仓库乃至商业智能（BI）系统的“灵魂”，正是由于元数据在整个数据仓库生命周期中有着重要的地位，各个厂商的数据仓库解决方案都提到了关于对元数据的管理。但遗憾的是对于元数据的管理，各个解决方案都没有明确提出一个完整的管理模式；它们提供的仅仅是对特定的局部元数据的管理。与元数据相关的数据仓库工具大致可分为四类：

### 1. 数据抽取工具：

把业务系统中的数据抽取、转换、集成到数据仓库中，如Ardent的DataStage、Pentaho的开源ETL产品Kettle、ETI的Extract等。这些工具仅提供了技术元数据，几乎没有提供对业务元数据的支持。

### 2. 前端展现工具：

包括OLAP分析、报表和商业智能工具等，如Cognos的PowerPlay、Business Objects的BO，以及国内厂商帆软的FineBI／FineReport等。它们通过把关系表映射成与业务相关的事实和维来支持多维业务视图，进而对数据仓库中的数据进行多维分析。这些工具都提供了业务元数据与技术元数据相对应的语义层。

### 3. 建模工具：

为非技术人员准备的业务建模工具，这些工具可以提供更高层的与特定业务相关的语义。如CA的ERwin、Sysbase的PowerDesigner以及Rational的Rose等。

### 4. 元数据存储工具：

元数据通常存储在专用的数据库中，该数据库就如同一个“黑盒子”，外部无法知道这些工具所用到和产生的元数据是如何存储的。还有一类被称为元数据知识库（Metadata Repository）的工具，它们独立于其它工具，为元数据提供一个集中的存储空间。这些工具包括微软的Repository，Ardent的MetaStage和Sybase的WCC等。

### 5.元数据管理工具：

目前国内的元数据管理工具大概有三类。一是像IBM、CA等公司都提供的专门工具，比如IBM收购Ascential得到的MetaStage，CA的DecisionBase都是如此；二是像DAG的MetaCenter，开源产品Pentaho Metadata，它们不依托于某项BI产品，是一种第三方的元数据管理工具；三是像普元、石竹这样的集成商也有自己的元数据管理工具：普元MetaCube、新炬网络元数据管理系统、石竹MetaOne等。

专门的元数据管理工具，对自家产品兼容较好，一旦涉及跨系统管理，就不尽如人意了。从国内的实际应用来看，DAG的MetaCenter这一工具使用最多，目前所看到的在电信、金融领域建设的元数据管理项目基本上都是应用了这一产品。
我从互联网上搜索了几乎所有的元数据厂家：Pentaho开源的MetaData产品，支持源码下载试用，可以进行集成开发；普元MetaCube下载后，配置麻烦，目前为止还没有调通；其他公司产品均不提供下载试用。 

## 四、元数据管理标准

 

没有规矩不成方圆。元数据管理之所以困难，一个很重要的原因就是缺乏统一的标准。在这种情况下，各公司的元数据管理解决方案各不相同。近几年，随着元数据联盟MDC（Meta Data Coalition）的开放信息模型OIM（Open Information Model）和OMG组织的公共仓库模型CWM（Common Warehouse Model）标准的逐渐完善，以及MDC和OMG组织的合并，为数据仓库厂商提供了统一的标准，从而为元数据管理铺平了道路。

从元数据的发展历史不难看出，元数据管理主要有两种方法：

- 对于相对简单的环境，按照通用的元数据管理标准建立一个集中式的元数据知识库。
- 对于比较复杂的环境，分别建立各部分的元数据管理系统，形成分布式元数据知识库，然后，通过建立标准的元数据交换格式，实现元数据的集成管理。

目前OMG家的CWM（Common Warehouse MetaModel）标准已成为元数据管理界的统一标准：
OMG是一个拥有500多会员的国际标准化组织，著名的CORBA标准即出自该组织。公共仓库元模型（Common Warehouse Metamodel）的主要目的是在异构环境下，帮助不同的数据仓库工具、平台和元数据知识库进行元数据交换。2001年3月，OMG颁布了CWM 1.0标准。CWM模型既包括元数据存储，也包括元数据交换，它是基于以下三个工业标准制定的：

- UML：它对CWM模型进行建模。
- MOF（元对象设施）：它是OMG元模型和元数据的存储标准，提供在异构环境下对元数据知识库的访问接口。
- XMI（XML元数据交换）：它可以使元数据以XML文件流的方式进行交换。

OMG元数据知识库体系结构如下图所示。
CWM为数据仓库和商业智能（BI）工具之间共享元数据，制定了一整套关于语法和语义的规范。它主要包含以下四个方面的规范：

- CWM元模型（Metamodel）：描述数据仓库系统的模型；
- CWM XML：CWM元模型的XML表示；
- CWM DTD：DW/BI共享元数据的交换格式
- CWM IDL：DW/BI共享元数据的应用程序访问接口（API）

 

## 五、元数据管理功能

#### [1. 数据地图](http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ==&mid=2649373441&idx=1&sn=2f29fca1934b8b997f2c9daabaf3876b&chksm=f3900f3dc4e7862b5bfe34d1ab07edfdcf304094f6c1dca7ea9c6671bc0a6dc36c4f0368c851&scene=21#wechat_redirect)

数据地图展现是以拓扑图的形式对数据系统的各类数据实体、数据处理过程元数据进行分层次的图形化展现，并通过不同层次的图形展现粒度控制，满足开发、运维或者业务上不同应用场景的图形查询和辅助分析需要

#### [2. 元数据分析](http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ==&mid=2649372502&idx=1&sn=1a9c9abfcafab411d297b84b7a81fb9a&chksm=f390036ac4e78a7ca0b76c9a2625a794d3436ee557129c01310c28b3cf093f393832c4f25629&scene=21#wechat_redirect)

血缘分析
血缘分析（也称血统分析）是指从某一实体出发，往回追溯其处理过程，直到数据系统的数据源接口。对于不同类型的实体，其涉及的转换过程可能有不同类型，如：对于底层仓库实体，涉及的是ETL处理过程；而对于仓库汇总表，可能既涉及ETL处理过程，又涉及仓库汇总处理过程；而对于指标，则除了上面的处理过程，还涉及指标生成的处理过程。数据源接口实体由源系统提供，作为数据系统的数据输入，其它的数据实体都经过了一个或多个不同类型的处理过程。血缘分析正是提供了这样一种功能，可以让使用者根据需要了解不同的处理过程，每个处理过程具体做什么，需要什么样的输入，又产生什么样的输出。

影响分析
影响分析是指从某一实体出发，寻找依赖该实体的处理过程实体或其他实体。如果需要可以采用递归方式寻找所有的依赖过程实体或其他实体。该功能支持当某些实体发生变化或者需要修改时，评估实体影响范围。

实体关联分析
实体关联分析是从某一实体关联的其它实体和其参与的处理过程两个角度来查看具体数据的使用情况，形成一张实体和所参与处理过程的网络，从而进一步了解该实体的重要程度。本功能可以用来支撑需求变更影响评估的应用。

实体差异分析
实体差异分析是对元数据的不同实体进行检查，用图形和表格的形式展现它们之间的差异，包括名字、属性及数据血缘和对系统其他部分影响的差异等,在数据系统中存在许多类似的实体。这些实体（如数据表）可能只有名字上或者是在属性中存在微小的差异，甚至有部分属性名字都相同，但处于不同的应用中。由于各种原因，这些微小的差异直接影响了数据统计结果，数据系统需要清楚了解这些差异。本功能有助于进一步统一统计口径，评估近似实体的差异

指标一致性分析
指标一致性分析是指用图形化的方式来分析比较两个指标的数据流图是否一致，从而了解指标计算过程是否一致。该功能是指标血缘分析的一种具体应用。指标一致性分析可以帮助用户清楚地了解到将要比较的两个指标在经营分析数据流图中各阶段所涉及的数据对象和转换关系是否一致，帮助用户更好地了解指标的来龙去脉，清楚理解分布在不同部门且名称相同的指标之间的差异，从而提高用户对指标值的信任。

#### 3. 辅助应用优化

元数据对数据系统的数据、数据加工过程以及数据间的关系提供了准确的描述，利用血缘分析、影响分析和实体关联分析等元数据分析功能，可以识别与系统应用相关的技术资源，结合应用生命周期管理过程，辅助进行数据系统的应用优化.

#### 4. 辅助安全管理

企业数据平台所存储的数据和提供的各类分析应用，涉及到公司经营方面的各类敏感信息。因此在数据系统建设过程中，须采用全面的安全管理机制和措施来保障系统的数据安全。
数据系统安全管理模块负责数据系统的数据敏感度、客户隐私信息和各环节审计日志记录管理，对数据系统的数据访问和功能使用进行有效监控。为实现数据系统对敏感数据和客户隐私信息的访问控制，进一步实现权限细化，安全管理模块应以元数据为依据，由元数据管理模块提供敏感数据定义和客户隐私信息定义，辅助安全管理模块完成相关安全管控操作。

#### 5. 基于元数据的开发管理

数据系统项目开发的主要环节包括：需求分析、设计、开发、测试和上线。开发管理应用可以提供相应的功能，对以上各环节的工作流程、相关资源、规则约束、输入输出信息等提供管理和支持。

# 指标体系

指标体系是什么？如何使用OSM模型和AARRR模型搭建指标体系？如何统一流程、规范化、工具化管理指标体系？本文会对建设的方法论结合滴滴数据指标体系建设实践进行解答分析。

## 一、什么是指标体系

### 1. 指标体系定义

指标体系是将零散单点的具有相互联系的指标，系统化的组织起来，通过单点看全局，通过全局解决单点的问题。它主要由指标和体系两部分组成。

指标是指将业务单元细分后量化的度量值，它使得业务目标可描述、可度量、可拆解，它是业务和数据的结合，是统计的基础，也是量化效果的重要依据。

指标主要分为结果型和过程型：

- 结果型指标：用于衡量用户发生某个动作后所产生的结果，通常是延后知道的，很难进行干预。结果型指标更多的是监控数据异常，或者是监控某个场景下用户需求是否被满足
- 过程型指标：用户在做某个动作时候所产生的指标，可以通过某些运营策略来影响这个过程指标，从而影响最终的结果，过程型指标更加关注用户的需求为什么被满足或没被满足

体系是由不同的维度组成，而维度是指用户观察、思考与表述某事物的“思维角度”，维度是指标体系的核心，没有维度，单纯说指标是没有任何意义的。

维度主要分为定性维度和定量维度，定性维度，主要是偏文字描述类如城市、性别、职业等;定量维度，主要是数值类描述如收入、年龄等，对定量维度需要做数值分组处理。

### 2. 指标体系生命周期

生命周期主要包含定义、生产、消费、下线四个阶段。针对整个生命周期要持续做指标运维、质量保障，同时为了提高指标数据复用度，降低用户使用成本需要做对应的数据运营工作。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7gvwKGTPibk7CXtaD7tFchLuIbSfIQMeQM0jcRldmTqO87fXSSfYgskQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### 3. 综合使用场景

指标体系主要是结合用户的业务场景来进行使用，多个不同的指标和维度可以组合起来进行业务的综合分析，用户可通过指标的变化看到整体业务的变化，并能够快速发现问题、定位问题。常用的场景一种是决策分析的场景，通过数据看清业务现状进行战略决策支持；另一种是运营分析场景，无论是做用户运营、产品运营还是活动运营都需要各类指标数据的支撑去看清问题、分析问题和指导解决问题。

## 二、为什么搭建指标体系

### 1. 衡量业务发展质量

指标体系可以反映业务客观事实，看清业务发展现状，通过指标对业务质量进行衡量，把控业务发展情况，针对发现的业务问题聚焦解决，促进业务有序增长

### 2. 建立指标因果关系

主要明确结果型指标和过程型指标关系，通过结果指标回溯过程指标，找到解决问题的核心原因

### 3. 指导用户分析工作

目的建立产品评估体系、活动效果评估体系、智能运营分析体系

### 4. 指导基础数据建设

明确基础数据建设方向，集中资源，避免过程和结果分析指标数据的遗漏或缺失

### 5. 指导内容产品建设

结合用户的业务场景来进行使用，多个不同的指标和维度可以组合起来进行业务的综合分析，用户可通过指标的变化看到整体业务的变化，并能够快速发现问题、定位问题

### 6. 统一指标消费口径

企业内统一关键指标业务口径及计算口径，统一企业业务目标，实现自上而下目标驱动

## 三、如何搭建指标体系

指标体系建设的常用方法是通过场景化进行指标体系的搭建，以用户的视角场景化思考，自上而下业务驱动指标体系建设，所以要在特定场景下做好指标体系建设，需要先选好指标，然后用科学的方法搭建指标体系。

### 1. 科学方法选指标

选指标常用方法是指标分级方法和OSM模型。

指标分级主要是指标内容纵向的思考，根据企业战略目标、组织及业务过程进行自上而下的指标分级，对指标进行层层剖析，主要分为三级T1、T2、T3。

- T1指标：公司战略层面指标

用于衡量公司整体目标达成情况的指标，主要是决策类指标，T1指标使用通常服务于公司战略决策层

- T2指标：业务策略层面指标

为达成T1指标的目标，公司会对目标拆解到业务线或事业群，并有针对性做出一系列运营策略，T2指标通常反映的是策略结果属于支持性指标同时也是业务线或事业群的核心指标。T2指标是T1指标的纵向的路径拆解，便于T1指标的问题定位，T2指标使用通常服务业务线或事业群

- T3指标：业务执行层面指标

T3指标是对T2指标的拆解，用于定位T2指标的问题。T3指标通常也是业务过程中最多的指标。根据各职能部门目标的不同，其关注的指标也各有差异。T3指标的使用通常可以指导一线运营或分析人员开展工作，内容偏过程性指标，可以快速引导一线人员做出相应的动作。

例如：成交率的指标分级

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7ibppIO2j7vVsymtCRfFwnNQ6gBFeqZy9lmlFnTR55GCsYvr4CXrRo1A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

OSM模型（Obejective，Strategy，Measurement）是指标体系建设过程中辅助确定核心的重要方法，包含业务目标、业务策略、业务度量，是指标内容横向的思考。

- O

用户使用产品的目标是什么？产品满足了用户的什么需求？主要从用户视角和业务视角确定目标，原则是切实可行、易理解、可干预、正向有益

- S

为了达成上述目标我采取的策略是什么？

- M

这些策略随之带来的数据指标变化有哪些？

```javascript
以滴滴网约车为例，按照OSM模型，它的指标是什么样的？

O：用户来使用滴滴这个产品，需求和目标是什么？

用户需求及目标是便捷、快速打到车，安全到达目的地

那如何让用户感受到自己的需求被满足了呢？

S：滴滴做的策略是：

便捷方面，提供了独立APP版本、小程序版本，还可以多渠道打到车，例如在高德、微信、支付宝都有打车入口；起始、目的地地图智能精准定位；最优路线选择等

快速方面，针对不同人群不同诉求提供了多品类产品选择，例如快车、优享、拼车、出租车等业务，根据早晚高峰提高热点区域运力，减少用户排队时间

安全方面，司机准入机制，司机合规机制，司机画像

M：我们需要针对这些策略去做指标，在这里面我们的指标分别是结果指标和过程指标：

结果指标：渠道转化完成率、乘客取消率、供需比、司机服务分

过程指标：渠道发单数、渠道完单数、排队乘客数、乘客排队时长、司机好评率、司机接单量、司机取消数等

指标选取之后，下面就是最重要的分析维度选择了，前面指标体系定义里讲过维度是指标体系的核心，没有维度，单纯说指标是没有任何意义的。所以维度选择层面主要通过数据分析视角结合实际分析业务场景来确定。例如城市维度、商圈维度、渠道维度、时间维度、用户标签维度等。
```

### 2. 用分析模型搭建指标体系

在《精益数据分析》一书中给出了两套比较常用的指标体系建设方法论，其中一个就是比较有名的海盗指标法，也就是我们经常听到的AARRR海盗模型。海盗模型是用户分析的经典模型，它反映了增长是系统性地贯穿于用户生命周期各个阶段的：用户拉新(Acquisition)、用户激活(Activation)、用户留存(Retention)、商业变现(Revenue)、用户推荐(Referral)。

#### AARRR模型

- A拉新

通过各种推广渠道，以各种方式获取目标用户，并对各种营销渠道的效果评估，不断优化投入策略，降低获客成本。涉及关键指标例如新增注册用户数、激活率、注册转化率、新客留存率、下载量、安装量等

- A活跃

活跃用户指真正开始使用了产品提供的价值，我们需要掌握用户的行为数据，监控产品健康程度。这个模块主要反映用户进入产品的行为表现，是产品体验的核心所在。涉及关键指标例如DAU/MAU 、日均使用时长、启动APP时长、启动APP次数等

- R留存

衡量用户粘性和质量的指标。涉及关键指标例如留存率、流失率等

- R变现

主要用来衡量产品商业价值。涉及关键指标例如生命周期价值(LTV)、客单价、GMV等

- R推荐

衡量用户自传播程度和口碑情况。涉及关键指标例如邀请率、裂变系数等

可以根据实际业务场景，结合使用OSM和AARRR模型，来系统性的选择不同阶段所需要的核心数据指标。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7j3aib3dTOYNcXfkIDiavBL6KNyMJU9iba40JysVxhFEibiauRxl9ttTNOvQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### 3. 场景化搭建指标体系

目前阶段互联网业务比较流行的一种通用抽象场景“人、货、场”，实际就是我们日常所说的用户、产品、场景，在通俗点讲就是谁在什么场景下使用了什么产品，不同的商业模式会有不同的组合模式。以滴滴实际场景为例：哪些场景（此处场景定义为终端，如Native，微信，支付宝）的什么人（乘客）在平台上使用了哪些货（平台业务线，如快车/专车等），进而为评估用户增长的价值和效果。

- "人"的视角

从“人”的视角，我们比较关心的是什么乘客在什么时间打的车，排了多长时间，等了多长时间上车，周期内第几次打车，打车花了多少钱，是否有投诉和取消行为，具体到数据指标主要看发单用户数、完单用户数、客单价、周期内完单订单数、取消订单数、评价订单数等。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7LGIUrFruQnYia6cNYqXVo03W3UF7ibBrXaJjAy5ibn5JzwQ04j3HwHWIw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- "货"的视角

从“货”的视角，我们比较关心的就是成交了多少，交易额多少，花了多少，到具体数据指标主要会看GMV、成交率、取消率指标，在进一步会细分到城市、区域，一级品类、二级品类。数据的效果通过目标对比，横向对比、历史比较等方式进行分析确定。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7PVmXSAGeHM57soCFJibrYZVyLeslhxHVYHh1XnK5g5YibrXsRhyC0x3g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- "场"的视角

从“场”的视角，我们比较关心的就是哪个渠道用户点击量大曝光率大，带来了多少新用户，完成多少交易订单，客单价是多少；或者是哪个活动拉新或促活效果怎么样转化率多少，结合场景数据实际情况制定对应策略。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7LjsR9fFviatMNnIE5C2gkb5RIibjQ9yen3qjnVeRITFYebxTSATQQttA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

以上分别从“人”、“货”、“场”三个角度进行了数据指标和分析维度的提炼，下面我们把三类指标结合指标分级方法进行分解关联。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7Y3SPvrQiaibticiclBEwQV2KkHYaQg2466dPjyT04VWdTiaw1xUVZFx3PibQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 四、怎么管理指标体系

1. 痛点分析

主要从业务、技术、产品三个视角来看：

- 业务视角

业务分析场景指标、维度不明确；

频繁的需求变更和反复迭代，数据报表臃肿，数据参差不齐；

用户分析具体业务问题找数据、核对确认数据成本较高。

- 技术视角

指标定义，指标命名混乱，指标不唯一，指标维护口径不一致；

指标生产，重复建设；数据汇算成本较高；

指标消费，数据出口不统一，重复输出，输出口径不一致；

- 产品视角

缺乏系统产品化支持从生产到消费数据流没有系统产品层面打通；

2. 管理目标

- 技术目标

统一指标和维度管理，指标命名、计算口径、统计来源唯一， 维度定义规范、维度值一致

- 业务目标

统一数据出口、场景化覆盖

- 产品目标

指标体系管理工具产品化落地；指标体系内容产品化落地支持决策、分析、运营例如决策北极星、智能运营分析产品等

3. 模型架构

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7Dpp5DeL72iclCgUJxLhqicoc9PChFtEY41frYTMUhtXp05YkDZ37NHGQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

业务板块定义原则：业务逻辑层面进行抽象、物理组织架构层面进行细分，可根据实际业务情况进行层级分拆细化，层级分级建议进行最多进行三级分拆，一级细分可公司层面统一规范确定，二级及后续拆分可根据业务线实际业务进行拆分。

例如滴滴出行领域业务逻辑层面两轮车和四轮车都属于出行领域可抽象出行业务板块(level一级)，根据物理组织架构层面在进行细分普惠、网约车、出租车、顺风车（level二级），后续根据实际业务需求可在细分,网约车可细分独乘、合乘，普惠可细分单车、企业级。

#### 规范定义

数据域

指面向业务分析，将业务过程或者维度进行抽象的集合。其中，业务过程可以概括为一个个不拆分的行为事件，在业务过程之下，可以定义指标；维度，是度量的环境，如乘客呼单事件，呼单类型是维度。为了保障整个体系的生命力，数据域是需要抽象提炼，并且长期维护更新的，变动需执行变更流程。

业务过程

指公司的业务活动事件，如呼单、支付都是业务过程。其中，业务过程不可拆分。

时间周期

用来明确统计的时间范围或者时间点，如最近30天、自然周、截止当日等。

修饰类型

是对修饰词的一种抽象划分。修饰类型从属于某个业务域，如日志域的访问终端类型涵盖APP端、PC端等修饰词。

修饰词

指的是统计维度以外指标的业务场景限定抽象，修饰词属于一种修饰类型，如在日志域的访问终端类型下，有修饰词APP、PC端等。

度量/原子指标

原子指标和度量含义相同，基于某一业务事件行为下的度量，是业务定义中不可再拆分的指标，具有明确业务含义的名称，如支付金额。

维度

维度是度量的环境，用来反映业务的一类属性，这类属性的集合构成一个维度，也可以称为实体对象。维度属于一个数据域，如地理维度（其中包括国家、地区、省市等）、时间维度（其中包括年、季、月、周、日等级别内容）。

维度属性

维度属性隶属于一个维度，如地理维度里面的国家名称、国家ID、省份名称等都属于维度属性。

指标分类主要分为原子指标、派生指标、衍生指标

1. 原子指标

基于某一业务事件行为下的度量，是业务定义中不可再拆分的指标，具有明确业务含义的名称，如呼单量、交易金额

1. 派生指标

是1个原子指标+多个修饰词（可选）+时间周期，是原子指标业务统计范围的圈定。派生指标又分以下二种类型：

1. 事务型指标

是指对业务过程进行衡量的指标。例如，呼单量、订单支付金额，这类指标需要维护原子指标以及修饰词，在此基础上创建派生指标。

1. 存量型指标

是指对实体对象（如司机、乘客）某些状态的统计，例如注册司机总数、注册乘客总数，这类指标需要维护原子指标以及修饰词，在此基础上创建派生指标，对应的时间周期一般为“历史截止当前某个时间”。

1. 衍生指标

是在事务性指标和存量型指标的基础上复合成的。主要有比率型、比例型、统计型均值。



## 五、指标体系元数据管理

维度管理

包括基础信息和技术信息，由不同角色进行维护管理。

基础信息对应维度的业务信息，由业务管理人员、数据产品或BI分析师维护，主要包括维度名称、业务定义、业务分类。

技术信息对应维度的数据信息，由数据研发维护，主要包括是否有维表（是枚举维度还是有独立的物理维表）、是否是日期维、对应code英文名称和中文名称、对应name英文名称和中文名称。如果维度有维度物理表，则需要和对应的维度物理表绑定，设置code和name对应的字段。如果维度是枚举维，则需要填写对应的code和name。维度的统一管理，有利于以后数据表的标准化，也便于用户的查询使用。

指标管理

包括基础信息、技术信息和衍生信息，由不同角色进行维护管理。

基础信息对应指标的业务信息，由业务管理人员、数据产品或BI分析师维护，主要包括归属信息(业务板块、数据域、业务过程)，基本信息(指标名称、指标英文名称、指标定义、统计算法说明、指标类型(去重、非去重))，业务场景信息(分析维度，场景描述)；

技术信息对应指标的物理模型信息，由数据研发进行维护，主要包括对应物理表及字段信息；

衍生信息对应关联派生或衍生指标信息、关联数据应用和业务场景信息，便于用户查询指标被哪些其它指标和数据应用使用，提供指标血缘分析追查数据来源的能力。

原子指标定义归属信息 + 基本信息 + 业务场景信息派生指标定义时间周期 + 修饰词集合 + 原子指标修饰类型主要包含类型说明、统计算法说明、数据源(可选)

### 1.指标体系建设流程

建模流程

建模流程主要是从业务视角指导工程师对需求场景涉及的指标进行主题抽象，归类，统一业务术语，减少沟通成本，同时避免后续的指标重复建设。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7Uo94sJrT8Oic4DPMsQuB1fsRRAQwYmq0g9AVdic6MyyTKZGEaxYksviag/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

分析数据体系是模型架构中汇总事实表的物理集合，业务逻辑层面根据业务分析对象或场景进行指标体系抽象沉淀。滴滴出行主要是根据分析对象进行主题抽象的，例如司机主题、安全主题、体验主题、城市主题等。指标分类主要是根据实际业务过程进行抽象分类，例如司机交易类指标、司机注册类指标、司机增长类指标等。基础数据体系是模型架构中明细事实表和基础维度表的物理集合，业务逻辑层面根据实际业务场景进行抽象例如司机合规、乘客注册等，还原业务核心业务过程。

开发流程

开发流程是从技术视角指导工程师进行指标体系生产、运维及质量管控，也是数据产品或数据分析师和数仓研发沟通协调的桥梁。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7Px4BEibFWpich89QRHka46y4icdQdXkA2nmrOclFWUBuoqRsiaSicywvicyQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### 2.指标体系图谱建设

指标体系图谱概述

指标体系图谱也可称为数据分析图谱主要是依据实际业务场景抽象业务分析实体，整合梳理实体涉及的业务分类、分析指标和维度的集合。

建设方法：主要是通过业务思维、用户视角去构建，把业务和数据紧密关联起来，把指标结构化分类组织

建设目的：

- 对于用户：

便于用户能够快速定位所需指标和维度，同时通过业务场景化沉淀指标体系，能够快速触达用户数据诉求

- 对于研发：

利于后续指标生产模型设计、数据内容边界化、数据体系建设迭代量化和数据资产的落地

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7BYQwekmJia9wWaa3ibNGQttjicrpstRSviaCGXj9u9cn59hWMKTCzJA7ow/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7388WsbJKKDavDc5qJPZbzjicsQ9ibibXIWnjycXJ3OP4jHY3dnHRSGk5g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### 3.指标体系产品化

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7MSicHGXHuv8A3aSvEKfNKdyneTib2hfQTia8FlDqclqg7rIKUevdQF6PA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

指标体系涉及的产品集主要是依据其生命周期进行相应建设，通过产品工具打通数据流，实现指标体系统一化、自动化、规范化、流程化管理。因为指标体系建设本质目标是服务业务，实现数据驱动业务价值，所以建设的核心原则是“轻标准、重场景，从管控式到服务式”。通过工具、产品、技术和组织的融合提高用户使用数据效率，加速业务创新迭代。

其中和指标体系方法论强相关产品就是指标字典工具的落地，其产品的定位及价值：

- 支撑指标管理规范从方法到落地的工具，自动生成规范指标，解决指标名称混乱、指标不唯一的问题，消除数据的二义性
- 统一对外提供标准的指标口径和元数据信息

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7yFe7ARNWPymicSPMDMbTc1zAQU0icbOFzXebXVA1ubUdfEwf7xUlD3yg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

工具设计流程 (方法论->定义->生产->消费)

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7ibYoTFic6KvssjFysjAiaSzjkkt1PDwe51INcBzbLR1iakLleuN6JaN86w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

指标定义

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O2l0ALYnv0E7DDgibicicTvb7bL2fWz28Feyiat7mJMeW6xeUkET5j55gkJ5lGvtF3CIW0DWpuDdn0WA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

指标生产

这部分整体介绍了指标体系建设方法论和工具产品的建设情况，目前指标字典和开发工具已实现流程打通，与数据消费产品的打通后续会通过DataAPI方式提供数据服务，规划建设中。



# 数仓常用话术

##  一、数仓名词解释

#### 1. 实体

实体是指依附的主体，就是我们分析的一个对象，比如我们分析商品的销售情况，如华为手机近半年的销售量是多少，那华为手机就是一个实体；我们分析用户的活跃度，用户就是一个实体。当然实体也可以现实中不存在的，比如虚拟的业务对象，活动，会员等都可看做一个实体。

实体的存在是为了业务分析，作为分析的一个筛选的维度，拥有描述自己的属性，本身具有可分析的价值。

#### 2. 维度

维度就是看待问题的角度，分析业务数据，从什么角度分析，就建立什么样的维度。所以维度就是要对数据进行分析时所用的一个量，比如你要分析产品销售情况，你可以选择按商品类别来进行分析，这就构成一个维度，把所有商品类别集合在一起，就构成了维度表。

#### 3. 度量

度量是业务流程节点上的一个数值。比如销量，价格，成本等等。

事实表中的度量可分为三类：完全可加，半可加，不可加。

1. 完全可加的度量是最灵活，最有用的，比如说销量，销售额等，可进行任意维度汇总；
2. 半可加的度量可以对某些维度汇总，但不能对所有维度汇总，差额是常见的半可加度量，它除了时间维度外，可以跨所有维度进行加法操作；
3. 还有一种是完全不可加的，例如：比率。对于这类非可加度量，一种好的方法是，尽可能存储非可加度量的完全可加分量，并在计算出最终的非可加事实前，将这些分量汇总到最终的结果集中。

#### 4. 粒度

粒度就是业务流程中对度量的单位，比如商品是按件记录度量，还是按批记录度量。

在数仓建设中，我们说这是用户粒度的事实表，那么表中每行数据都是一个用户，无重复用户；例如还有销售粒度的表，那么表中每行都是一条销售记录。

选择合适的粒度级别是数据仓库建设好坏的重要关键内容，在设计数据粒度时，通常需重点考虑以下因素：

1. 要接受的分析类型、可接受的数据最低粒度和能存储的数据量；
2. 粒度的层次定义越高，就越不能在该仓库中进行更细致的分析；
3. 如果存储资源有一定的限制，就只能采用较高的数据粒度划分；
4. 数据粒度划分策略一定要保证：数据的粒度确实能够满足用户的决策分析需要，这是数据粒度划分策略中最重要的一个准则。

#### 5. 口径

口径就是取数逻辑（如何取数的），比如要取的数是10岁以下儿童中男孩的平均身高，这就是统计的口径。

#### 6. 指标

指标是口径的衡量值，也就是最后的结果。比如最近七天的订单量，一个促销活动的购买转化率等。

一个指标具体到计算实施，主要有以下几部分组成：

- 指标加工逻辑，比如count ,sum, avg
- 维度，比如按部门、地域进行指标统计，对应sql中的group by
- 业务限定/修饰词，比如以不同的支付渠道来算对应的指标，微信支付的订单退款率，支付宝支付的订单退款率 。对应sql中的where。

除此之外，指标本身还可以衍生、派生出更多的指标，基于这些特点，可以将指标进行分类：

- 原子指标：基本业务事实，没有业务限定、没有维度。比如订单表中的订单量、订单总金额都算原子指标；

> 业务方更关心的指标，是有实际业务含义，可以直接取数据的指标。比如店铺近1天订单支付金额就是一个派生指标，会被直接在产品上展示给商家看。
> 但是这个指标却不能直接从数仓的统一中间层里取数（因为没有现成的事实字段，数仓提供的一般都是大宽表）。需要有一个桥梁连接数仓中间层和业务方的指标需求，于是便有了派生指标

- 派生指标：维度+修饰词+原子指标。店铺近1天订单支付金额中店铺是维度，近1天是一个时间类型的修饰词，支付金额是一个原子指标；

> 维度：观察各项指标的角度；
> 修饰词：维度的一个或某些值，比如维度性别下，男和女就是2种修饰词。

- 衍生指标：比如某一个促销活动的转化率就是衍生指标，因为需要促销投放人数指标和促销订单数指标进行计算得出。

#### 7. 标签

标签是人为设定的、根据业务场景需求，对目标对象运用一定的算法得到的高度精炼的特征标识。可见标签是经过人为再加工后的结果，如网红、白富美、萝莉。对于有歧义的标签，我们内部可进行标签区分，比如：苹果，我们可以定义苹果指的是水果，苹果手机才指的是手机。

#### 8. 自然键

由现实中已经存在的属性组成的键，它在业务概念中是唯一的，并具有一定的业务含义，比如商品ID，员工ID。

以数仓角度看，来自于业务系统的标识符就是自然键，比如业务库中员工的编号。

#### 9. 持久键

保持永久性不会发生变化。有时也被叫做超自然持久键。比如身份证号属于持久键。

自然键和持久键区别：举个例子就明白了，比如说公司员工离职之后又重新入职，他的自然键也就是员工编号发生了变化，但是他的持久键身份证号是不变的。

#### 10. 代理键

就是不具有业务含义的键。代理键有许多其他的称呼：无意义键、整数键、非自然键、人工键、合成键等。

代理键就是简单的以按照顺序序列生产的整数表示。产品行的第1行代理键为1，则下一行的代理键为2，如此进行。代理键的作用仅仅是连接维度表和事实表。

#### 11. 退化维度

退化维度，就是那些看起来像是事实表的一个维度关键字，但实际上并没有对应的维度表，就是维度属性存储到事实表中，这种存储到事实表中的维度列被称为退化维度。与其他存储在维表中的维度一样，退化维度也可以用来进行事实表的过滤查询、实现聚合操作等。

那么究竟怎么定义退化维度呢？比如说订单id，这种量级很大的维度，没必要用一张维度表来进行存储，而我们进行数据查询或者数据过滤的时候又非常需要，所以这种就冗余在事实表里面，这种就叫退化维度，citycode这种我们也会冗余在事实表里面，但是它有对应的维度表，所以它不是退化维度。

#### 12. 下钻

这是在数据分析中常见的概念，下钻可以理解成增加维的层次，从而可以由粗粒度到细粒度来观察数据，比如对产品销售情况分析时，可以沿着时间维从年到月到日更细粒度的观察数据。从年的维度可以下钻到月的维度、日的维度等。

#### 13. 上卷

知道了下钻，上卷就容易理解了，它俩是相逆的操作，所以上卷可以理解为删掉维的某些层，由细粒度到粗粒度观察数据的操作或沿着维的层次向上聚合汇总数据。

#### 14. 数据集市

数据集市（Data Mart），也叫数据市场，数据集市就是满足特定的部门或者用户的需求，按照多维的方式进行存储，包括定义维度、需要计算的指标、维度的层次等，生成面向决策分析需求的数据立方体。其实就是从数据仓库中抽取出来的一个小合集。

## 二、数仓名词之间关系

### 1. 实体表，事实表，维度表之间的关系

在Kimball维度建模中有维度与事实，在Inmon范式建模中有实体与关系，如果我们分开两种建模方式看这些概念比较容易理解。但是目前也出现了不少混合建模方式，两种建模方式结合起来看，这些概念是不是容易记忆混乱，尤其事实表和实体表，它们之间到底有怎样区别与联系，先看下它们各自概念：

1. 维度表：维度表可以看成是用户用来分析一个事实的窗口，它里面的数据应该是对事实的各个方面描述，比如时间维度表，地域维度表，维度表是事实表的一个分析角度。
2. 事实表：事实表其实就是通过各种维度和一些指标值的组合来确定一个事实的，比如通过时间维度，地域组织维度，指标值可以去确定在某时某地的一些指标值怎么样的事实。事实表的每一条数据都是几条维度表的数据和指标值交汇而得到的。
3. 实体表：实体表就是一个实际对象的表，实体表放的数据一定是一条条客观存在的事物数据，比如说各种商品，它就是客观存在的，所以可以将其设计一个实体表。实时表只描述各个事物，并不存在具体的事实，所以也有人称实体表是无事实的事实表。

举个例子：比如说手机商场中有苹果手机，华为手机等各品牌各型号的手机，这些数据可以组成一个手机实体表，但是表中没有可度量的数据。某天苹果手机卖了15台，华为手机卖了20台，这些手机销售数据属于事实，组成一个事实表。这样就可以使用日期维度表和地域维度表对这个事实表进行各种维度分析。

### 2. 指标与标签的区别

- 概念不同

指标是用来定义、评价和描述特定事物的一种标准或方式。比如：新增用户数、累计用户数、用户活跃率等是衡量用户发展情况的指标；

标签是人为设定的、根据业务场景需求，对目标对象运用一定的算法得到的高度精炼的特征标识。可见标签是经过人为再加工后的结果，如网红、白富美、萝莉。

- 构成不同

指标名称是对事物质与量两方面特点的命名；指标取值是指标在具体时间、地域、条件下的数量表现，如人的体重，指标名称是体重，指标的取值就是120斤；

标签名称通常都是形容词或形容词+名词的结构，标签一般是不可量化的，通常是孤立的，除了基础类标签，通过一定算法加工出来的标签一般都没有单位和量纲。如将超过200斤的称为大胖子。

- 分类不同

对指标的分类：

按照指标计算逻辑，可以将指标分为原子指标、派生指标、衍生指标三种类型；

按照对事件描述内容的不同，分为过程性指标和结果性指标；

对标签的分类：

按照标签的变化性分为静态标签和动态标签；

按照标签的指代和评估指标的不同，可分为定性标签和定量标签；

> 指标最擅长的应用是监测、分析、评价和建模。
> 标签最擅长的应用是标注、刻画、分类和特征提取。
> 特别需要指出的是，由于对结果的标注也是一种标签，所以在自然语言处理和机器学习相关的算法应用场景下，标签对于监督式学习有重要价值，只是单纯的指标难以做到的。而指标在任务分配、绩效管理等领域的作用，也是标签无法做到的。

### 3. 维度和指标区别与联系

维度就是数据的观察角度，即从哪个角度去分析问题，看待问题。

指标就是从维度的基础上去衡算这个结果的值。

维度一般是一个离散的值，比如时间维度上每一个独立的日期或地域，因此统计时，可以把维度相同记录的聚合在一起，应用聚合函数做累加、均值、最大值、最小值等聚合计算。

指标就是被聚合的通计算，即聚合运算的结果，一般是一个连续的值。

### 4. 自然键与代理键在数仓的使用区别

数仓工具箱中说维度表的唯一主键应该是代理键而不应该是自然键。有时建模人员不愿意放弃使用自然键，因为他们希望与操作型代码查询事实表，而不希望与维度表做连接操作。然而，应该避免使用包含业务含义的多维键，因为不管我们做出任何假设最终都可能变得无效，因为我们控制不了业务库的变动。

所以数据仓库中维度表与事实表的每个连接应该基于无实际含义的整数代理键。避免使用自然键作为维度表的主键。

### 5. 数据集市和数据仓库的关系

数据集市是企业级数据仓库的一个子集，他主要面向部门级业务，并且只面向某个特定的主题。为了解决灵活性和性能之间的矛盾，数据集市就是数据仓库体系结构中增加的一种小型的部门或工作组级别的数据仓库。数据集市存储为特定用户预先计算好的数据，从而满足用户对性能的需求。数据集市可以在一定程度上缓解访问数据仓库的瓶颈。

数据集市和数据仓库的主要区别：数据仓库是企业级的，能为整个企业各个部门的运行提供决策支持手段；而数据集市则是一种微型的数据仓库,它通常有更少的数据,更少的主题区域,以及更少的历史数据,因此是部门级的，一般只能为某个局部范围内的管理人员服务，因此也称之为部门级数据仓库。

### 6. 缓慢变化维处理

常见的缓慢变化维处理方式有三种：1）直接覆盖：不记录历史数据，薪数据覆盖旧数据

2）新加一行数据（纵向扩展）：使用代理主键+生效失效时间或者是代理主键+生效失效标识（保存多条记录，直接新添一条记录，同时保留原有记录，并用单独的专用字段保存）

3）新加两个字段（横向扩展）：一个是previous，一个是current，每次更新只更新这两个值，但是这样职能保留最近两次的变化（添加历史列，用不同的字段保存变化痕迹，因为只保存两次变化记录，使用与变化不超过两次的维度）

4) 通过拉链表

### 7. 拉链表的应用

拉链表是什么：记录数据的历史状态以及变化记录。记录一个事物从开始，一直到当前状态的所有变化的信息。拉链表可以避免按每一天存储所有记录造成的海量存储问题，同时也是处理缓慢变化数据的一种方式。

适用场景1、单张表数据量很大。2、表中的部分字段会被update更新操作，如用户联系方式，产品的描述信息，订单的状态等等。3、需要查看某一个时间点或者时间段的历史快照信息，比如，查看某一个订单在历史某一个时间点的状态， 4、变化的比例和频率不是很大，比如，总共有1000万的会员，每天新增和发生变化的有10万左右;

对于以上需求，有以下方式

方案一：每天只留最新的一份 实现简单，每天drop掉前一天的数据，重新抽一份最新全量表。优点：节省空间，一些普通的使用也很方便，不用在选择表的时候加一个时间分区什么的。缺点同样明显，没有历史变化数据，无法查看状态的变化。

方案二：每天保留一份全量的切片数据。每天一份全量的切片，而且历史数据也在。缺点：占用大量存储空间，如果每天都保留一份全量，那么每次全量中会保存很多不变的信息，对存储是极大的浪费。

方案三：使用拉链表。

在空间上做了一个取舍，虽说不像方案一那样占用量那么小，但是它只需增量记录每天变化的数据。

其次它能满足方案二所能满足的需求，既能获取最新的数据，也能添加筛选条件获取历史的数据。

开链与闭链拉链表中每条数据都有starttime列和endtime列，根据此来控制当前数据的状态并且获取历史的变化情况。

开链：拉链表在初始化完成后，或者存在更新数据，则拉链表中当前数据的starttime为最新时间，endtime为9999-12-31，表示当前数据的状态为最新状态。

闭链：拉链表中的数据如果存在更新，首先会对被更新数据进行闭链操作，然后再添加开链数据。闭链操作为将被更新的数据endtime改为当前时间，表示此条数据的历史状态被定格在endtime。以后根据end_time即可获取数据在指定日期的状态值。

设计与实现

目前数据仓库设计几乎都是基于新增策略，而不update，基于此策略设计拉链表。

1、需要一张ODS层的用户全量表。需要用它来初始化。2、获取每日的用户更新表，将更新表与全量表比对，进行开链与闭链操作，记录数据的更新状态。

- 我们可以监听Mysql数据的变化，比如说用Canal，最后合并每日的变化，获取到最后的一个状态。
- 流水表！有每日的变更流水表。

而且我们要确定拉链表的时间粒度，比如说拉链表每天只取一个状态，就是说如果一天有3个状态变更，我们只取最后一个状态，这种天粒度的表其实已经能解决大部分的问题，如果有更细粒度的分析需求，根据需求指定时间粒度。

### 8. 事实表的类型

事务型事实表

概述

事务事实表用来记录各业务过程，它保存的是各业务过程的原子操作事件，即最细粒度的操作事件。粒度是指事实表中一行数据所表达的业务细节程度。

事务型事实表可用于分析与各业务过程相关的各项统计指标，由于其保存了最细粒度的记录，可以提供最大限度的灵活性，可以支持无法预期的各种细节层次的统计需求。

设计流程

设计事务事实表时一般可遵循以下四个步骤：

选择业务过程→声明粒度→确认维度→确认事实

> 选择业务过程在业务系统中，挑选我们感兴趣的业务过程，业务过程可以概括为一个个不可拆分的行为事件，例如电商交易中的下单，取消订单，付款，退单等，都是业务过程。通常情况下，一个业务过程对应一张事务型事实表。声明粒度业务过程确定后，需要为每个业务过程声明粒度。即精确定义每张事务型事实表的每行数据表示什么，应该尽可能选择最细粒度，以此来应各种细节程度的需求。典型的粒度声明如下：订单事实表中一行数据表示的是一个订单中的一个商品项。确定维度确定维度具体是指，确定与每张事务型事实表相关的维度有哪些。确定维度时应尽量多的选择与业务过程相关的环境信息。因为维度的丰富程度就决定了维度模型能够支持的指标丰富程度。确定事实此处的“事实”一词，指的是每个业务过程的度量值（通常是可累加的数字类型的值，例如：次数、个数、件数、金额等）。经过上述四个步骤，事务型事实表就基本设计完成了。第一步选择业务过程可以确定有哪些事务型事实表，第二步可以确定每张事务型事实表的每行数据是什么，第三步可以确定每张事务型事实表的维度外键，第四步可以确定每张事务型事实表的度量值字段。

周期快照事实表

概述

周期快照事实表以具有规律性的、可预见的时间间隔来记录事实，主要用于分析一些存量型（例如商品库存，账户余额）或者状态型（空气温度，行驶速度）指标。

对于商品库存、账户余额这些存量型指标，业务系统中通常就会计算并保存最新结果，所以定期同步一份全量数据到数据仓库，构建周期型快照事实表，就能轻松应对此类统计需求，而无需再对事务型事实表中大量的历史记录进行聚合了。

对于空气温度、行驶速度这些状态型指标，由于它们的值往往是连续的，我们无法捕获其变动的原子事务操作，所以无法使用事务型事实表统计此类需求。而只能定期对其进行采样，构建周期型快照事实表。

设计流程

> 确定粒度周期型快照事实表的粒度可由采样周期和维度描述，故确定采样周期和维度后即可确定粒度。采样周期通常选择每日。维度可根据统计指标决定，例如指标为统计每个仓库中每种商品的库存，则可确定维度为仓库和商品。确定完采样周期和维度后，即可确定该表粒度为每日-仓库-商品。确认事实事实也可根据统计指标决定，例如指标为统计每个仓库中每种商品的库存，则事实为商品库存。适用场景适用于分析存量型、状态型指标

事实类型

此处的事实类型是指度量值的类型，而非事实表的类型。事实（度量值）共分为三类，分别是可加事实，半可加事实和不可加事实。

> 可加事实可加事实是指可以按照与事实表相关的所有维度进行累加，例如事务型事实表中的事实。半可加事实半可加事实是指只能按照与事实表相关的一部分维度进行累加，例如周期型快照事实表中的事实。以上述各仓库中各商品的库存每天快照事实表为例，这张表中的库存事实可以按照仓库或者商品维度进行累加，但是不能按照时间维度进行累加，因为将每天的库存累加起来是没有任何意义的。不可加事实不可加事实是指完全不具备可加性，例如比率型事实。不可加事实通常需要转化为可加事实，例如比率可转化为分子和分母。

累计快照事实表

概述

累计快照事实表是基于一个业务流程中的多个关键业务过程联合处理而构建的事实表，如交易流程中的下单、支付、发货、确认收货业务过程。用于记录当前事务的状态变化。

累积型快照事实表主要用于分析业务过程（里程碑）之间的时间间隔等需求。例如前文提到的用户下单到支付的平均时间间隔，使用累积型快照事实表进行统计，就能避免两个事务事实表的关联操作，从而变得十分简单高效。

设计流程

累积型快照事实表的设计流程同事务型事实表类似，也可采用以下四个步骤，下面重点描述与事务型事实表的不同之处。

选择业务过程→声明粒度→确认维度→确认事实

> 选择业务过程选择一个业务流程中需要关联分析的多个关键业务过程，多个业务过程对应一张累积型快照事实表。声明粒度精确定义每行数据表示的是什么，尽量选择最小粒度。确认维度选择与各业务过程相关的维度，需要注意的是，每各业务过程均需要一个日期维度。确认事实选择各业务过程的度量值。适用场景适用于处理多事务关联

### 9. 全量表,增量表,流水表,拉链表的区别及使用场景（同步策略）

全量表每天的所有的最新状态的数据。1、全量表，有无变化，都要报 2、每次上报的数据都是所有的数据（变化的 + 没有变化的）

增量表新增数据，增量数据是上次导出之后的新数据。1、记录每次增加的量，而不是总量；2、增量表，只报变化量，无变化不用报 3、业务库表中需有主键及创建时间，修改时间

流水表对于表中的每一个修改都会记录，可以用于反映实际记录的变更，主要用于数据变化状态。

拉链表维护历史状态，以及最新状态数据 适用情况：

1. 数据量比较大
2. 表中的部分字段会被更新
3. 需要查看某一个时间点或者时间段的历史快照信息 查看某一个订单在历史某一个时间点的状态 某一个用户在过去某一段时间，下单次数
4. 更新的比例和频率不是很大 如果表中信息变化不是很大，每天都保留一份全量，那么每次全量中会保存很多不变的信息，对存储是极大的浪费

优点 1、满足反应数据的历史状态 2、最大程度节省存储

### 10. 指标与标签的区别

- 概念不同

指标是用来定义、评价和描述特定事物的一种标准或方式。比如：新增用户数、累计用户数、用户活跃率等是衡量用户发展情况的指标；

标签是人为设定的、根据业务场景需求，对目标对象运用一定的算法得到的高度精炼的特征标识。可见标签是经过人为再加工后的结果，如网红、白富美、萝莉。

- 构成不同

指标名称是对事物质与量两方面特点的命名；指标取值是指标在具体时间、地域、条件下的数量表现，如人的体重，指标名称是体重，指标的取值就是120斤；

标签名称通常都是形容词或形容词+名词的结构，标签一般是不可量化的，通常是孤立的，除了基础类标签，通过一定算法加工出来的标签一般都没有单位和量纲。如将超过200斤的称为大胖子。

- 分类不同

对指标的分类：

按照指标计算逻辑，可以将指标分为原子指标、派生指标、衍生指标三种类型；

按照对事件描述内容的不同，分为过程性指标和结果性指标；

对标签的分类：

按照标签的变化性分为静态标签和动态标签；

按照标签的指代和评估指标的不同，可分为定性标签和定量标签；

指标最擅长的应用是监测、分析、评价和建模。
标签最擅长的应用是标注、刻画、分类和特征提取。
特别需要指出的是，由于对结果的标注也是一种标签，所以在自然语言处理和机器学习相关的算法应用场景下，标签对于监督式学习有重要价值，只是单纯的指标难以做到的。而指标在任务分配、绩效管理等领域的作用，也是标签无法做到的。



### 11. 维度和指标区别与联系

维度就是数据的观察角度，即从哪个角度去分析问题，看待问题。

指标就是从维度的基础上去衡算这个结果的值。

维度一般是一个离散的值，比如时间维度上每一个独立的日期或地域，因此统计时，可以把维度相同记录的聚合在一起，应用聚合函数做累加、均值、最大值、最小值等聚合计算。

指标就是被聚合的通计算，即聚合运算的结果，一般是一个连续的值。

### 12. 自然键与代理键在数仓的使用区别

数仓工具箱中说维度表的唯一主键应该是代理键而不应该是自然键。有时建模人员不愿意放弃使用自然键，因为他们希望与操作型代码查询事实表，而不希望与维度表做连接操作。然而，应该避免使用包含业务含义的多维键，因为不管我们做出任何假设最终都可能变得无效，因为我们控制不了业务库的变动。

所以数据仓库中维度表与事实表的每个连接应该基于无实际含义的整数代理键。避免使用自然键作为维度表的主键。

### 13. 数据集市与数据仓库的区别与联系

数据集市就是企业级数据仓库的一个子集，它主要面向部门级业务，并且只面向某个特定的主题。为了解决灵活性与性能之间的矛盾，数据集市就是数据仓库体系结构中增加的一种小型的部门或工作组级别的数据仓库。数据集市存储为特定用户预先计算好的数据，从而满足用户对性能的需求。数据集市可以在一定程度上缓解访问数据仓库的瓶颈。



# 离线数仓建设核心

数据仓库的核心是展现层和提供优质的服务。ETL 及其规范、分层等所做的一切都是为了一个更清晰易用的展现层。

## 一、 数仓分层

数仓分层的原则：

1. 为便于数据分析，要屏蔽底层复杂业务，简单、完整、集成的将数据暴露给分析层。
2. 底层业务变动与上层需求变动对模型冲击最小化，业务系统变化影响削弱在基础数据层，结合自上而下的建设方法削弱需求变动对模型的影响。
3. 高内聚松耦合，即主题之内或各个完整意义的系统内数据的高内聚，主题之间或各个完整意义的系统间数据的松耦合。
4. 构建仓库基础数据层，使底层业务数据整合工作与上层应用开发工作相隔离，为仓库大规模开发奠定基础 仓库层次更加清晰，对外暴露数据更加统一。

一般采用如下分层结构：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zG329FOSxOPZhQuUCmKA72K9KgDzibC497KOGwCTWRicD9F5zA7MicicsDxwTFx44PuwXD1nJYcMZ28mg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### 1. 数据源层：ODS

ODS全称是Operational Data Store，即操作数据存储。

Inmon VS Kimball

Bill.Inmon的定义：ODS是一个面向主题的、集成的、可变的、当前的细节数据集合，用于支持企业对于即时性的、操作性的、集成的全体信息的需求。常常被作为数据仓库的过渡，也是数据仓库项目的可选项之一。

而Kimball的定义：操作型系统的集成，用于当前、历史以及其它细节查询(业务系统的一部分)；为决策支持提供当前细节数据(数据仓库的一部分)。

ODS VS DB VS EDW

ODS是用于支持企业日常的全局应用的数据集合，ODS的数据具有面向主题、集成的、可变的以及数据是当前的或是接近当前的特点。同样也可以看出ODS是介于DB和DW之间的一种过渡存储。

值得注意的是，Kimball所说的ODS是物理落地关系型数据库中，但是在实际生产应用中，ODS往往是物理落地在数据仓库中，比如Hive。

通常来说ODS是在数据仓库中存储业务系统源数据，所以从数据粒度、数据结构、数据关系等各个方面都与业务系统的数据源保持一致。但是，也不能仅仅将ODS层看做是业务系统数据源的一个简单备份，ODS和业务系统数据源的差异主要是由于两者之间面向业务需求是不同的，业务系统是面向多并发读写同时有需要满足数据的一致性，而ODS数据通常是面向数据报表等批量数据查询需求。

ODS层的设计思路

ODS层数据同步

上文提到ODS的数据来源于业务系统，且ODS落地的系统通常和业务系统是不同的，比如常见的将数据落到Hive中。所以，首先我们就需要将业务系统的数据抽取到ODS表中。一般来说，数据同步的方式大概可以分为三大类：文件抽取、数据库表的抽取和原始日志的抽取。

文件抽取

通常情况下，ODS层表的存储位置与业务系统表的存储位置是不一样的，比如业务表存在MySQL中，而ODS层存储在Hive中。另外，有的时候，ODS层需要对接多个不同类型的业务系统库，比如DB2、Oracle、Mysql等等，一种比较简单实用的做法是和各个业务系统约定好数据接口，并让业务系统按照数据接口格式生成数据文件和完结标示文件给到ODS。

这种方式有两个明显的优势：一方面可以降低ODS处理多种类型数据库系统能力需求，另一方面也减少了对业务系统的性能影响。但是这种方式也存在一些不足：数据的抽取过程和加载过程是分开的，由业务系统和ODS分别负责，同时接口新增和变更比较麻烦，需要较大的沟通维护成本，另外，数据落地到文件增加了额外的上传下载工作，会造成效率比较低。

在实际的生产过程中，这种方式的数据同步也很少被使用。

直连同步

直连同步是指通过定义好的规范接口API和基于动态链接库的方式直接连接业务库，比如ODBC/JDBC等规定了统一的标准接口，不同的数据库基于这套标准提供规范的驱动，从而支持完全相同的函数调用和SQL实现。比如经常使用的Sqoop就是采取这种方式进行批量数据同步的。

直连同步的方式配置十分简单，很容易上手操作，比较适合操作型业务系统的数据同步，但是会存在以下问题：

- 数据同步时间：随着业务规模的增长，数据同步花费的时间会越来越长，无法满足下游数仓生产的时间要求。
- 性能瓶颈：直连数据库查询数据，对数据库影响非常大，容易造成慢查询，如果业务库没有采取主备策略，则会影响业务线上的正常服务，如果采取了主备策略，虽然可以避免对业务系统的性能影响，但当数据量较大时，性能依然会很差。
- 抽取增量数据需要依靠修改业务系统，新增时间戳字段，并且按时间戳增量抽取的数据准确性不能得到保障，业务系统做数据补丁不更新时间戳字段将会导致漏数；
- 实时性差，只能在某个时刻抽取数据，不能满足准实时数据需求；

在实际的生产过程中，这种方式的数据同步经常被使用，值得注意的是：数据库直连抽取比较适用于小批量表的数据抽取，对于大批量的数据而言，性能会比较差。

日志解析

据库日志抽取是指通过分析数据库日志，将业务系统的DDL和DML语句在一个镜像系统还原，并通过数据流的方式对外提供实时数据服务。

所谓日志解析，即解析数据库的变更日志，比如MySQL的Binlog日志，Oracle的归档日志文件。通过读取这些日志信息，收集变化的数据并将其解析到目标存储中即可完成数据的实时同步。这种读操作是在操作系统层面完成的，不需要通过数据库，因此不会给源数据库带来性能上的瓶颈。

由于是数据库日志抽取是获取所有的变更记录，落地到ODS表的时候我们需要根据主键去重按照日志时间倒排序获取最后状态的变化情况。通常使FULL OUTER JOIN全外连接的方式进行Merge数据。

数据库日志解析的同步方式可以实现实时与准实时的同步，延迟可以控制在毫秒级别的，其最大的优势就是性能好、效率高，不会对源数据库造成影响，目前，从业务系统到数据仓库中的实时增量同步，广泛采取这种方式。

当然，任何方式都不是完美的，使用日志解析的方式进行数据同步也会存在一些已知的问题：比如在业务系统做批量补数时会造成数据更新量超过处理的能力，从而导致数据延迟。另外，这种方式需要额外补数一个实时抽取的系统，从而也增加了投入和处理的复杂性。

该如何选择同步方式

在实际的生产环境中，直连同步和日志解析是非常普遍的两种数据同步方式，随着实时技术的发展，使得实时数据同步的方式变得越来越方便，越来越多的企业开始尝试使用日志解析的方式进行数据同步。这里需要注意的是，每种方式都有其优缺点及适用的场景，找到合适的方式就是最好的方式，切不可一味的追求狂拽酷炫的同步技术，这也是很多技术人员经常犯的错误，应用和钻研新技术是技术人的追求，但是过犹不及，在解决具体问题的时候，要多方面权衡。

另外，数仓的建设是为业务服务的，应该把时间和精力放在如何支持业务、如何发挥数仓的价值、如何用数据为业务提供支持决策上来。笔者认为，数仓的建设不是一堆大数据技术的简单堆砌，深入理解业务和数据才是数仓建设的第一要义。

ODS层数据清洗

关于ODS层是否做数据清洗一直是存在争议的，但有一点是可以确定的，对于比较重的清洗工作是要留到后面数仓的ETL过程中进行处理。

但是，有这么一种情况：我们在长期的生产实际过程中，发现部分已知的数据问题的处理可以通过自动化的方式来处理，这种方式通常在数据入库之前，做额外的加工处理后再做入库操作。

数据清洗的主要工作是处理那些不符合要求的数据，从而提升数据质量，比如一些常见的问题：错误的数据、重复的数据

- 错误的数据

  这种错误通常是业务系统处理不够健全造成的，比如字符串数据后面有回车空格、日期格式不正确、日期越界等等，这些问题如果不在ODS层做处理，后续的解析处理过程中也是要留意处理的

- 重复的数据

  例如，一些前端系统迁移过后的新老表融合可能会存在大量的重复历史数据，这也可以在数据清洗这一步骤中完成消除重复数据的操作。需要注意的是，在数据清洗后还需要对ODS的数据做稽核，还需要对脏数据做稽核校验，脏数据的校验主要集中在数据量上，如果数据量波动特别大则需要人工介入处理。

其实，在大多数的情况下，是不需要做数据清洗处理的，可以把这个清洗环节放到后面的明细层ETL中进行处理。

ODS层表设计

通常而言，ODS层表跟业务系统保持一致，但又不完全等同于业务系统。在设计ODS物理表时，在表命名、数据存储等方面都需要遵循一定的准则。

命名

比如：不管是表命名还是字段命名尽量和业务系统保持一致，但是需要通过额外的标识来区分增量和全量表，”_delta”来标识该表为增量表。

存储

另外，为了满足历史数据分析需求，我们需要在ODS表中加一个时间维度，这个维度通常在ODS表中作为分区字段。如果是增量存储，则可以按天为单位使用业务日期作为分区，每个分区存放日增量的业务数据。如果是全量存储，只可以按天为单位使用业务日期作为分区，每个分区存储截止到当前业务时间的全量快照数据。

### 2. 数据仓库层：DWD

数据仓库层是我们在做数据仓库时要核心设计的一层，在这里，从 ODS 层中获得的数据按照主题建立各种数据模型。

DW 层又细分为 DWD（Data Warehouse Detail）层、DWM（Data WareHouse Middle）层和 DWS（Data WareHouse Servce） 层。

DWD层是对用户的日志行为事实进行解析，以及对交易业务数据采用维度模型的方式重新建模（即维度退化）。

1、回顾DWD层概念

我们在来回顾一下对DWD层（Data Warehouse Detail）的定义：“明细粒度事实层：是以业务过程来作为建模驱动，基于每个具体的业务过程特点，构建最细粒度的明细层事实表（注意是最细粒度）。需要结合企业的数据使用特点，将明细事实表的某些重要维度属性字段做适当冗余，即宽表化处理。明细粒度事实层的表通常也被称为逻辑事实表。”

2、DWD层建模4步骤

DWD层是事实建模层，这层建模主要做的4个步骤：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/EGZ1ibxgFrbgqHUicWfnn3YYKq0lptnUsHqHR2Qzo08d4Os5ykz0s4IV5U696obur0BDgibBkPFhsg6ZyQaCD7m3Q/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

我们目前已经完成了：

2.1、选择业务过程

选择了事实表，比如：订单事实表、支付事实表等；

2.2、声明粒度

即确认每一行数据是什么，要保证事实表的最小粒度。

2.3、确认维度

在前面两节中我们确定了6个维度；比如时间、用户、地点、商品、优惠券、活动这6个维度。思路是其他ODS层表的维度需要向这6个维度进行退化到DIM层，这样做的母的是减少后期的大量表之间的join操作。

****

![图片](https://mmbiz.qpic.cn/mmbiz_png/EGZ1ibxgFrbiadSnicNe1icicia80EXibrxWMMbu7OAsMEI6M3FmrkFj7LVQsl1v75vKQANVlXYtXNssmvTYlHnibGGicWQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

****

6个维度表的退化操作其实我们在前面的第十二章节已经做了即DIM层。除了第3张表即商品维度表是5个表退化到1张表上，其他都是1-2张表退化到1张表上，相对比较简单。

2.4、确认事实

就是确认事实表的每张事实表的度量值。

![图片](https://mmbiz.qpic.cn/mmbiz_png/EGZ1ibxgFrbiadSnicNe1icicia80EXibrxWMMbDeaO9Hnu8yhq9LmHqMxuibYKCeGy5roHvgq0anbNWtez7XGkzOdicU7w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

下面我们根据事实表的加载方式来选择几个实战操作一下。

二、DWD层-事务型事实表

关于事实表分类，我们在数仓关系建模和维度建模，里面说过，分为6类事实表。

1、事务型事实表的概念

适用于不会发生变化的业务。业务表的同步策略是增量同步。以每个事务或事件为单位，例如一个销售订单记录，一笔支付记录等，作为事实表里的一行数据。一旦事务被提交，事实表数据被插入，数据就不再进行更改，其更新方式为增量更新。

8张表里面包含：支付事实表、评价事实表、退款事实表、订单明细(详情)事实表

2、解析思路

根据事实表（行），选择不同的维度（列）来建表。

![图片](https://mmbiz.qpic.cn/mmbiz_png/EGZ1ibxgFrbjmwR8j4s6DLtSqObkrPYKDhaNfXBRJC8fcVBwxfGNFR7fb3xibAal1V9SzyVZNEKzFFgFnvRhibX0g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

3、支付事实表（事务型事实表）

需要时间、用户、地区三个维度，查看ODS层表ods_payment_info，发现没有地区维度字段。所以通过ods_order_info表关联做join获取该字段。

3.1、建表语句

```sql
drop table if exists dwd_fact_payment_info;
create external table dwd_fact_payment_info (
    `id` string COMMENT 'id',
    `out_trade_no` string COMMENT '对外业务编号',
    `order_id` string COMMENT '订单编号',
    `user_id` string COMMENT '用户编号',
    `alipay_trade_no` string COMMENT '支付宝交易流水编号',
    `payment_amount`    decimal(16,2) COMMENT '支付金额',
    `subject`         string COMMENT '交易内容',
    `payment_type` string COMMENT '支付类型',
    `payment_time` string COMMENT '支付时间',
    `province_id` string COMMENT '省份ID'
) COMMENT '支付事实表表'
PARTITIONED BY (`dt` string)
stored as parquet
location '/warehouse/gmall/dwd/dwd_fact_payment_info/'
tblproperties ("parquet.compression"="lzo");
```

3.2、装载语句

province_id省份ID这个字段通过 ods_order_info表做join获取

```sql
SET hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
insert overwrite table dwd_fact_payment_info partition(dt='2021-05-03')
select
    pi.id,
    pi.out_trade_no,
    pi.order_id,
    pi.user_id,
    pi.alipay_trade_no,
    pi.total_amount,
    pi.subject,
    pi.payment_type,
    pi.payment_time,
    oi.province_id
from
(
    select  from ods_payment_info where dt='2021-05-03'
)pi
join
(
    select id, province_id from ods_order_info where dt='2021-05-03'
)oi
on pi.order_id = oi.id;
```

4、退款事实表（事务型事实表）

需要时间、用户、商品三个维度，查看ODS层表ods_order_refund_info，所有字段都有，那么直接取数装载。

4.1、创建表



```sql
drop table if exists dwd_fact_order_refund_info;
create external table dwd_fact_order_refund_info(
    `id` string COMMENT '编号',
    `user_id` string COMMENT '用户ID',
    `order_id` string COMMENT '订单ID',
    `sku_id` string COMMENT '商品ID',
    `refund_type` string COMMENT '退款类型',
    `refund_num` bigint COMMENT '退款件数',
    `refund_amount` decimal(16,2) COMMENT '退款金额',
    `refund_reason_type` string COMMENT '退款原因类型',
    `create_time` string COMMENT '退款时间'
) COMMENT '退款事实表'
PARTITIONED BY (`dt` string)
stored as parquet
location '/warehouse/gmall/dwd/dwd_fact_order_refund_info/'
tblproperties ("parquet.compression"="lzo");
```

4.2、装载时间

直接从ODS层查到数据后装载。

```sql
insert overwrite table dwd_fact_order_refund_info partition(dt='2021-05-03')
select
    id,
    user_id,
    order_id,
    sku_id,
    refund_type,
    refund_num,
    refund_amount,
    refund_reason_type,
    create_time
from ods_order_refund_info
where dt='2021-05-03';
```

5、评价事实表、订单明细事实表（事务型事实表）

都和上面“退款事实表”处理方法一样，并且所有字段均从ODS层ods_comment_info直接获取。你是否可以自己创建呢？

三、DW层-周期型快照事实表

1、周期型快照事实表的概念

周期型快照事实表，表中不会保留所有数据，只保留固定时间间隔的数据，例如每天或者每月的销售额或每月的账户余额等。例如购物车，有加减商品，随时都有可能变化，但是我们更关心每天结束时这里面有多少商品，方便我们后期统计分析。相当于每天一个全量快照，业务表的同步策略是全量同步。

2、解析思路

每天做一次快照，导入的数据是全量，区别于事务型事实表是每天导入新增。

存储的数据比较讲究时效性，时间太久了的意义不大，可以删除以前的数据。

![图片](https://mmbiz.qpic.cn/mmbiz_png/EGZ1ibxgFrbgugEqew0X0aHCwSLhXUBAp0ez5AZ1dEXRzq1RribZ9zq1ncp2FE4lDlzKw8pEdmKtomLpC7yThvug/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

3、加购事实表（周期型快照事实表）

3.1、创建表结构

所有字段ODS层，fact_cart_info表都有。

```sql
drop table if exists dwd_fact_cart_info;
create external table dwd_fact_cart_info(
    `id` string COMMENT '编号',
    `user_id` string  COMMENT '用户id',
    `sku_id` string  COMMENT 'skuid',
    `cart_price` string  COMMENT '放入购物车时价格',
    `sku_num` string  COMMENT '数量',
    `sku_name` string  COMMENT 'sku名称 (冗余)',
    `create_time` string  COMMENT '创建时间',
    `operate_time` string COMMENT '修改时间',
    `is_ordered` string COMMENT '是否已经下单。1为已下单;0为未下单',
    `order_time` string  COMMENT '下单时间',
    `source_type` string COMMENT '来源类型',
    `srouce_id` string COMMENT '来源编号'
) COMMENT '加购事实表'
PARTITIONED BY (`dt` string)
stored as parquet
location '/warehouse/gmall/dwd/dwd_fact_cart_info/'
tblproperties ("parquet.compression"="lzo");
```

3.2、装载数据



```sql
insert overwrite table dwd_fact_cart_info partition(dt='2021-05-03')
select
    id,
    user_id,
    sku_id,
    cart_price,
    sku_num,
    sku_name,
    create_time,
    operate_time,
    is_ordered,
    order_time,
    source_type,
    source_id
from ods_cart_info
where dt='2020-06-14';
```

4、收藏事实表

收藏事实表的操作和加购事实表一样，从时间、商品、用户三个维度来创建表。

四、DWD层-累积型快照事实表

1、累积型快照事实表的概念

累积型快照事实表，用于周期性发生变化的业务，即需要周期性的跟踪业务事实的变化。例如：数据仓库中可能需要累积或者存储订单从下订单开始，到订单商品被打包、运输、和签收的各个业务阶段的时间点数据来跟踪订单声明周期的进展情况。当这个业务过程进行时，事实表的记录也要不断更新。

业务表的同步策略是新增以及变化同步。

2、解析思路

我们以优惠券领用事实表为例。首先要了解优惠卷的生命周期：领取优惠卷——>用优惠卷下单——>优惠卷参与支付

累积型快照事实表使用：统计优惠卷领取次数、优惠卷下单次数、优惠卷参与支付次数。

![图片](https://mmbiz.qpic.cn/mmbiz_png/EGZ1ibxgFrbhzpmCCuwLSGmiaKv6JeUh0uPv9ia5v2oqwliafEib4JPw012YVeFM9D1KYIicjTyV6sEyem3N0DibAjTfw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

3、优惠券领用事实表（累积型快照事实表）

3.1、创建表结构



```sql
drop table if exists dwd_fact_coupon_use;
create external table dwd_fact_coupon_use(
    `id` string COMMENT '编号',
    `coupon_id` string  COMMENT '优惠券ID',
    `user_id` string  COMMENT 'userid',
    `order_id` string  COMMENT '订单id',
    `coupon_status` string  COMMENT '优惠券状态',
    `get_time` string  COMMENT '领取时间',
    `using_time` string  COMMENT '使用时间(下单)',
    `used_time` string  COMMENT '使用时间(支付)'
) COMMENT '优惠券领用事实表'
PARTITIONED BY (`dt` string)
stored as parquet
location '/warehouse/gmall/dwd/dwd_fact_coupon_use/'
tblproperties ("parquet.compression"="lzo");
```

注意：这里dt是按照优惠卷领用时间get_time做为分区

```sql
`get_time` string  COMMENT '领取时间',
`using_time` string  COMMENT '使用时间(下单)',
`used_time` string  COMMENT '使用时间(支付)'
```

3.2装载数据

首日装载分析

![图片](https://mmbiz.qpic.cn/mmbiz_png/EGZ1ibxgFrbhzpmCCuwLSGmiaKv6JeUh0uDHYiaVVwWSic8IdlW9RuBvRrVPbbxGwsqf4z837ufHbGv24XA3GkvFsA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

首日装载SQL代码,注意是动态分区。



```sql
insert overwrite table dwd_coupon_use partition(dt)
select
    id,
    coupon_id,
    user_id,
    order_id,
    coupon_status,
    get_time,
    using_time,
    used_time,
    expire_time,
    coalesce(date_format(used_time,'yyyy-MM-dd'),date_format(expire_time,'yyyy-MM-dd'),'9999-99-99')
from ods_coupon_use
where dt='2021-05-03';
```

每日装载思路分析

![图片](https://mmbiz.qpic.cn/mmbiz_png/EGZ1ibxgFrbghwypnlx60h4mHx8zGbFQx4p8LHtoymSqKr8ibUBx5zdUUiciczO88zPxHZsPwh6DaSw3tavARnGhnA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

SQL代码

```sql
set hive.exec.dynamic.partition.mode=nonstrict;
set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
insert overwrite table dwd_fact_coupon_use partition(dt)
select
    if(new.id is null,old.id,new.id),
    if(new.coupon_id is null,old.coupon_id,new.coupon_id),
    if(new.user_id is null,old.user_id,new.user_id),
    if(new.order_id is null,old.order_id,new.order_id),
    if(new.coupon_status is null,old.coupon_status,new.coupon_status),
    if(new.get_time is null,old.get_time,new.get_time),
    if(new.using_time is null,old.using_time,new.using_time),
    if(new.used_time is null,old.used_time,new.used_time),
    date_format(if(new.get_time is null,old.get_time,new.get_time),'yyyy-MM-dd')
from
(
    select
        id,
        coupon_id,
        user_id,
        order_id,
        coupon_status,
        get_time,
        using_time,
        used_time
    from dwd_fact_coupon_use
    where dt in
    (
        select
            date_format(get_time,'yyyy-MM-dd')
        from ods_coupon_use
        where dt='2021-05-04'
    )
)old
full outer join
(
    select
        id,
        coupon_id,
        user_id,
        order_id,
        coupon_status,
        get_time,
        using_time,
        used_time
    from ods_coupon_use
    where dt='2021-05-04'
)new
on old.id=new.id;
```

其他类似的累积型事实表也是这个操作思路。

这样我们就完成了DWD层业务数据的建模和设计、搭建和使用包括简要的SQL代码的编写。

现在我们来总结一下：

DWD层是对事实表的处理，代表的是业务的最小粒度层。任何数据的记录都可以从这一层获取，为后续的DWS和DWT层做准备。DWD层是站在选择好事实表的基础上，对维度建模的视角，这层维度建模主要做的4个步骤：选择业务过程、声明粒度、确认维度、确认事实

### 3.汇总数据层 DWS

对于数仓的分层，想必大家都不陌生。基于OneData方法论的三层数仓划分：数据引入层（ODS，Operational Data Store）、数据公共层（CDM，Common Dimenions Model）和数据应用层（ADS，Application Data Store）早就深入人心。

当然啦，涉及到每一层具体该怎么开发、建模，可能大家都有自己的理解。

但好在大家对数据建模重要性的认识那都是一致的，如果我们把指标比作树上的果实，那么模型就好比是大树的躯干，想让果实结得好，必须让树干变得粗壮。

我们先来回想下，构建数据中台的初衷是什么：

- 缺少可以复用的数据
- 大家不得不使用原始数据进行清洗、加工和计算指标
- 大量重复代码的开发对资源的消耗

问题的根源就在于数据模型的无法复用，以及数据开发都是烟囱式的。所以要解决这个问题，就要搞清楚健壮的数据模型该如何设计。





Part1常见的数仓分层设计思路

下图是数仓分层的逻辑架构图，大家不妨回忆一下数据模型的分层设计：

[![图片](https://mmbiz.qpic.cn/mmbiz_png/zWSuIP8rdu2gwBjUucvb5oWPQiaibicJbAqUDJP6tcf1pRRHuckTqRibMyBvtfxjWj78vjJ9ElJytiatHxLGyVUJE8w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)](http://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&mid=2247507972&idx=1&sn=e19cfa6cb4119831f3ab5ef26af03c98&chksm=cf379209f8401b1f449f43a0631aa46981fecc84be511da2ac91c0e552fdcd45ea6b9aac218e&scene=21#wechat_redirect)

- 数据引入层（ODS，Operational Data Store，又称数据基础层）：将原始数据几乎无处理地存放在数据仓库系统中，结构上与源系统基本保持一致，是数据仓库的数据准备区。这一层的主要职责是将基础数据同步、存储。

- 数据公共层（CDM，Common Dimenions Model）：存放明细事实数据、维表数据及公共指标汇总数据。其中，明细事实数据、维表数据一般根据ODS层数据加工生成。公共指标汇总数据一般根据维表数据和明细事实数据加工生成。CDM层又细分为维度层（DIM）、明细数据层（DWD）和汇总数据层（DWS），采用维度模型方法作为理论基础， 可以定义维度模型主键与事实模型中外键关系，减少数据冗余，也提高明细数据表的易用性。在汇总数据层同样可以关联复用统计粒度中的维度，采取更多的宽表化手段构建公共指标数据层，提升公共指标的复用性，减少重复加工。

- - 维度层（DIM，Dimension）：以维度作为建模驱动，基于每个维度的业务含义，通过添加维度属性、关联维度等定义计算逻辑，完成属性定义的过程并建立一致的数据分析维表。为了避免在维度模型中冗余关联维度的属性，基于雪花模型构建维度表。
  - 明细数据层（DWD，Data Warehouse Detail）：以业务过程作为建模驱动，基于每个具体的业务过程特点，构建最细粒度的明细事实表。可将某些重要属性字段做适当冗余，也即宽表化处理。
  - 汇总数据层（DWS，Data Warehouse Summary）：以分析的主题对象作为建模驱动，基于上层的应用和产品的指标需求，构建公共粒度的汇总指标表。以宽表化手段物理化模型，构建命名规范、口径一致的统计指标，为上层提供公共指标，建立汇总宽表、明细事实表。

- 数据应用层（ADS，Application Data Store）：存放数据产品个性化的统计指标数据，根据CDM层与ODS层加工生成。

Part2DWS层很重要？

通常，大家都会有这样的疑问：明明可以直接从DWD层取数，为什么要多此一举建立DWS的汇总逻辑表呢？

我想说的是：如果在业务场景不复杂的情况下，那样做是没有问题的。可一旦面对复杂的业务场景，那这种做法无疑是混乱的根源所在，前面提到的烟囱式开发、计算资源的浪费等等情况，正是这样产生的。

举个例子，我们需要的是从数据明细层中做一个初步的汇总，抽象出来一些通用的维度：时间、用户ID、IP等，并根据这些维度做一些统计，比如用户每个时间段在不同登录IP购买的商品数等。

这里做一层轻度的汇总会让计算更加的高效，在此基础上如果计算仅7天、30天、90天的行为的话会快很多。我们希望80%的业务都能通过我们的DWS层计算，而不是ODS或者DWD层。

Part3应该遵循的设计原则

聚集是指针对原始明细粒度的数据进行汇总。DWS汇总数据层是面向分析对象的主题聚集建模，以零售的场景为例，我们最终的分析目标为：最近一天某个类目（例如，厨具）商品在各省的销售总额、该类目销售额Top10的商品名称、各省用户购买力分布。

因此，我们可以以最终交易成功的商品、类目、买家等角度对最近一天的数据进行汇总。数据聚集的注意事项如下：

- 聚集是不跨越事实的。聚集是针对原始星形模型进行的汇总。为获取和查询与原始模型一致的结果，聚集的维度和度量必须与原始模型保持一致，因此聚集是不跨越事实的，所以原子指标只能基于一张事实表定义，但是支持原子指标组合为衍生原子指标。
- 聚集会带来查询性能的提升，但聚集也会增加ETL维护的难度。当子类目对应的一级类目发生变更时，先前存在的、已经被汇总到聚集表中的数据需要被重新调整。

此外，进行DWS层设计时还需遵循数据公用性原则。数据公用性需要考虑汇总的聚集是否可以提供给第三方使用。我们可以思考基于某个维度的聚集是否经常用于数据分析中，如果答案是肯定的，就有必要把明细数据经过汇总沉淀到聚集表中。

简单的说就是：

- 主题
- 宽表
- 轻度汇总

Part4图解DWS层设计流程

以电商零售的场景为例，我们已经基于ODS层的订单表、用户表、商品表、优惠券表等，经过ETL完成了DWD层的建模，一般是采用星型模型。

这里严格按照：业务过程→声明粒度→确认维度→确认事实 完成建模，过程如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/zWSuIP8rdu2gwBjUucvb5oWPQiaibicJbAqzibY6DbzX4NH06m9ib5tICLcF5HLkbiaicl8dL7xnBff7kQibyrzgRP7flQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

接下来，便是到了DWS层设计的环节。按照我们上面的设计思路，通过从维度表去看事实表，便可得出每天的宽表。

这样即可统计各个主题对象的当天行为，服务于ADS层的主题宽表以及一些业务的明细数据，也可以以应对一些特殊的需求，例如：购买行为，统计商品复购率等。

[![图片](https://mmbiz.qpic.cn/mmbiz_png/zWSuIP8rdu2gwBjUucvb5oWPQiaibicJbAqFJiaEOlKHCbbuuxOT6864Lf2aIcGBUdgZ52cNn4TvGMfVylzecf1Waw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)](http://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&mid=2247507972&idx=2&sn=3f25b2a1527f453bcde3edc35721fb38&chksm=cf379209f8401b1fbd694838d7d029a3048261d545bb3f9394b0bce083913084a7ae714e6b67&scene=21#wechat_redirect)

通过外键获取相关的度量值，我们整合多个DWD的明细事实表度量值来构成新表。

在这里，我们还是要遵循上文提到的设计原则，在设计上尽量体现出公共性、使用简单并且用户很容易理解。

Part5思考：如何设计出完美的DWS层？

在我们数据中台实际实施落地的过程中，团队不但要建设公共数据层，形成数据中台，还要承担着新需求的压力。

往往我们要先满足需求（活下去），再研发公共数据层（构建美好未来），在满足业务需求的过程中，再根据需求不断对模型进行迭代和优化，随着时间的推移，越来越多的业务需求可以通过DWS层的数据完成。

这一过程中，完善度是很好的考核标准，主要看DWS层汇总的数据能满足多少的查询需求，如果汇总数据无法满足需求，使用数据的人就必须使用明细的数据，甚至是ODS层的原始数据。

DWS/ADS层的完善度越高，说明数据的上层建设越完善，而从使用者的角度来说，查询快、易取数、用的爽，那才是硬道理。

### 4.数据应用层：ADS

在这里，主要是提供给数据产品和数据分析使用的数据，一般会存放在 ES、 PostgreSql、Redis 等系统中供线上系统使用，也可能会存在 Hive 或者 Druid 中供数据分析和数据挖掘使用。比如我们经常说的报表数据，一般就放在这里。

数仓ADS层指标计算案例分享

ADS层数据往往是最终的结果指标数据，在大屏展示，或者实时流处理时候使用，通过下面两个例子来练习业务大屏展示sql该怎么写。

1. 会员分析案例

#### 1.1 数据准备

表结构如下，其中此表是dws层以天为维度的会员表，比如每天的会员信息汇总，

```sql
use dws;
drop table if exists dws.dws_member_start_day;
create table dws.dws_member_start_day(
`device_id` string, -- 设备id，来区分用户
`uid` string, -- uid
`app_v` string,
`os_type` string,
`language` string,
`channel` string,
`area` string,
`brand` string
) COMMENT '会员日启动汇总'
partitioned by(dt string)
stored as parquet;

```

#### 1.2 会员指标计算

沉默会员的定义：只在安装当天启动过App，而且安装时间是在7天前；
流失会员的定义：最近30天未登录的会员

#### 1.2.1 如何计算沉默会员数

```sql
-- 关键点在于只启动一次
-- 拿到只启动一次的会员，后面再过滤安装时间是再7天前的，使用sum窗口函数
SELECT count()
FROM
  (SELECT device_id,
          sum(device_id) OVER (PARTITION BY device_id) AS sum_num,
                     dt
   FROM dws.dws_member_start_day) tmp
WHERE dt <= date_add(CURRENT_DATE, -7)
  AND sum_num=1

```

#### 1.2.2 如何计算流失会员数

```sql
-- 关键点在于最近一次登录
-- 拿到会员最近一次登录时间，并用row_number来过滤
SELECT count()
FROM
  (SELECT device_id,
          dt,
          row_number() OVER (PARTITION BY device_id
                             ORDER BY dt DESC) ro
   FROM dws.dws_member_start_day) tmp
WHERE ro=1
  AND dt >= date_add(CURRENT_DATE, -30) 

```

2. 核心交易案例

#### 2.1 数据准备

给定一个每日订单维度表，表结构如下：

```sql
-- 订单明细
DROP TABLE IF EXISTS dwd.dwd_trade_orders;
create table dwd.dwd_trade_orders(
`orderId`    int,
`orderNo`   string,
`userId`    bigint,
`status`    tinyint,
`productMoney` decimal,
`totalMoney`  decimal,
`payMethod`   tinyint,
`isPay`     tinyint,
`areaId`    int,
`tradeSrc`   tinyint,
`tradeType`   int,
`isRefund`   tinyint,
`dataFlag`   tinyint,
`createTime`  string,
`payTime`   string,
`modifiedTime` string,
`start_date`  string,
`end_date`   string
) COMMENT '订单事实拉链表'
partitioned by (dt string)
STORED AS PARQUET;

```

其中，订单状态 -3 用户拒收；-2未付款的订单；-1用户取消；0 待发货；1配送中；2用户确认收货，订单有效标志；-1 删除；1 有效。

数据预处理，在明细事实拉链表处理时不太方便，可以做一张中间表，dws_trade_orders_day 其表结构和加工如下：

```sql
DROP TABLE IF EXISTS dws.dws_trade_orders_day;

CREATE TABLE IF NOT EXISTS dws.dws_trade_orders_day(day_dt string COMMENT '日期：yyyy-MM-dd',
                                                   day_cnt decimal commnet '日订单笔数',
                                                   day_sum decimal COMMENT '日订单总额') COMMENT '日订单统计表';

SELECT dt,
       count() cnt,
       sum(totalMoney) sm
FROM
  (SELECT DISTINCT orderid,
                   dt,
                   totalMoney
   FROM dwd.dwd_trade_orders
   WHERE status >= 0
     AND dataFlag = '1') tmp
GROUP BY dt;


INSERT OVERWRITE TABLE dws.dws_trade_orders_day
SELECT dt,
       count() cnt,
       sum(totalMoney) sm
FROM
  (SELECT DISTINCT orderid,
                   dt,
                   totalMoney
   FROM dwd.dwd_trade_orders
   WHERE status >= 0
     AND dataFlag = '1') tmp
GROUP BY dt;


SELECT 
FROM dws.dws_trade_orders_day
WHERE day_dt BETWEEN '2020-01-01' AND '2020-12-31';

```

#### 2.2 指标1，统计2020年每个季度的销售订单笔数、订单总额

先创建ads指标表：dws_trade_orders_quarter

```sql
DROP TABLE IF EXISTS dws.dws_trade_orders_quarter;


CREATE TABLE IF NOT EXISTS dws.dws_trade_orders_quarter(YEAR string COMMENT '年份',
                                                        QUARTER string COMMENT '季度',
                                                        cnt decimal COMMENT '订单总笔数',
                                                        SUM decimal COMMENT '订单总额') COMMENT '季度订单统计表';

INSERT OVERWRITE TABLE dws.dws_trade_orders_quarter WITH tmp AS
  (SELECT substr(day_dt, 0, 4) YEAR,
                               CASE WHEN substr(dat_dt, 6, 2)="01"
   OR substr(dat_dt, 6, 2)="02"
   OR substr(day_dt, 6, 2)="03" THEN "1" WHEN substr(dat_dt, 6, 2)="04"
   OR substr(dat_dt, 6, 2)="05"
   OR substr(day_dt, 6, 2)="06" THEN "2" WHEN substr(dat_dt, 6, 2)="07"
   OR substr(dat_dt, 6, 2)="08"
   OR substr(day_dt, 6, 2)="09" THEN "3" WHEN substr(dat_dt, 6, 2)="10"
   OR substr(dat_dt, 6, 2)="11"
   OR substr(day_dt, 6, 2)="12" THEN "4" AS QUARTER day_cnt,
                                     day_sum
   FROM dws.dws_trade_orders_day)
SELECT YEAR,
       QUARTER,
       sum(day_cnt),
       sum(day_sum)
FROM tmp
GROUP BY YEAR QUARTER;

```

#### 2.3 统计2020年每个月的销售订单笔数、订单总额

先创建ads指标表：`dws_trade_orders_month`

```sql
DROP TABLE IF EXISTS dws.dws_trade_orders_month;

CREATE TABLE IF NOT EXISTS dws.dws_trade_orders_month(yearstring COMMENT '年份',
                                                      MONTH string COMMENT '月份',
                                                      month_cnt decimal COMMENT '月订单总笔数',
                                                      month_sum decimal COMMENT '月订单总额') COMMENT '月订单统计表';


INSERT OVERWRITE TABLE dws.dws_trade_orders_month WITH tmp AS
  (SELECT substr(day_dt, 0, 4) YEAR,
                               sunstr(day_dt, 6, 2) MONTH,
                                                    day_cnt,
                                                    day_sum
   FROM dws.dws_trade_orders_day)
SELECT YEAR,
       MONTH,
       sum(day_cnt) month_cnt,
       sum(day_sum) month_sum
FROM tmp
GROUP BY YEAR,
         MONTH;

```

#### 2.4 统计2020年每周（周一到周日）的销售订单笔数、订单总额

创建ads层指标表：`dws_trade_orders_week`利用到日期函数```weekofyear

```sql
DROP TABLE IF EXISTS dws.dws_trade_orders_week;
CREATE TABLE IF NOT EXISTS dws.dws_trade_orders_week(YEAR string COMMENT '年份',
                                                     WEEK string COMMENT '一年中的第几周',
                                                     week_cnt decimal COMMENT '周订单总笔数',
                                                     week_sum decimal COMMENT '周订单总额') COMMENT '周订单统计表';

INSERT OVERWRITE TABLE dws.dws_trade_orders_week
SELECT substr(day_dt, 0, 4) YEAR,
                            weekofyear(day_dt) WEEK,
                                               sum(day_cnt),
                                               sum(day_sum)
FROM dws.dws_trade_orders_day
GROUP BY substr(day_dt, 0, 4) YEAR,
                              weekofyear(day_dt) WEEK;

```

#### 2.5 统计2020年国家法定节假日、休息日、工作日的订单笔数、订单总额

创建日期信息维表：`dim_day_info` 并录入节假日信息数据（数据每年都不一样，需要国务院通知的公告，所以定期手动维护）

```sql
drop table if exists dim.dim_day_info;
create table if not exists dim.dim_day_info(
  day_dt string comment '日期',
  is_holidays int comment '节假日标识：0不是 1是',
  is_workday int comment '工作日标识 0不是 1是'
) comment '日期信息表';

-- 统计2020节假日的订单笔数，订单总额

SELECT nvl(sum(day_cnt), 0) nvl(sum(day_sum), 0)
FROM dws.dws_trade_orders_day A
LEFT JOIN dim.dim_day_info B ON A.day_dt = B.day_dt
WHERE B.is_holiday = 1;

-- 统计2020年休息日的订单笔数，订单总额

SELECT nvl(sum(day_cnt), 0) nvl(sum(day_sum), 0)
FROM dws.dws_trade_orders_day A
LEFT JOIN dim.dim_day_info B ON A.day_dt = B.day_dt
WHERE B.is_workday = 0;

-- 统计2020节工作日的订单笔数，订单总额

SELECT nvl(sum(day_cnt), 0) nvl(sum(day_sum), 0)
FROM dws.dws_trade_orders_day A
LEFT JOIN dim.dim_day_info B ON A.day_dt = B.day_dt
WHERE B.is_workday = 1;
```

### 5. 维表层：DIM（Dimension）

如果维表过多，也可针对维表设计单独一层，维表层主要包含两部分数据：

高基数维度数据：一般是用户资料表、商品资料表类似的资料表。数据量可能是千万级或者上亿级别。

低基数维度数据：一般是配置表，比如枚举值对应的中文含义，或者日期维表。数据量可能是个位数或者几千几万。

## 二、数仓建模方法

数仓建模在哪层建设呢？我们以维度建模为例，建模是在数据源层的下一层进行建设，在上节的分层架构中，就是在DW层进行数仓建模，所以DW层是数仓建设的核心层。

那数仓建模怎么建呢？其实数据仓库的建模方法有很多种，每一种建模方法代表了哲学上的一个观点，代表了一种归纳、概括世界的一种方法。常见的有 范式建模法、维度建模法、实体建模法等，每种方法从本质上将是从不同的角度看待业务中的问题。

### 1. 范式建模法（Third Normal Form，3NF）

范式建模法其实是我们在构建数据模型常用的一个方法，该方法的主要由 Inmon 所提倡，主要解决关系型数据库的数据存储，利用的一种技术层面上的方法。目前，我们在关系型数据库中的建模方法，大部分采用的是三范式建模法。

范式 是符合某一种级别的关系模式的集合。构造数据库必须遵循一定的规则，而在关系型数据库中这种规则就是范式，这一过程也被称为规范化。目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、Boyce-Codd范式（BCNF）、第四范式（4NF）和第五范式（5NF）。

在数据仓库的模型设计中，一般采用第三范式。一个符合第三范式的关系必须具有以下三个条件 :

- 每个属性值唯一，不具有多义性 ;
- 每个非主属性必须完全依赖于整个主键，而非主键的一部分 ;
- 每个非主属性不能依赖于其他关系中的属性，因为这样的话，这种属性应该归到其他关系中去。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zG329FOSxOPZhQuUCmKA72KZolxPz56MCL3tE9OLicj0GUPXVyuDlfFPIIbeyUjkZNjnVgGztu4azg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)范式建模

根据 Inmon 的观点，数据仓库模型的建设方法和业务系统的企业数据模型类似。在业务系统中，企业数据模型决定了数据的来源，而企业数据模型也分为两个层次，即主题域模型和逻辑模型。同样，主题域模型可以看成是业务模型的概念模型，而逻辑模型则是域模型在关系型数据库上的实例化。

### 2. 维度建模法（Dimensional Modeling）

维度模型是数据仓库领域另一位大师Ralph Kimall所倡导，他的《数据仓库工具箱》是数据仓库工程领域最流行的数仓建模经典。维度建模以分析决策的需求出发构建模型，构建的数据模型为分析需求服务，因此它重点解决用户如何更快速完成分析需求，同时还有较好的大规模复杂查询的响应性能。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zG329FOSxOPZhQuUCmKA72KTeGFOvRx1r2YkmYBVMkYje9ZyKzbXiaPhDEWUaibibGniaEESvibtmBTiaMQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)维度建模

典型的代表是我们比较熟知的星形模型（Star-schema），以及在一些特殊场景下适用的雪花模型（Snow-schema）。

维度建模中比较重要的概念就是 事实表（Fact table）和维度表（Dimension table）。其最简单的描述就是，按照事实表、维度表来构建数据仓库、数据集市。

### 3. 实体建模法（Entity Modeling）

实体建模法并不是数据仓库建模中常见的一个方法，它来源于哲学的一个流派。从哲学的意义上说，客观世界应该是可以细分的，客观世界应该可以分成由一个个实体，以及实体与实体之间的关系组成。那么我们在数据仓库的建模过程中完全可以引入这个抽象的方法，将整个业务也可以划分成一个个的实体，而每个实体之间的关系，以及针对这些关系的说明就是我们数据建模需要做的工作。

虽然实体法粗看起来好像有一些抽象，其实理解起来很容易。即我们可以将任何一个业务过程划分成 3 个部分，实体，事件，说明，如下图所示：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zG329FOSxOPZhQuUCmKA72KRMou9En6eoelD3cNWib1pUcznh3h5IHKv6IbIebpjyHB3pm1RRrZX6Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)实体建模

上图表述的是一个抽象的含义，如果我们描述一个简单的事实：“小明开车去学校上学”。以这个业务事实为例，我们可以把“小明”，“学校”看成是一个实体，“上学”描述的是一个业务过程，我们在这里可以抽象为一个具体“事件”，而“开车去”则可以看成是事件“上学”的一个说明。

## 三、维度建模详解

目前在互联网公司最常用的建模方法就是维度建模，我们将重点讲解！

维度建模是专门应用于分析型数据库、数据仓库、数据集市建模的方法。数据集市可以理解为是一种"小型数据仓库"。

我们先不着急开始维度建模，先来了解下维度建模中表的类型和维度建模的模式之后再开始建模，这样能够让我们深刻理解！

### 1. 维度建模中表的类型

维度建模分为两种表：事实表和维度表：

1. 事实表：必然存在的一些数据，像采集的日志文件，订单表，都可以作为事实表 。
   特征：是一堆主键的集合，每个主键对应维度表中的一条记录，客观存在的，根据主题确定出需要使用的数据
2. 维度表：维度就是所分析的数据的一个量，维度表就是以合适的角度来创建的表，分析问题的一个角度：时间、地域、终端、用户等角度

#### 1. 事实表

发生在现实世界中的操作型事件，其所产生的可度量数值，存储在事实表中。从最低的粒度级别来看，事实表行对应一个度量事件，反之亦然。

事实表表示对分析主题的度量。比如一次购买行为我们就可以理解为是一个事实。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zG329FOSxOPZhQuUCmKA72K29yCYe9FxjFsgG3QVUWTdnQSSZTRBvr50G8Ezf39jmz9x9nCefBmpw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)事实与维度

图中的订单表就是一个事实表，你可以理解他就是在现实中发生的一次操作型事件，我们每完成一个订单，就会在订单中增加一条记录。事实表的特征：表里没有存放实际的内容，他是一堆主键的集合，这些ID分别能对应到维度表中的一条记录。事实表包含了与各维度表相关联的外键，可与维度表关联。事实表的度量通常是数值类型，且记录数会不断增加，表数据规模迅速增长。

明细表（宽表）：

事实表的数据中，有些属性共同组成了一个字段（糅合在一起），比如年月日时分秒构成了时间,当需要根据某一属性进行分组统计的时候，需要截取拼接之类的操作，效率极低。如：

|     local_time      |
| :-----------------: |
| 2021-03-18 06:31:42 |

为了分析方便，可以事实表中的一个字段切割提取多个属性出来构成新的字段，因为字段变多了，所以称为宽表，原来的成为窄表。

将上述的`local_time`字段扩展为如下6个字段：

| year | month | day  | hour |  m   |  s   |
| :--: | :---: | :--: | :--: | :--: | :--: |
| 2021 |  03   |  18  |  06  |  31  |  42  |

又因为宽表的信息更加清晰明细，所以也可以称之为明细表。

事实表种类

事实表分为以下6类：

1. 事务事实表
2. 周期快照事实表
3. 累积快照事实表
4. 无事实的事实表
5. 聚集事实表
6. 合并事实表

简单解释下每种表的概念：

- 事务事实表

表中的一行对应空间或时间上某点的度量事件。就是一行数据中必须有度量字段，什么是度量，就是指标，比如说销售金额，销售数量等这些可加的或者半可加就是度量值。另一点就是事务事实表都包含一个与维度表关联的外键。并且度量值必须和事务粒度保持一致。

- 周期快照事实表

顾名思义，周期事实表就是每行都带有时间值字段，代表周期，通常时间值都是标准周期，如某一天，某周，某月等。粒度是周期，而不是个体的事务，也就是说一个周期快照事实表中数据可以是多个事实，但是它们都属于某个周期内。

- 累计快照事实表

周期快照事实表是单个周期内数据，而累计快照事实表是由多个周期数据组成，每行汇总了过程开始到结束之间的度量。每行数据相当于管道或工作流，有事件的起点，过程，终点，并且每个关键步骤都包含日期字段。如订单数据，累计快照事实表的一行就是一个订单，当订单产生时插入一行，当订单发生变化时，这行就被修改。

- 无事实的事实表

我们以上讨论的事实表度量都是数字化的，当然实际应用中绝大多数都是数字化的度量，但是也可能会有少量的没有数字化的值但是还很有价值的字段，无事实的事实表就是为这种数据准备的，利用这种事实表可以分析发生了什么。

- 聚集事实表

聚集，就是对原子粒度的数据进行简单的聚合操作，目的就是为了提高查询性能。如我们需求是查询全国所有门店的总销售额，我们原子粒度的事实表中每行是每个分店每个商品的销售额，聚集事实表就可以先聚合每个分店的总销售额，这样汇总所有门店的销售额时计算的数据量就会小很多。

- 合并事实表

这种事实表遵循一个原则，就是相同粒度，数据可以来自多个过程，但是只要它们属于相同粒度，就可以合并为一个事实表，这类事实表特别适合经常需要共同分析的多过程度量。

#### 2．维度表

每个维度表都包含单一的主键列。维度表的主键可以作为与之关联的任何事实表的外键，当然，维度表行的描述环境应与事实表行完全对应。维度表通常比较宽，是扁平型非规范表，包含大量的低粒度的文本属性。

维度表示你要对数据进行分析时所用的一个量，比如你要分析产品销售情况， 你可以选择按类别来进行分析，或按区域来分析。每个类别就构成一个维度。上图中的用户表、商家表、时间表这些都属于维度表，这些表都有一个唯一的主键，然后在表中存放了详细的数据信息。

总的说来，在数据仓库中不需要严格遵守规范化设计原则。因为数据仓库的主导功能就是面向分析，以查询为主，不涉及数据更新操作。事实表的设计是以能够正确记录历史信息为准则，维度表的设计是以能够以合适的角度来聚合主题内容为准则。

- 维度表结构

维度表谨记一条原则，包含单一主键列，但有时因业务复杂，也可能出现联合主键，请尽量避免，如果无法避免，也要确保必须是单一的，这很重要，如果维表主键不是单一，和事实表关联时会出现数据发散，导致最后结果可能出现错误。

维度表通常比较宽，包含大量的低粒度的文本属性。

- 跨表钻取

跨表钻取意思是当每个查询的行头都包含相同的一致性属性时，使不同的查询能够针对两个或更多的事实表进行查询

钻取可以改变维的层次，变换分析的粒度。它包括上钻/下钻：

上钻（roll-up）：上卷是沿着维的层次向上聚集汇总数据。例如，对产品销售数据，沿着时间维上卷，可以求出所有产品在所有地区每月（或季度或年或全部）的销售额。

下钻（drill-down）：下钻是上钻的逆操作，它是沿着维的层次向下，查看更详细的数据。

- 退化维度

退化维度就是将维度退回到事实表中。因为有时维度除了主键没有其他内容，虽然也是合法维度键，但是一般都会退回到事实表中，减少关联次数，提高查询性能

- 多层次维度

多数维度包含不止一个自然层次，如日期维度可以从天的层次到周到月到年的层次。所以在有些情况下，在同一维度中存在不同的层次。

- 维度表空值属性

当给定维度行没有被全部填充时，或者当存在属性没有被应用到所有维度行时，将产生空值维度属性。上述两种情况，推荐采用描述性字符串代替空值，如使用 unknown 或 not applicable 替换空值。

- 日历日期维度

在日期维度表中，主键的设置不要使用顺序生成的id来表示，可以使用更有意义的数据表示，比如将年月日合并起来表示，即YYYYMMDD，或者更加详细的精度。

### 2. 维度建模三种模式

#### 1. 星型模式

星形模式(Star Schema)是最常用的维度建模方式。星型模式是以事实表为中心，所有的维度表直接连接在事实表上，像星星一样。星形模式的维度建模由一个事实表和一组维表成，且具有以下特点：a. 维表只和事实表关联，维表之间没有关联；b. 每个维表主键为单列，且该主键放置在事实表中，作为两边连接的外键；c. 以事实表为核心，维表围绕核心呈星形分布；![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zG329FOSxOPZhQuUCmKA72KcpPYr1MWibZtibEvPLoUFt2DtCBXe90gHZpHbY9Q1V5X3BDN2EajBRpQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### 2. 雪花模式

雪花模式(Snowflake Schema)是对星形模式的扩展。雪花模式的维度表可以拥有其他维度表的，虽然这种模型相比星型更规范一些，但是由于这种模型不太容易理解，维护成本比较高，而且性能方面需要关联多层维表，性能也比星型模型要低。所以一般不是很常用

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zG329FOSxOPZhQuUCmKA72KzcibOBfEjTib8icElvuNUy33w54HiaouC22psquTKtibM7tTFKT1IyLvL8g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)雪花模式

#### 3. 星座模式

星座模式是星型模式延伸而来，星型模式是基于一张事实表的，而星座模式是基于多张事实表的，而且共享维度信息。前面介绍的两种维度建模方法都是多维表对应单事实表，但在很多时候维度空间内的事实表不止一个，而一个维表也可能被多个事实表用到。在业务发展后期，绝大部分维度建模都采用的是星座模式。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zG329FOSxOPZhQuUCmKA72K6hyibaznlSKibvncfM1ASvOH8RfZBiaMlXqma9TPHcZrianoCP5AOia0a2g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)星座模型

### 3. 维度建模过程

我们知道维度建模的表类型有事实表，维度表；模式有星形模型，雪花模型，星座模型这些概念了，但是实际业务中，给了我们一堆数据，我们怎么拿这些数据进行数仓建设呢，数仓工具箱作者根据自身60多年的实际业务经验，给我们总结了如下四步，请务必记住！

数仓工具箱中的维度建模四步走：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zG329FOSxOPZhQuUCmKA72KIsWmqHczrG2Y4ud3RoF7OsAibH3984pz8lPpqZqSLuSn7vXLIicaIMEA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)维度建模四步走

请牢记以上四步，不管什么业务，就按照这个步骤来，顺序不要搞乱，因为这四步是环环相扣，步步相连。下面详细拆解下每个步骤怎么做

1、选择业务过程
维度建模是紧贴业务的，所以必须以业务为根基进行建模，那么选择业务过程，顾名思义就是在整个业务流程中选取我们需要建模的业务，根据运营提供的需求及日后的易扩展性等进行选择业务。比如商城，整个商城流程分为商家端，用户端，平台端，运营需求是总订单量，订单人数，及用户的购买情况等，我们选择业务过程就选择用户端的数据，商家及平台端暂不考虑。业务选择非常重要，因为后面所有的步骤都是基于此业务数据展开的。

2、声明粒度
先举个例子：对于用户来说，一个用户有一个身份证号，一个户籍地址，多个手机号，多张银行卡，那么与用户粒度相同的粒度属性有身份证粒度，户籍地址粒度，比用户粒度更细的粒度有手机号粒度，银行卡粒度，存在一对一的关系就是相同粒度。为什么要提相同粒度呢，因为维度建模中要求我们，在同一事实表中，必须具有相同的粒度，同一事实表中不要混用多种不同的粒度，不同的粒度数据建立不同的事实表。并且从给定的业务过程获取数据时，强烈建议从关注原子粒度开始设计，也就是从最细粒度开始，因为原子粒度能够承受无法预期的用户查询。但是上卷汇总粒度对查询性能的提升很重要的，所以对于有明确需求的数据，我们建立针对需求的上卷汇总粒度，对需求不明朗的数据我们建立原子粒度。

3、确认维度
维度表是作为业务分析的入口和描述性标识，所以也被称为数据仓库的“灵魂”。在一堆的数据中怎么确认哪些是维度属性呢，如果该列是对具体值的描述，是一个文本或常量，某一约束和行标识的参与者，此时该属性往往是维度属性，数仓工具箱中告诉我们牢牢掌握事实表的粒度，就能将所有可能存在的维度区分开，并且要确保维度表中不能出现重复数据，应使维度主键唯一

4、确认事实
事实表是用来度量的，基本上都以数量值表示，事实表中的每行对应一个度量，每行中的数据是一个特定级别的细节数据，称为粒度。维度建模的核心原则之一是同一事实表中的所有度量必须具有相同的粒度。这样能确保不会出现重复计算度量的问题。有时候往往不能确定该列数据是事实属性还是维度属性。记住最实用的事实就是数值类型和可加类事实。所以可以通过分析该列是否是一种包含多个值并作为计算的参与者的度量，这种情况下该列往往是事实。

# 离线数仓建设理论


### 前言

> ### 技术是为业务服务的，业务是为公司创造价值的，离开业务的技术是无意义的。

## 一、业务介绍

需要针对不同需求的用户开发不同的产品，所以公司内部有很多条业务线，但是对于数据部门来说，所有业务线的数据都是数据源。对数据的划分不只是根据业务进行，而是结合数据的属性。

## 二、早期规划

之前开发是不同业务线对应不同的数据团队，每个数据团队互不干扰，这种模式比较简单，只针对自己的业务线进行数仓建设及报表开发即可。

但是随着业务的发展，频繁迭代及跨部门的垂直业务单元越来越多，业务之间的出现耦合情况，这时再采用这种烟囱式开发就出现了问题：

例如权限问题，公司对数据管理比较严格，不同的数据开发组没有权限共享数据，需要其他业务线的数据权限需要上报审批，比较耽误时间；

还有重复开发问题，不同业务线会出现相同的报表需求，如果每个业务方都开发各自的报表，太浪费资源。

所以对于数据开发而言，需要对各个业务线的数据进行统一管理，所以就有了数据中台的出现。

## 三、数据中台

我认为数据中台是根据每个公司具体的业务需求而搭建的，不同的业务，对中台的理解有所不同。

公司内部开发的敏捷数据中台，主要从数据技术和计算能力的复用，到数据资产和数据服务的复用，数据中台以更大价值带宽，快准精让数据直接赋能业务。提供一个统一化的管理，打破数据孤岛，追溯数据血缘，实现自助化及高复用度。

如下所示：

![03.数仓建设之离线数仓建设实战01.png](https://lilinchao.com/usr/uploads/2022/09/833665135.png)

以上解释比较抽象，我们以实际项目开发来看下数据中台的便利性。

比如我们之前做报表开发流程，首先是要数据采集，不同的数据源通过sqoop等工具采集到大数据平台，然后进行数仓搭建，最后产出报表数据，放到可视化系统展示，最终把整个流程写成脚本放到调度平台进行自动化执行。

而有了数据中台之后就不需要那么繁琐，直接进行数仓搭建，产生报表即可，无需将精力过多放在数据源、可视化展示及调度。并且可以直观的查看数据血缘关系，计算表之间血缘。像下面图中，表之间的依赖关系很明确：

![03.数仓建设之离线数仓建设实战02.png](https://lilinchao.com/usr/uploads/2022/09/1690138845.png)

另一点，数据中台的异构数据系统可以非常简单的进行关联查询，比如hive的表关联MySQL的表。可透明屏蔽异构数据系统异构交互方式，轻松实现跨异构数据系统透明混算。

异构数据系统原理是数据中台提供虚拟表到物理表之间的映射，终端用户无需关心数据的物理存放位置和底层数据源的特性，可直接操作数据，体验类似操作一个虚拟数据库。

数据中台额外集成可视化展示，提供一站式数据可视化解决方案，支持JDBC数据源和CSV文件上传，支持基于数据模型拖拽智能生成可视化组件，大屏展示自适应不同大小屏幕。

调度系统是公司内部自写集成到数据中台的，在编写完sql语句之后可以直接进行调度。

## 四、数仓建设

到这才真正到数仓建设，为什么前面我要占那么大篇幅去介绍公司业务及所使用的数据中台系统，因为下面的数仓建设是根据公司的业务发展及现有的数据中台进行，数仓的建设离不开公司的业务。

数仓建设核心思想：从设计、开发、部署和使用层面，避免重复建设和指标冗余建设，从而保障数据口径的规范和统一，最终实现数据资产全链路关联、提供标准数据输出以及建立统一的数据公共层。有了核心思想，那怎么开始数仓建设，有句话说数仓建设者即是技术专家，也是大半个业务专家，所以采用的方式就是需求推动数据建设，并且因为数据中台，所以各业务知识体系比较集中，各业务数据不再分散，加快了数仓建设速度。

数仓建设主要从两个方面进行，模型和规范，所有业务进行统一化。

1）模型

所有业务采用统一的模型体系，从而降低研发成本，增强指标复用，并且能保证数据口径的统一。

2）模型分层

结合公司业务，后期新增需求较多，所以分层不宜过多，并且需要清晰明确各层职责，要保证数据层的稳定又要屏蔽对下游影响，所以采用如下分层结构：

![03.数仓建设之离线数仓建设实战03.png](https://lilinchao.com/usr/uploads/2022/09/3855029187.png)

3）数据流向

遵循模型开发时分层结构，数据从 `ods -> dw -> dm ->app` 这样正向流动，可以防止因数据引用不规范而造成数据链路混乱及SLA时效难保障等问题，同时保证血缘关系简洁化，能够轻易追踪数据流向。在开发时应避免以下情况出现：

- 数据引用链路不正确，如 `ods -> dm ->app` ，出现这种情况说明明细层没有完全覆盖数据；如 `ods -> dw -> app` ，说明轻度汇总层主题划分未覆盖全 。减少跨层引用，才能提高中间表的复用度。理想的数仓模型设计应当具备：数据模型可复⽤，完善且规范。
- 尽量避免一层的表生成当前层的表，如dw层表生成dw层表，这样会影响ETL效率。
- 禁止出现反向依赖，如dw表依赖于dm表。

4）规范

①表命名规范

- 对于ods、dm、app层表名：`类型_主题_表含义`，如：`dm_xxsh_user`
- 对于dw层表名：`类型_主题_维度_表含义`，如：`dw_xxsh_fact_users`（事实表）、`dw_xxsh_dim_city`（维度表）

②字段命名规范

构建词根，词根是维度和指标管理的基础，划分为普通词根与专有词根

- 普通词根：描述事物的最小单元体，如：sex-性别。
- 专有词根：具备行业专属或公司内部规定的描述体，如：xxsh-公司内部对某个产品的称呼。

③脚本命名规范

脚本名称：`脚本类型.脚本功用.[库名].脚本名称`，如 `hive.hive.dm.dm_xxsh_users`

脚本类型主要分为以下三类：

- 常规Hive sql：hive
- 自定义shell脚本：sh
- 自定义Python脚本：python

④脚本内容规范

```shell
#变量的定义要符合python的语法要求
#指定任务负责人
owner = "zhangsan@xxx.com"
#脚本存放目录/opt/xxx
#脚本名称 hive.hive.dm.dm_xxsh_users
#source用来标识上游依赖表，一个任务如果有多个上游表，都需要写进去
#(xxx_name 是需要改动的，其余不需要改)
source = {
        "table_name": {
        "db": "db_name",
        "table": "table_name"
        }
}
#如source，但是每个任务target只有一张表
target = {
        "db_table": {
                "host": "hive",
                "db": "db_name",
                "table": "table_name"
        }
}
#变量列表
#$now
#$now.date 常用，格式示例：2020-12-11


task = '''
写sql代码
'''

```

## 五、数据层具体实现

使用四张图说明每层的具体实现：

1）数据源层ODS

![03.数仓建设之离线数仓建设实战04.png](https://lilinchao.com/usr/uploads/2022/09/489554476.png)

数据源层主要将各个业务数据导入到大数据平台，作为业务数据的快照存储。

2）数据明细层DW

![03.数仓建设之离线数仓建设实战05.png](https://lilinchao.com/usr/uploads/2022/09/190699163.png)

事实表中的每行对应一个度量，每行中的数据是一个特定级别的细节数据，称为粒度。维度建模的核心原则之一是同一事实表中的所有度量必须具有相同的粒度。这样能确保不会出现重复计算度量的问题。

维度表一般都是单一主键，少数是联合主键，注意维度表不要出现重复数据，否则和事实表关联会出现数据发散问题。

有时候往往不能确定该列数据是事实属性还是维度属性。记住最实用的事实就是数值类型和可加类事实。所以可以通过分析该列是否是一种包含多个值并作为计算的参与者的度量，这种情况下该列往往是事实；如果该列是对具体值的描述，是一个文本或常量，某一约束和行标识的参与者，此时该属性往往是维度属性。但是还是要结合业务进行最终判断是维度还是事实。

3）数据轻度汇总层DM

![03.数仓建设之离线数仓建设实战06.png](https://lilinchao.com/usr/uploads/2022/09/3263953617.png)

此层命名为轻汇总层，就代表这一层已经开始对数据进行汇总，但是不是完全汇总，只是对相同粒度的数据进行关联汇总，不同粒度但是有关系的数据也可进行汇总，此时需要将粒度通过聚合等操作进行统一。

4）数据应用层APP

![03.数仓建设之离线数仓建设实战07.png](https://lilinchao.com/usr/uploads/2022/09/264370834.png)

数据应用层的表就是提供给用户使用的，数仓建设到此就接近尾声了，接下来就根据不同的需求进行不同的取数，如直接进行报表展示，或提供给数据分析的同事所需的数据，或其他的业务支撑。

## 六、总结

一张图总结下数据仓库的构建整体流程：

![03.数仓建设之离线数仓建设实战08.png](https://lilinchao.com/usr/uploads/2022/09/2923433265.png)

## 七、实际生产中注意事项

生产环境中操作不能像我们自己测试时那样随意，一不小心都可能造成生产事故。所以每步操作都要十分小心，需全神贯注，管好大脑管住右手。

仅列出以下但不限于以下的注意事项：

- 请勿操作自己管理及授权表之外的其它库表；
- 未经授权，请勿操作生产环境中其他人的脚本及文件；
- 在修改生产环境脚本前，请务必自行备份到本地；
- 请确认自己的修改操作能迅速回滚；
- 生产环境中表名及字段等所有命名请遵循命名规则。



# 企业级离线数据仓库构建方法论

## 一、全域数仓早期面临的问题

- 1、95% 的表建在同一个数据库

\- xxx 库 3000+ 张表,表逻辑层次不清晰

- 2、表定义不规范，标准不统一

-表命名形式多样化，对应数据层级不清晰

-字段采用关键字命名：”from”、”date”

-时间分区形式不统一：yyyyMMdd、yyyy-MM-dd

-默认以 textfile 格式存储，磁盘空间使用不合理

- 3、数据建模意识差，缺乏对业务的高度抽象

-数据报表生产直接依赖底层表

-数据、主题域划分不清晰

-缺乏数据沉淀，重复计算浪费资源

-数据RD在业务分工责任不明确，信息入口不能收拢、统一

- 4、烟囱式开发，产生数据孤岛

-数据调研投入不足：业务、需求、数据库

-指标定义混乱，重复开发、数据冗余

- 5、各个业务团队各自建数仓

-风格多样化

-管理维护成本高

## 二、全域数仓目标期望

- 1、可落地、可扩展，满足未来 2-3 年左右千万日活的业务体量
- 2、统一的数据仓库开发标准、规范
- 3、开放的数据存储、建模、计算能力

全域数仓需求分析及构建之道



![图片](https://mmbiz.qpic.cn/mmbiz_png/sgic3ibOqWyE5RMYQPc5gos72c7Qr0vWE2GCcibadNtXJE1pMDoI3o87YAZ4mgFyl3jl1fa9gOTrxWVt9cc4ghRow/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

企业级全域数仓构建

****

Lambda架构

![图片](https://mmbiz.qpic.cn/mmbiz_png/sgic3ibOqWyE5RMYQPc5gos72c7Qr0vWE2M4n1VSOB2Wibhl519TtuaQFRrA3icG06ibVfVzY1DegBSAXxY8zvWH1zA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

数据平台架构

![图片](https://mmbiz.qpic.cn/mmbiz_png/sgic3ibOqWyE5RMYQPc5gos72c7Qr0vWE2aaBaDApdWvNPWybiapaZrsT9c9oQrkiblfgfiaHdicJic0tQoq9fo5nwLcw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 三、大数据的技术分类

``1、存储``

`mysql  redis  hbase  es` 

`2、计算`

`mapreduce  spark  flink` 

`3、服务协调`

`zookeeper etcd dubbo springcloud nacos consul` 

`4、资源调度`

`yarn mesos docker+k8s` 

`5、数据采集`

`flume sqoop datax canal maxwell logstash filebeat seatunnel`

`6、元数据治理`

`atlas`

`7、部署  运维  监控`

`cdh hdp` 

`8、任务调度`

`azkaban oozie dophinschedler airflow` 

`9、自助报表分析`

`davinci  superset`

`10、OLAP`

``doris clickhouse kudu druid ....``

## 四、数据开发流程

![图片](https://mmbiz.qpic.cn/mmbiz_png/sgic3ibOqWyE5RMYQPc5gos72c7Qr0vWE24siayJoH7EysF09Ut6iaXVYziaVU8pv6AoktbXMEmr77TfcLwP5lZDhQw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 五、数仓分层架构

![图片](https://mmbiz.qpic.cn/mmbiz_png/sgic3ibOqWyE5RMYQPc5gos72c7Qr0vWE2QI2SbmzzaaES0a5iar018YdsCia7xnTW8ZNV5lSF85aHM5s6I3HKsWXg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

数据来源(业务) ---> 数据仓库> 数据应用

可维护性，可读性，可扩展性

## 六、分层划分与定义

ODS：Operational Data Store 原始数据层，主要包含业务数据库快照数据(rawdb)、运营埋点数据

(rawdata)、其他业务等数据。

TMP：临时层， 数据处理的辅助处理层，服务于 DWD、DWS 层，主要是一些临时存储的数据，根据实际情况选择创建与不创建，包括：计算任务的中间结果数据。

DIM：维度数据层，主要包含一些业务维度数据。实例：地区表，订单状态，支付方式，审批状态，商 品分类，商品型号，渠道类型、终端类型、广告位、红包计划等

DWD：Data Warehouse Detail，存储经过标准规范化处理（即数据清洗）后的运营数据，是基础事实数据明细层。实例：行为事件明细表、MySQL 各业务数据经过 ETL 处理后的实体表。

DWS：Data Warehouse Service，数据服务主题层或者宽表层，按数据、业务专题进行划分，支持OLAP 分析、数据分发等，其信息主要来源于 DWD 或 TMP 层汇总数据。实例：新激活用户表、日活表、历史激活用户表

ADS：Application Database Service，应用数据层, 面向具体应用的表，要创建在这层，可导入 HBase

或 MySQL 等使用。实例：按季、月、周、天、小时等粒度计算汇总的结果存入 MySQL、HBase的报表

MDW：Meta Data Warehouse 元数据信息层，元数据机制主要支持以下五类系统管理功能：

1、描述哪些数据在数据仓库中;

2、定义要进入数据仓库中的数据和从数据仓库中产生的数据;

3、记录根据业务事件发生而随之进行的数据抽取工作时间安排;

4、记录并检测系统数据一致性的要求和执行情况;

5、衡量数据质量。

## 七、数据库表命名规范

| 业务规范层 | 数据库名称                         | 数据库释义                                       | 物理表命名规范                                               | 数据存储格式 |
| ---------- | ---------------------------------- | ------------------------------------------------ | ------------------------------------------------------------ | ------------ |
| ODS        | hdp_公司英文简称_ods_global        | 从公司各业务MySQL 表同步的快照信息和运营埋点数据 | 埋点日志：ods_log_{埋点说明}_{更新方式}_{时间粒度}运营数据库：ods_{业务数据库表}_{更新方式}_{时间粒度} | Text         |
| DWD        | hdp_公司英文简称_dwd_global        | 包含公司各业务经过 ETL 后的基础事实明细表        | 埋点日志：dwd_log_业务过程_更新方式_时间粒度运营数据库：dwd_{数据库类型（mysql\hbase\wtable\redis）}_{业务过程}_{更新方式}_{时间粒度}多数据源：dwd_{业务过程}_{更新方式}_{时间粒度} | Parquet      |
| DWS        | hdp_公司英文简称_dws_global        | 按数据、业务专题进行划分的轻度汇总数据           | dws_{业务主题域}_{业务过程}_{更新方式}_{时间粒度}            | Parquet      |
| DIM        | hdp_公司英文简称_dim_global        | 业务维度相关的字典数据                           | dim_{维度类型（cate\city\channel\group）}_{更新方式}_{时间粒度} | Text         |
| TMP        | hdp_公司英文简称_tmp_global        | 存放数据计算过程中的临时结果表                   | tmp_{数据层类型(dwd\dws\ads)_{业务过程描述}                  | Parquet      |
| ADS        | hdp_公司英文简称_ads_global        | 存放面向各业务应用分析的通用结果表               | ads_{数据主题域}_{业务过程描述}_{更新方式}_{时间粒度}        | Text\Parquet |
| ADS        | hdp_公司英文简称_ads_{部门/产品线} | 业务方个性化应用数据表                           | ads_{数据主题域}_{业务过程描述}_{更新方式}_{时间粒度}        | Text\Parquet |

## 八、业务主题域

重点注意 主题域名称 和 对应的 英文名称，目的是为了统一，比如用户名：username uname name

| 主题域        | 子域           |
| ---------- | ------------ |
| 用户：user    |              |
| 商品：info    |              |
|            | 属性：param     |
| 交易：trade   |              |
|            | 订单：order     |
|            | 优惠券：coupon   |
|            | 回收：recycle   |
|            | 租赁：lease     |
|            | 维修：repair    |
| 流量：traﬃc   |              |
|            | 用户行为：ub      |
|            | 归因：attribute |
|            | 直播：live      |
| 供应链：scm    |              |
|            | 物流：logistics |
|            | 采购：pur       |
|            | 仓储：store     |
| 营销：market  |              |
|            | 内容：content   |
|            | 活动：activity  |
| 服务：service |              |
|            | 客服：csc       |
|            | 售后：afs       |
|            | 鉴定：auth      |
|            | 质检：qc        |
| 商业广告：biz   |              |
|            | 线索：clue      |
|            | 客户：customer  |
|            | 充值：recharge  |
|            | 账务：account   |

| 主题域        | 子域            |
| ---------- | ------------- |
|            | 活动：activity   |
|            | 推广：promote    |
|            | 广告：ad         |
|            | 增值产品：valueadd |
|            | 用户：user       |
| 渠道：channel |               |
| 地址：address |               |
| 财务：ﬁnance  |               |
| 风控：spam    |               |
| 竞品：compete |               |

ODS层，按照业务主题域进行划分管理

ADS层，按照数据主题进行划分管理

数据主题域

用户增长：activity

商品发布：addinfo

交易链路：trade

私信互动：social

收入：income

推送：push

流量：traﬃc

更新方式命名规范

增量：inc

全量：full

表名时间粒度规范

分区表

小时(hour)：1h 天(day)：1d

周(week)：1w 月(month)：1m

季度(quarter)：1q 年(year)：1y

分区字段: 日期分区统一命名为：dt，格式：yyyy-MM-dd or yyyy-MM or yyyy

注意：单张表的分区每日新增不宜超过200个，分区太多导致文件分布太细，对集群 namenode 压力过大

非分区表：统一后缀加上：_0p

| 非分区表 |          |                                          |                  |
| ---- | -------- | ---------------------------------------- | ---------------- |
|      | 增量表      | xxx_inc_1h_0p xxx_inc_1d_0p xxx_inc_1w_0p...... | 无dt字段            |
|      | 全量表      | xxx_full_1h_0p xxx_full_1d_0p xxx_full_1w_0p...... | 无dt字段            |
| 分区表  |          |                                          |                  |
|      | 增量&小时 更新 | xxx_inc_1h                               | dt=yyyy-MM-dd-HH |
|      | 全量&小时 更新 | xxx_full_1h                              | dt=yyyy-MM-dd    |

xxx_inc_1h_0p：分层_主题域_业务过程_更新方式_时间粒度/分区信息

dwd_goods_new_inc_1d 

dwd_goods_new_full_0p 

dwd_goods_new_inc_1y

字段命名规范

日期字段：<业务主体>_date

时间字段：<业务主体>_time

属性字段：属性自身英文单词；如：status

id 字段：<标识主体>_id;

标识字段：is_<标识主体>；如：is_true

指标字段：时间周期+修饰词+原子指标 如：近30天优品帮卖支付订单数 英：ypbm_payorder_1m

计次字段：<计数主体>_pv；如：visit_pv

排重计数字段：<计数主体>_uv；如：visit_uv

价格字段：<业务主体>_price；如：pay_price

来源字段：<业务主体>_source；如：order_source

比例字段：<业务主体>_rate；如：gmv_yoy_rate

调度任务开发规范

1、任务命名规范

任务命名格式：{输出表名}-任务描述 或者 任务描述-{输出表名}

2、开发规范

01、表和列的注释是否有确定，复杂计算逻辑是否有注释，贵精不贵多

02、任务是否支持多次重跑而输出不变，不能有 insert into 语句

​       insert overwrite .... into table partition(...)

03 、04 等等 此处省略号

企业级数据采集平台架构设计

![图片](https://mmbiz.qpic.cn/mmbiz_png/sgic3ibOqWyE5RMYQPc5gos72c7Qr0vWE2ic3f0Lm5VzFZ8M19iaL8yL38S5astWEicM3vNibC0XPQfqibkKWX3lttXdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 九、企业级数仓平台资源评估

服务器配置

| 内存（GB） | cpu      | 磁盘 (容量x个数) | 网络带宽 |
| ---------- | -------- | ---------------- | -------- |
| 128        | 8Core x2 | SATA：7TB x 12   | 万兆     |

数据规模(1副本)

| 每天增量（TB） | 每天记录数（条） | 累计数据量（PB） | 保留周期(年) | hadoop节点 | 任务运行数量 |
| -------------- | ---------------- | ---------------- | ------------ | ---------- | ------------ |
| 20+            | 400+亿           | 15+              | >=3          | 700+       | 10000+/天    |

## 十、数据治理

数据治理模块主要包括：

- 1、元数据管理
- 2、数据血缘
- 3、数据安全
- 4、数据质量
- 5、报表生命周期管理
- 6、数据工具监控
- 7、数据报表监控
- 8、数据平台菜单访问量
- 9、监控统计项过期清理

![图片](https://mmbiz.qpic.cn/mmbiz_png/sgic3ibOqWyE5RMYQPc5gos72c7Qr0vWE2qj4H9uyicyllLiatV2HluibYre9nBmU89UFkNLAofcjCuAyCoABe2jP1A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



数据治理平台化、产品化、工具化-Web UI界面-最高境界

# 基于Hive数据仓库的标签画像实战！

## 一、Hive数据仓库

建立用户画像首先需要建立数据仓库，用于存储用户标签数据。Hive是基于Hadoop的数据仓库工具，依赖于HDFS存储数据，提供的SQL语言可以查询存储在HDFS中的数据。开发时一般使用Hive作为数据仓库，存储标签和用户特征库等相关数据。

"数据仓库之父" W.H.Inmon 在《Building the Data Warehouse》（中文版《数据仓库（原书第4版）》）一书中定义数据仓库是"一个面向主题的、集成的、非易失的、随时间变化的、用来支持管理人员决策的数据集合"。

- `面向主题`: 业务数据库中的数据主要针对事务处理，各个业务系统之间是相互分离的，而数据仓库中的数据是按照一定主题进行组织的。
- `集成`:数据仓库中存储的数据是从业务数据库中提取出来的，但并不是对原有数据的简单复制，而是经过了抽取、清理、转换（ETL）等工作。业务数据库记录的是每一项业务处理的流水账。这些数据不适合进行分析处理，进入数据仓库之前需要经过一系列计算，同时抛弃一些无关分析处理的数据。
- `非易失`:业务数据库中一般只存储短期数据，因此其数据是不稳定的，记录的是系统中数据变化的瞬态。数据仓库中的数据大多表示过去某一时刻的数据，主要用于查询、分析，不像业务系统中的数据库一样经常修改，一般数据仓库构建完成后主要用于访问，不进行修改和删除。
- `随时间变化`:数据仓库关注的是历史数据，按时间顺序定期从业务库和日志库里面载入新的数据进行追加，带有时间属性。

数据抽取到数据仓库的流程如下图所示。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG0RCnyKsiaMAiaiaS5iaB3fWibs92GI7ufJnQYTz8eqFoFibHheI1U0S0IxWCg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

在数据仓库建模的过程中，主要涉及事实表和维度表的建模开发：

事实表主要围绕业务过程设计，就应用场景来看主要包括事务事实表，周期快照事实表和累计快照事实表:

- `事务事实表`：用于描述业务过程，按业务过程的单一性或多业务过程可进一步分为单事务事实表和多事务事实表。其中单事务事实表分别记录每个业务过程，如下单业务记入下单事实表，支付业务记入支付事实表。多事务事实表在同一个表中包含了不同业务过程，如下单、支付、签收等业务过程记录在一张表中，通过新增字段来判断属于哪一个业务过程。当不同业务过程有着相似性时可考虑将多业务过程放到多事务事实表中。
- `周期快照事实表`:在一个确定的时间间隔内对业务状态进行度量。例如查看一个用户的近1年付款金额、近1年购物次数、近30日登录天数等。
- `累计快照事实表`:用于查看不同事件之间的时间间隔，例如分析用户从购买到支付的时长、从下单到订单完结的时长等。一般适用于有明确时间周期的业务过程。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG0INSZIrqSD4zz6g0faSgkpF72nZ67y03iaD6HP5XellzB90eBkg9xOQA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

维度表主要用于对事实属性的各个方面描述，例如，商品维度包括商品的价格、折扣、品牌、原厂家、型号等方面信息。维度表开发的过程中，经常会遇到维度缓慢变化的情况，对于缓慢变化维一般会采用：①重写维度值，对历史数据进行覆盖；②保留多条记录，通过插入维度列字段加以区分；③开发日期分区表，每日分区数据记录当日维度的属性；④开发拉链表按时间变化进行全量存储等方式进行处理。

在画像系统中主要使用Hive作为数据仓库，开发相应的维度表和事实表来存储标签、人群、应用到服务层的相关数据。

## 二、分区存储

如果将用户标签开发成一张大的宽表，在这张宽表下放几十种类型标签，那么每天该画像宽表的ETL作业将会花费很长时间，而且不便于向这张宽表中新增标签类型。

要解决这种ETL花费时间较长的问题，可以从以下几个方面着手：

- 将数据分区存储，分别执行作业;
- 标签脚本性能调优;
- 基于一些标签共同的数据来源开发中间表。

下面介绍一种用户标签分表、分区存储的解决方案。

根据标签指标体系的人口属性、行为属性、用户消费、风险控制、社交属性等维度分别建立对应的标签表进行分表存储对应的标签数据。如下图所示。

- 人口属性表：dw.userprofile_attritube_all
- 行为属性表：dw.userprofile_action_all
- 用户消费表：dw.userprofile_consume_all
- 风险控制表：dw.userprofile_riskmanage_all
- 社交属性表：dw.userprofile_social_all

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG033JyxL8JmxqUCFeHGib4Hg0sI89DHga3QVD4axR7Mfpe4eB1Hl8oYCA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

例如创建用户的人口属性宽表：

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG0UYRRBVPBVxYNuQ3tkzBXC52RUG6AfelXh9rEesq3tDUg1tN3AicCvtA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

同样的，用户其他id维度（如cookieid、deviceid、registerid等）的标签数据存储，也可以使用上面案例中的表结构。

在上面的创建中通过设立人口属性维度的宽表开发相关的用户标签，为了提高数据的插入和查询效率，在Hive中可以使用分区表的方式，将数据存储在不同的目录中。在Hive使用select查询时一般会扫描整个表中所有数据，将会花费很多时间扫描不是当前要查询的数据，为了扫描表中关心的一部分数据，在建表时引入了partition的概念。在查询时，可以通过Hive的分区机制来控制一次遍历的数据量。[Hive SQL优化思路](http://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&mid=2247514411&idx=2&sn=44348fb0a3389d486996cdbb82cc7ca7&chksm=cf378b26f840023055209a674d4210e87c5e5f548bafdf09ea25e6ee21f2dd7a2429f88a8b24&scene=21#wechat_redirect)。

## 三、标签汇聚

在上面一节提到的案例中，用户的每个标签都插入到相应的分区下面，但是对一个用户来说，打在他身上的全部标签存储在不同的分区下面。为了方便分析和查询，需要将用户身上的标签做聚合处理。

标签汇聚后将一个每个用户身上的全量标签汇聚到一个字段中，表结构设计如下：

```sql
CREATE TABLE `dw.userprofile_userlabel_map_all`
(
    `userid`     string COMMENT 'userid',
    `userlabels` map<string,string> COMMENT 'tagsmap',
)
    COMMENT 'userid 用户标签汇聚'
    PARTITIONED BY ( `data_date` string COMMENT '数据日期')

```

开发udf函数“cast_to_json”将用户身上的标签汇聚成json字符串，执行命令将按分区存储的标签进行汇聚:

```sql
insert overwrite table dw.userprofile_userlabel_map_all partition(data_date= "data_date")  
  select userid,  
         cast_to_json(concat_ws(',',collect_set(concat(labelid,':',labelweight)))) as userlabels
      from “用户各维度的标签表” 
    where data_date= " data_date " 
group by userid

```

汇聚后用户标签的存储格式如图所示:

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG09LywVTesbk1LUYu90OVgZqOLKveXuZYaazvGVmu1kwVvZ0urhZiccicQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

将用户身上的标签进行聚合便于查询和计算。例如，在画像产品中，输入用户id后通过直接查询该表，解析标签id和对应的标签权重后，即可在前端展示该用户的相关信息

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG0Jao3qjlndVxkRw8tzqKQRE6S4lgPebkmzxfD4uCScoGqd63Xia4prjw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 四、ID-MAP

开发用户标签的时候，有项非常重要的内容——`ID-MApping，即把用户不同来源的身份标识通过数据手段识别为同一个主体`。用户的属性、行为相关数据分散在不同的数据来源中，通过ID-MApping能够把用户在不同场景下的行为串联起来，消除数据孤岛。下图展示了用户与设备间的多对多关系。[解密One ID中的核心技术ID-Mapping](http://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&mid=2247506004&idx=2&sn=24a1ae236549687f481f591ef9820fdb&chksm=cf37ea59f840634f5bffeb06dcb255261ca3a8db44fc11efbb3499432bcb4b5e74b0dcec4bea&scene=21#wechat_redirect)。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG0SdAINUD8fgdYkB3gvu62sVIR621BlmzmdqOgVgBGicNwQlicMAZOfaWg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

下图展示了同一用户在不同平台间的行为示意图。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG0rEBZwlaRsxZKfHODYjeBvFI9ia3uaK3RSWZOh2HGVYYictD5ic7PTwRoQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

举例来说，用户在未登录App的状态下，在App站内访问、搜索相关内容时，记录的是设备id（即cookieid）相关的行为数据。而用户在登录App后，访问、收藏、下单等相关的行为记录的是账号id（即userid）相关行为数据。虽然是同一个用户，但其在登录和未登录设备时记录的行为数据之间是未打通的。通过ID-MApping打通 userid 和 cookieid 的对应关系，可以在用户登录、未登录设备时都能捕获其行为轨迹。

下面通过一个案例介绍如何通过Hive的ETL工作完成ID-Mapping的数据清洗工作。

`缓慢变化维是在维表设计中常见的一种方式，维度并不是不变的，随时间也会发生缓慢变化。`如用户的手机号、邮箱等信息可能会随用户的状态变化而改变，再如商品的价格也会随时间变化而调整上架的价格。因此在设计用户、商品等维表时会考虑用缓慢变化维来开发。同样，在设计ID-Mapping表时，由于一个用户可以在多个设备上登录，一个设备也能被多个用户登录，所以考虑用缓慢变化维表来记录这种不同时间点的状态变化。

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG0Qqkuo7IxLYvia9IqcENMI8EZ0HfFYusuxhRfffWYn2qOIMAHO8pM7ibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

拉链表是针对缓慢变化维表的一种设计方式，记录一个事物从开始到当前状态的全部状态变化信息。

在上图中，通过拉链表记录了userid每一次关联到不同cookieid的情况。如userid为44463729的用户，在20190101这天登录某设备，在6号那天变换了另一个设备登录。其中start_date表示该记录的开始日期，end_date表示该记录的结束日期，当end_date为99991231时，表示该条记录当前仍然有效。

首先需要从埋点表和访问日志表里面获取到cookieid和userid同时出现的访问记录。下面案例中，ods.page_event_log是埋点日志表，ods.page_view_log是访问日志表，将获取到的userid和cookieid信息插入cookieid-userid关系表（ods.cookie_user_signin）中。代码执行如下：

```sql
INSERT OVERWRITE TABLE ods.cookie_user_signin PARTITION (data_date = '${data_date}')
  SELECT t.
    FROM (
         SELECT userid,
                cookieid,
                from_unixtime(eventtime,'yyyyMMdd') as signdate
           FROM ods.page_event_log      -- 埋点表
           WHERE data_date = '${data_date}'
        UNION ALL
         SELECT userid,
                cookieid,
                from_unixtime(viewtime,'yyyyMMdd') as signdate
           FROM ods.page_view_log   -- 访问日志表
           WHERE data_date = '${data_date}'
           ) t


```

创建ID-Map的拉链表，将每天新增到ods.cookie_user_signin表中的数据与拉链表历史数据做比较，如果有变化或新增数据则进行更新。

```sql
CREATE TABLE `dw.cookie_user_zippertable`(
`userid` string COMMENT '账号ID', 
`cookieid` string COMMENT '设备ID', 
`start_date` string COMMENT 'start_date', 
`end_date` string COMMENT 'end_date')
COMMENT 'id-map拉链表'
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'

```

创建完成后，每天ETL调度将数据更新到ID-Mapping拉链表中，任务执行如下。

```sql
INSERT OVERWRITE TABLE dw.cookie_user_zippertable
SELECT t. 
  FROM (
      SELECT t1.user_num,
             t1.mobile,
             t1.reg_date,
             t1.start_date,
             CASE WHEN t1.end_date = '99991231' AND t2.userid IS NOT NULL THEN '${data_date}'
                  ELSE t1.end_date
             END AS end_date
       FROM dw.cookie_user_zippertable t1
    LEFT JOIN (  SELECT 
                 FROM ods.cookie_user_signin
                WHERE data_date='${data_date}'
              )t2
           ON t1.userid = t2.userid
UNION
       SELECT userid,
              cookieid,
              '${data_date}' AS start_date,
              '99991231' AS end_date
        FROM ods.cookie_user_signin
       WHERE data_date = '${data_date
       }'
          ) t

```

数据写入表中，如上图所示。

对于该拉链表，可查看某日（如20190801）的快照数据。

```sql
select   
from dw.cookie_user_zippertable 
where start_date<='20190801' and end_date>='20190801'

```

例如，目前存在一个记录userid和cookieid关联关系的表，但是为多对多的记录（即一个userid对应多条cookieid记录，以及一条cookieid对应多条userid记录）。这里可以通过拉链表的日期来查看某个时间点userid对应的cookieid。查看某个用户（如32101029）在某天（如20190801）关联到的设备id。

```sql
select cookieid 
from dw.cookie_user_zippertable 
where userid='32101029' and start_date<='20190801' and end_date>='20190801'

```

![图片](https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OgxYGIvGSib2EE79zNntpG0L98d3ib3uNO71YkQ7HBUrm66raLmtNVicBWS4CqACDNgmp19MF4nBdPw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

上图可看出用户'32101029'在历史中曾登录过3个设备，通过限定时间段可找到特定时间下用户的登录设备。

在开发中需要注意关于userid与cookieid的多对多关联，如果不加条件限制就做关联，很可能引起数据膨胀问题：

> 在实际应用中，会遇到许多需要将userid和cookieid做关联的情况。例如，需要在userid维度开发出该用户近30日的购买次数、购买金额、登录时长、登录天数等标签。前两个标签可以很容易地从相应的业务数据表中根据算法加工出来，而登录时长、登录天数的数据存储在相关日志数据中，日志数据表记录的userid与cookieid为多对多关系。因此在结合业务需求开发标签时，要确定好标签口径定义。

## 小结

本期内容通过案例介绍了将userid 和 cookieid 打通的一种解决方案，实践中还存在需要将用户在不同平台间（如Web端和App端）行为打通的应用场景。



# 数仓用户行为面向需求SQL案例实践

## 需求一：用户活跃主题

DWS层--（用户行为宽表层） 目标：统计当日、当周、当月活动的每个设备明细

1 每日活跃设备明细 dwd_start_log--->dws_uv_detail_day

--把相同的字段collect_set到一个数组, 按mid_id分组(便于后边统计)

collect_set将某字段的值进行去重汇总，产生array类型字段。如: concat_ws('|', collect_set(user_id)) user_id,

建分区表dws_uv_detail_day：partitioned by ('dt' string)

```sql
drop table if exists dws_uv_detail_day;
create table dws_uv_detail_day( 
    `mid_id` string COMMENT '设备唯一标识',
    `user_id` string COMMENT '用户标识', 
    `version_code` string COMMENT '程序版本号', 
    `version_name` string COMMENT '程序版本名', 
`lang` string COMMENT '系统语言', 
`source` string COMMENT '渠道号', 
`os` string COMMENT '安卓系统版本', 
`area` string COMMENT '区域', 
`model` string COMMENT '手机型号', 
`brand` string COMMENT '手机品牌', 
`sdk_version` string COMMENT 'sdkVersion', 
`gmail` string COMMENT 'gmail', 
`height_width` string COMMENT '屏幕宽高',
`app_time` string COMMENT '客户端日志产生时的时间',
`network` string COMMENT '网络模式',
`lng` string COMMENT '经度',
`lat` string COMMENT '纬度'
) COMMENT '活跃用户按天明细'
PARTITIONED BY ( `dt` string)
stored as  parquet
location '/warehouse/gmall/dws/dws_uv_detail_day/'
;

```

数据导入

按周分区；过滤出一周内的数据；按设备id分组；===>count（）得到最终结果；

partition(dt='2019-02-10')   from dwd_start_log  where dt='2019-02-10'  group by mid_id  ( mid_id设备唯一标示 )

以用户单日访问为key进行聚合，如果某个用户在一天中使用了两种操作系统、两个系统版本、多个地区，登录不同账号，只取其中之一

```sql
hive (gmall)>
set hive.exec.dynamic.partition.mode=nonstrict;

insert overwrite table dws_uv_detail_day  partition(dt='2019-02-10')
select  
    mid_id,
    concat_ws('|', collect_set(user_id)) user_id,
    concat_ws('|', collect_set(version_code)) version_code,
    concat_ws('|', collect_set(version_name)) version_name,
    concat_ws('|', collect_set(lang))lang,
    concat_ws('|', collect_set(source)) source,
    concat_ws('|', collect_set(os)) os,
    concat_ws('|', collect_set(area)) area, 
    concat_ws('|', collect_set(model)) model,
    concat_ws('|', collect_set(brand)) brand,
    concat_ws('|', collect_set(sdk_version)) sdk_version,
    concat_ws('|', collect_set(gmail)) gmail,
    concat_ws('|', collect_set(height_width)) height_width,
    concat_ws('|', collect_set(app_time)) app_time,
    concat_ws('|', collect_set(network)) network,
    concat_ws('|', collect_set(lng)) lng,
    concat_ws('|', collect_set(lat)) lat
from dwd_start_log
where dt='2019-02-10'  
group by mid_id;

```

查询导入结果；

```
hive (gmall)> select  from dws_uv_detail_day limit 1;

###最后count()即是每日活跃设备的个数；
hive (gmall)> select count() from dws_uv_detail_day;

```

2 每周（dws_uv_detail_wk）活跃设备明细  partition(wk_dt)

周一到周日concat(date_add(next_day('2019-02-10', 'MO'), -7), '_', date_add(next_day('2019-02-10', 'MO'), -1))即 2019-02-04_2019-02-10

创建分区表：partitioned by('wk_dt' string)

```sql
hive (gmall)>
drop table if exists dws_uv_detail_wk;

create table dws_uv_detail_wk( 
    `mid_id` string COMMENT '设备唯一标识',
    `user_id` string COMMENT '用户标识', 
    `version_code` string COMMENT '程序版本号', 
    `version_name` string COMMENT '程序版本名', 
`lang` string COMMENT '系统语言', 
`source` string COMMENT '渠道号', 
`os` string COMMENT '安卓系统版本', 
`area` string COMMENT '区域', 
`model` string COMMENT '手机型号', 
`brand` string COMMENT '手机品牌', 
`sdk_version` string COMMENT 'sdkVersion', 
`gmail` string COMMENT 'gmail', 
`height_width` string COMMENT '屏幕宽高',
`app_time` string COMMENT '客户端日志产生时的时间',
`network` string COMMENT '网络模式',
`lng` string COMMENT '经度',
`lat` string COMMENT '纬度',
    `monday_date` string COMMENT '周一日期',
    `sunday_date` string COMMENT  '周日日期' 
) COMMENT '活跃用户按周明细'
PARTITIONED BY (`wk_dt` string)
stored as  parquet
location '/warehouse/gmall/dws/dws_uv_detail_wk/'
;

```

导入数据：以周为分区；过滤出一个月内的数据，按设备id分组；

周一：date_add(next_day('2019-05-16','MO'),-7);

周日：date_add(next_day('2019-05-16','MO'),-1);

周一---周日：concat(date_add(next_day('2019-05-16', 'MO'), -7), "_", date_add(next_day('2019-05-16', 'MO'), -1));

```sql
insert overwrite table dws_uv_detail_wk partition(wk_dt)
select mid_id,
concat_ws('|', collect_set(user_id)) user_id,
concat_ws('|', collect_set(version_code)) version_code,
concat_ws('|', collect_set(version_name)) version_name,
concat_ws('|', collect_set(lang)) lang,
concat_ws('|', collect_set(source)) source,
concat_ws('|', collect_set(os)) os,
concat_ws('|', collect_set(area)) area, 
concat_ws('|', collect_set(model)) model,
concat_ws('|', collect_set(brand)) brand,
concat_ws('|', collect_set(sdk_version)) sdk_version,
concat_ws('|', collect_set(gmail)) gmail,
concat_ws('|', collect_set(height_width)) height_width,
concat_ws('|', collect_set(app_time)) app_time,
concat_ws('|', collect_set(network)) network,
concat_ws('|', collect_set(lng)) lng,
concat_ws('|', collect_set(lat)) lat,
date_add(next_day('2019-02-10', 'MO'), -7),
date_add(next_day('2019-02-10', 'MO'), -1),
concat(date_add(next_day('2019-02-10', 'MO'), -7), '_', date_add(next_day('2019-02-10', 'MO'), -1))
from dws_uv_detail_day
where dt >= date_add(next_day('2019-02-10', 'MO'), -7) and dt <= date_add(next_day('2019-02-10', 'MO'), -1)
group by mid_id;

```

![图片](https://mmbiz.qpic.cn/mmbiz_png/wicYdantzM3oBgynBoib6gRrKShriafLS4nD5h5sXMXYCQCRRcCh2INxB4LAEDfMNjribjsgOLEONG6ZkO0SKRwiaCw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

查询导入结果

```sql
hive (gmall)> select  from dws_uv_detail_wk limit 1;
hive (gmall)> select count() from dws_uv_detail_wk;

```

3 每月活跃设备明细 dws_uv_detail_mn   partition(mn) - 把每日的数据插入进去

DWS层创建分区表 partitioned by(mn string)

```sql
hive (gmall)>
drop table if exists dws_uv_detail_mn;

create  external table dws_uv_detail_mn( 
    `mid_id` string COMMENT '设备唯一标识',
    `user_id` string COMMENT '用户标识', 
    `version_code` string COMMENT '程序版本号', 
    `version_name` string COMMENT '程序版本名', 
`lang` string COMMENT '系统语言', 
`source` string COMMENT '渠道号', 
`os` string COMMENT '安卓系统版本', 
`area` string COMMENT '区域', 
`model` string COMMENT '手机型号', 
`brand` string COMMENT '手机品牌', 
`sdk_version` string COMMENT 'sdkVersion', 
`gmail` string COMMENT 'gmail', 
`height_width` string COMMENT '屏幕宽高',
`app_time` string COMMENT '客户端日志产生时的时间',
`network` string COMMENT '网络模式',
`lng` string COMMENT '经度',
`lat` string COMMENT '纬度'
) COMMENT '活跃用户按月明细'
PARTITIONED BY (`mn` string)
stored as  parquet
location '/warehouse/gmall/dws/dws_uv_detail_mn/'
;

```

数据导入 按月分区；过滤出一个月内的数据，按照设备id分组；

data_format('2019-03-10', 'yyyy-MM')  ---> 2019-03

where date_format('dt', 'yyyy-MM') = date_format('2019-02-10', 'yyyy-MM')  group by mid_id;

```sql
hive (gmall)>
set hive.exec.dynamic.partition.mode=nonstrict;

insert  overwrite table dws_uv_detail_mn  partition(mn)
select  
    mid_id,
    concat_ws('|', collect_set(user_id)) user_id,
    concat_ws('|', collect_set(version_code)) version_code,
    concat_ws('|', collect_set(version_name)) version_name,
    concat_ws('|', collect_set(lang)) lang,
    concat_ws('|', collect_set(source)) source,
    concat_ws('|', collect_set(os)) os,
    concat_ws('|', collect_set(area)) area, 
    concat_ws('|', collect_set(model)) model,
    concat_ws('|', collect_set(brand)) brand,
    concat_ws('|', collect_set(sdk_version)) sdk_version,
    concat_ws('|', collect_set(gmail)) gmail,
    concat_ws('|', collect_set(height_width)) height_width,
    concat_ws('|', collect_set(app_time)) app_time,
    concat_ws('|', collect_set(network)) network,
    concat_ws('|', collect_set(lng)) lng,
    concat_ws('|', collect_set(lat)) lat,
    date_format('2019-02-10','yyyy-MM')
from dws_uv_detail_day
where date_format(dt,'yyyy-MM') = date_format('2019-02-10','yyyy-MM')   
group by mid_id;

```

查询导入结果

```
hive (gmall)> select  from dws_uv_detail_mn limit 1;
hive (gmall)> select count() from dws_uv_detail_mn ;

```

DWS层加载数据脚本

在hadoop101的/home/kris/bin目录下创建脚本

[kris@hadoop101 bin]$ vim dws.sh

```sql
#!/bin/bash

# 定义变量方便修改
APP=gmall
hive=/opt/module/hive/bin/hive

# 如果是输入的日期按照取输入日期；如果没输入日期取当前时间的前一天
if [ -n "$1" ] ;then
    do_date=$1
else 
    do_date=`date -d "-1 day" +%F`  
fi 


sql="
  set hive.exec.dynamic.partition.mode=nonstrict;

  insert overwrite table "$APP".dws_uv_detail_day partition(dt='$do_date')
  select  
    mid_id,
    concat_ws('|', collect_set(user_id)) user_id,
    concat_ws('|', collect_set(version_code)) version_code,
    concat_ws('|', collect_set(version_name)) version_name,
    concat_ws('|', collect_set(lang)) lang,
    concat_ws('|', collect_set(source)) source,
    concat_ws('|', collect_set(os)) os,
    concat_ws('|', collect_set(area)) area, 
    concat_ws('|', collect_set(model)) model,
    concat_ws('|', collect_set(brand)) brand,
    concat_ws('|', collect_set(sdk_version)) sdk_version,
    concat_ws('|', collect_set(gmail)) gmail,
    concat_ws('|', collect_set(height_width)) height_width,
    concat_ws('|', collect_set(app_time)) app_time,
    concat_ws('|', collect_set(network)) network,
    concat_ws('|', collect_set(lng)) lng,
    concat_ws('|', collect_set(lat)) lat
  from "$APP".dwd_start_log
  where dt='$do_date'  
  group by mid_id;


  insert  overwrite table "$APP".dws_uv_detail_wk partition(wk_dt)
  select  
    mid_id,
    concat_ws('|', collect_set(user_id)) user_id,
    concat_ws('|', collect_set(version_code)) version_code,
    concat_ws('|', collect_set(version_name)) version_name,
    concat_ws('|', collect_set(lang)) lang,
    concat_ws('|', collect_set(source)) source,
    concat_ws('|', collect_set(os)) os,
    concat_ws('|', collect_set(area)) area, 
    concat_ws('|', collect_set(model)) model,
    concat_ws('|', collect_set(brand)) brand,
    concat_ws('|', collect_set(sdk_version)) sdk_version,
    concat_ws('|', collect_set(gmail)) gmail,
    concat_ws('|', collect_set(height_width)) height_width,
    concat_ws('|', collect_set(app_time)) app_time,
    concat_ws('|', collect_set(network)) network,
    concat_ws('|', collect_set(lng)) lng,
    concat_ws('|', collect_set(lat)) lat,
    date_add(next_day('$do_date','MO'),-7),
    date_add(next_day('$do_date','SU'),-7),
    concat(date_add( next_day('$do_date','MO'),-7), '_' , date_add(next_day('$do_date','MO'),-1) 
  )
  from "$APP".dws_uv_detail_day 
  where dt>=date_add(next_day('$do_date','MO'),-7) and dt<=date_add(next_day('$do_date','MO'),-1) 
  group by mid_id; 


  insert overwrite table "$APP".dws_uv_detail_mn partition(mn)
  select  
    mid_id,
    concat_ws('|', collect_set(user_id)) user_id,
    concat_ws('|', collect_set(version_code)) version_code,
    concat_ws('|', collect_set(version_name)) version_name,
    concat_ws('|', collect_set(lang))lang,
    concat_ws('|', collect_set(source)) source,
    concat_ws('|', collect_set(os)) os,
    concat_ws('|', collect_set(area)) area, 
    concat_ws('|', collect_set(model)) model,
    concat_ws('|', collect_set(brand)) brand,
    concat_ws('|', collect_set(sdk_version)) sdk_version,
    concat_ws('|', collect_set(gmail)) gmail,
    concat_ws('|', collect_set(height_width)) height_width,
    concat_ws('|', collect_set(app_time)) app_time,
    concat_ws('|', collect_set(network)) network,
    concat_ws('|', collect_set(lng)) lng,
    concat_ws('|', collect_set(lat)) lat,
    date_format('$do_date','yyyy-MM')
  from "$APP".dws_uv_detail_day
  where date_format(dt,'yyyy-MM') = date_format('$do_date','yyyy-MM')   
  group by mid_id;
"

$hive -e "$sql"

```

增加脚本执行权限 chmod 777 dws.sh

脚本使用[kris@hadoop101 module]$ dws.sh 2019-02-11

查询结果

```sql
hive (gmall)> select count() from dws_uv_detail_day;
hive (gmall)> select count() from dws_uv_detail_wk;
hive (gmall)> select count() from dws_uv_detail_mn ;

```

脚本执行时间；企业开发中一般在每日凌晨30分~1点

ADS层 目标：当日、当周、当月活跃设备数    使用 day_count表 join wk_count  join mn_count , 把3张表连接一起

建表ads_uv_count表：

字段有day_count、wk_count、mn_count is_weekend if(date_add(next_day('2019-02-10', 'MO'), -1) = '2019-02-10', 'Y', 'N') is_monthend if(last_day('2019-02-10') = '2019-02-10', 'Y', 'N')

```sql
drop table if exists ads_uv_count;
create external table ads_uv_count(
`dt` string comment '统计日期',
`day_count` bigint comment '当日用户量',
`wk_count` bigint comment '当周用户量',
`mn_count` bigint comment '当月用户量',
`is_weekend` string comment 'Y,N是否是周末,用于得到本周最终结果',
`is_monthend` string comment 'Y,N是否是月末,用于得到本月最终结果'
) comment '每日活跃用户数量'
stored as parquet
location '/warehouse/gmall/ads/ads_uv_count/';

```

导入数据：

```sql
hive (gmall)>
insert  overwrite table ads_uv_count 
select  
  '2019-02-10' dt,
   daycount.ct,
   wkcount.ct,
   mncount.ct,
   if(date_add(next_day('2019-02-10','MO'),-1)='2019-02-10','Y','N') ,
   if(last_day('2019-02-10')='2019-02-10','Y','N') 
from 
(
   select  
      '2019-02-10' dt,
       count() ct
   from dws_uv_detail_day
   where dt='2019-02-10'  
)daycount   join 
( 
   select  
     '2019-02-10' dt,
     count () ct
   from dws_uv_detail_wk
   where wk_dt=concat(date_add(next_day('2019-02-10','MO'),-7),'_' ,date_add(next_day('2019-02-10','MO'),-1) )
)  wkcount  on daycount.dt=wkcount.dt
join 
( 
   select  
     '2019-02-10' dt,
     count () ct
   from dws_uv_detail_mn
   where mn=date_format('2019-02-10','yyyy-MM')  
)mncount on daycount.dt=mncount.dt
;

```

查询导入结果

hive (gmall)> select  from ads_uv_count ;

ADS层加载数据脚本

1）在hadoop101的/home/kris/bin目录下创建脚本

[kris@hadoop101 bin]$ vim ads.sh

```sql
#!/bin/bash

# 定义变量方便修改
APP=gmall
hive=/opt/module/hive/bin/hive

# 如果是输入的日期按照取输入日期；如果没输入日期取当前时间的前一天
if [ -n "$1" ] ;then
    do_date=$1
else 
    do_date=`date -d "-1 day" +%F`  
fi 

sql="
  set hive.exec.dynamic.partition.mode=nonstrict;

insert into table "$APP".ads_uv_count 
select  
  '$do_date' dt,
   daycount.ct,
   wkcount.ct,
   mncount.ct,
   if(date_add(next_day('$do_date','MO'),-1)='$do_date','Y','N') ,
   if(last_day('$do_date')='$do_date','Y','N') 
from 
(
   select  
      '$do_date' dt,
       count() ct
   from "$APP".dws_uv_detail_day
   where dt='$do_date'  
)daycount   join 
( 
   select  
     '$do_date' dt,
     count () ct
   from "$APP".dws_uv_detail_wk
   where wk_dt=concat(date_add(next_day('$do_date','MO'),-7),'_' ,date_add(next_day('$do_date','MO'),-1) )
)  wkcount  on daycount.dt=wkcount.dt
join 
( 
   select  
     '$do_date' dt,
     count () ct
   from "$APP".dws_uv_detail_mn
   where mn=date_format('$do_date','yyyy-MM')  
)mncount on daycount.dt=mncount.dt;
"

$hive -e "$sql"


```

增加脚本执行权限 chmod 777 ads.sh

脚本使用 ads.sh 2019-02-11

查询导入结果 hive (gmall)> select  from ads_uv_count ;

## 需求二：用户新增主题

首次联网使用应用的用户。如果一个用户首次打开某APP，那这个用户定义为新增用户；卸载再安装的设备，不会被算作一次新增。新增用户包括日新增用户、周新增用户、月新增用户。

每日新增(老用户不算,之前没登陆过，今天是第一次登陆)设备--没有分区 -->以往的新增库里边没有他，但他今天活跃了即新增加的用户；

1 DWS层（每日新增设备明细表） 创建每日新增设备明细表：dws_new_mid_day

```sql
hive (gmall)>
drop table if exists  dws_new_mid_day;
create  table  dws_new_mid_day
(
    `mid_id` string COMMENT '设备唯一标识',
    `user_id` string COMMENT '用户标识', 
    `version_code` string COMMENT '程序版本号', 
    `version_name` string COMMENT '程序版本名', 
`lang` string COMMENT '系统语言', 
`source` string COMMENT '渠道号', 
`os` string COMMENT '安卓系统版本', 
`area` string COMMENT '区域', 
`model` string COMMENT '手机型号', 
`brand` string COMMENT '手机品牌', 
`sdk_version` string COMMENT 'sdkVersion', 
`gmail` string COMMENT 'gmail', 
`height_width` string COMMENT '屏幕宽高',
`app_time` string COMMENT '客户端日志产生时的时间',
`network` string COMMENT '网络模式',
`lng` string COMMENT '经度',
`lat` string COMMENT '纬度',
    `create_date`  string  comment '创建时间' 
)  COMMENT '每日新增设备信息'
stored as  parquet
location '/warehouse/gmall/dws/dws_new_mid_day/';

```

![图片](https://mmbiz.qpic.cn/mmbiz_png/wicYdantzM3oBgynBoib6gRrKShriafLS4naOSk5lCHL5AJsibdNqc53gkFQyTbYYRRFxYE83lnmPyciclJNvziakPDw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

dws_uv_detail_day(每日活跃设备明细) left join dws_new_mid_day nm(以往的新增用户表, 新建字段create_time2019-02-10) nm.mid_id is null;

导入数据

用每日活跃用户表 left join 每日新增设备表，关联的条件是mid_id相等。如果是每日新增的设备，则在每日新增设备表中为null。

from dws_uv_detail_day ud left join dws_new_mid_day nm on ud.mid_id=nm.mid_id

where ud.dt='2019-02-10' and nm.mid_id is null;

```sql
hive (gmall)>
insert into table dws_new_mid_day  
select  
    ud.mid_id,
    ud.user_id , 
    ud.version_code , 
    ud.version_name , 
    ud.lang , 
    ud.source, 
    ud.os, 
    ud.area, 
    ud.model, 
    ud.brand, 
    ud.sdk_version, 
    ud.gmail, 
    ud.height_width,
    ud.app_time,
    ud.network,
    ud.lng,
    ud.lat,
    '2019-02-10'
from dws_uv_detail_day ud left join dws_new_mid_day nm on ud.mid_id=nm.mid_id
where ud.dt='2019-02-10' and nm.mid_id is null;

```

查询导入数据

hive (gmall)> select count() from dws_new_mid_day ;

2 ADS层（每日新增设备表） 创建每日新增设备表ads_new_mid_count

```sql
hive (gmall)>
drop table if exists  `ads_new_mid_count`;
create  table  `ads_new_mid_count`
(
    `create_date`     string  comment '创建时间' ,
    `new_mid_count`   BIGINT comment '新增设备数量' 
)  COMMENT '每日新增设备信息数量'
row format delimited  fields terminated by '\t' 
location '/warehouse/gmall/ads/ads_new_mid_count/';

```

导入数据   count（） dws_new_mid_day表即可

加了create_date就必须group by create_time，否则报错：not in GROUP BY key 'create_date'

```sql
hive (gmall)>
insert into table ads_new_mid_count 
select create_date , count()  from dws_new_mid_day
where create_date='2019-02-10'
group by create_date ;

```

查询导入数据

hive (gmall)> select  from ads_new_mid_count;

扩展每月新增：

```sql
--每月新增
drop table if exists dws_new_mid_mn;
create table dws_new_mid_mn(
    `mid_id` string COMMENT '设备唯一标识',
    `user_id` string COMMENT '用户标识', 
    `version_code` string COMMENT '程序版本号', 
    `version_name` string COMMENT '程序版本名', 
    `lang` string COMMENT '系统语言', 
    `source` string COMMENT '渠道号', 
    `os` string COMMENT '安卓系统版本', 
    `area` string COMMENT '区域', 
    `model` string COMMENT '手机型号', 
    `brand` string COMMENT '手机品牌', 
    `sdk_version` string COMMENT 'sdkVersion', 
    `gmail` string COMMENT 'gmail', 
    `height_width` string COMMENT '屏幕宽高',
    `app_time` string COMMENT '客户端日志产生时的时间',
    `network` string COMMENT '网络模式',
    `lng` string COMMENT '经度',
    `lat` string COMMENT '纬度'
)comment "每月新增明细"
partitioned by(mn string)
stored as parquet
location "/warehouse/gmall/dws/dws_new_mid_mn";

insert overwrite table dws_new_mid_mn partition(mn)
select
    um.mid_id,
    um.user_id , 
    um.version_code , 
    um.version_name , 
    um.lang , 
    um.source, 
    um.os, 
    um.area, 
    um.model, 
    um.brand, 
    um.sdk_version, 
    um.gmail, 
    um.height_width,
    um.app_time,
    um.network,
    um.lng,
    um.lat,
    date_format('2019-02-10', 'yyyy-MM')
from dws_uv_detail_mn um left join dws_new_mid_mn nm on um.mid_id = nm.mid_id
where um.mn =date_format('2019-02-10', 'yyyy-MM') and nm.mid_id = null; ----为什么加上它就是空的？？查不到数据了呢
--##注意这里不能写出date_format(um.mn, 'yyyy-MM') =date_format('2019-02-10', 'yyyy-MM') 
    |

```

## 需求三：用户留存主题

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwpEzP28l14HdeO9PJcHNJdcPwk5xheByfvu9ibVxMxHOarxwU4jkAWnI8pibSarNUxFCQLxN7XRMJiarLROXSicPw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

如果不考虑2019-02-11和2019-02-12的新增用户：2019-02-10新增100人，一天后它的留存率是30%，2天12号它的留存率是25%，3天后留存率32%；

站在2019-02-12号看02-11的留存率：新增200人，12号的留存率是20%；

站在2019-02-13号看02-12的留存率：新增100人，13号即一天后留存率是25%；

用户留存率的分析：昨日的新增且今天是活跃的 / 昨日的新增用户量

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwpEzP28l14HdeO9PJcHNJdcPwk5xheBhlTEffnsibLFXsRh6Tx4pCKaexYMfn0YqZbiaf7yGU9JI4Zz900vsY0w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

如今天11日，要统计10日的 用户留存率---->10日的新设备且是11日活跃的 / 10日新增设备 　　分母：10日的新增设备(每日活跃 left join 以往新增设备表(nm) nm.mid_id is null ) 　　分子：每日活跃表(ud) join 每日新增表(nm) where ud.dt='今天' and nm.create_date = '昨天'

① DWS层（每日留存用户明细表dws_user_retention_day） 用户1天留存的分析：===>>

留存用户=前一天新增 join 今天活跃

```
   用户留存率=留存用户/前一天新增

```

创建表：dws_user_retention_day

```sql
hive (gmall)>
drop table if exists  `dws_user_retention_day`;
create  table  `dws_user_retention_day` 
(
    `mid_id` string COMMENT '设备唯一标识',
    `user_id` string COMMENT '用户标识', 
    `version_code` string COMMENT '程序版本号', 
    `version_name` string COMMENT '程序版本名', 
`lang` string COMMENT '系统语言', 
`source` string COMMENT '渠道号', 
`os` string COMMENT '安卓系统版本', 
`area` string COMMENT '区域', 
`model` string COMMENT '手机型号', 
`brand` string COMMENT '手机品牌', 
`sdk_version` string COMMENT 'sdkVersion', 
`gmail` string COMMENT 'gmail', 
`height_width` string COMMENT '屏幕宽高',
`app_time` string COMMENT '客户端日志产生时的时间',
`network` string COMMENT '网络模式',
`lng` string COMMENT '经度',
`lat` string COMMENT '纬度',
   `create_date`       string  comment '设备新增时间',
   `retention_day`     int comment '截止当前日期留存天数'
)  COMMENT '每日用户留存情况'
PARTITIONED BY ( `dt` string)
stored as  parquet
location '/warehouse/gmall/dws/dws_user_retention_day/'
;

```

导入数据（每天计算前1天的新用户访问留存明细）

from dws_uv_detail_day每日活跃设备 ud join dws_new_mid_day每日新增设备 nm on ud.mid_id =nm.mid_id where ud.dt='2019-02-11' and nm.create_date=date_add('2019-02-11',-1);

```sql
hive (gmall)>
insert  overwrite table dws_user_retention_day  partition(dt="2019-02-11")
select  
    nm.mid_id,
    nm.user_id , 
    nm.version_code , 
    nm.version_name , 
    nm.lang , 
    nm.source, 
    nm.os, 
    nm.area, 
    nm.model, 
    nm.brand, 
    nm.sdk_version, 
    nm.gmail, 
    nm.height_width,
    nm.app_time,
    nm.network,
    nm.lng,
    nm.lat,
nm.create_date,
1 retention_day 
from  dws_uv_detail_day ud join dws_new_mid_day nm   on ud.mid_id =nm.mid_id 
where ud.dt='2019-02-11' and nm.create_date=date_add('2019-02-11',-1);

```

查询导入数据（每天计算前1天的新用户访问留存明细）

hive (gmall)> select count() from dws_user_retention_day;

② DWS层（1,2,3,n天留存用户明细表）直接插入数据：dws_user_retention_day 用union all连接起来，汇总到一个表中；1）直接导入数据（每天计算前1,2,3，n天的新用户访问留存明细） 直接改变这个即可以，date_add('2019-02-11',-3); -1是一天的留存率；-2是两天的留存率、-3是三天的留存率

```sql
hive (gmall)>
insert  overwrite table dws_user_retention_day  partition(dt="2019-02-11")
select  
    nm.mid_id,
    nm.user_id , 
    nm.version_code , 
    nm.version_name , 
    nm.lang , 
    nm.source, 
    nm.os, 
    nm.area, 
    nm.model, 
    nm.brand, 
    nm.sdk_version, 
    nm.gmail, 
    nm.height_width,
    nm.app_time,
    nm.network,
    nm.lng,
    nm.lat,
    nm.create_date,
    1 retention_day 
from dws_uv_detail_day ud join dws_new_mid_day nm  on ud.mid_id =nm.mid_id 
where ud.dt='2019-02-11' and nm.create_date=date_add('2019-02-11',-1)

union all
select  
    nm.mid_id,
    nm.user_id , 
    nm.version_code , 
    nm.version_name , 
    nm.lang , 
    nm.source, 
    nm.os, 
    nm.area, 
    nm.model, 
    nm.brand, 
    nm.sdk_version, 
    nm.gmail, 
    nm.height_width,
    nm.app_time,
    nm.network,
    nm.lng,
    nm.lat,
    nm.create_date,
    2 retention_day 
from  dws_uv_detail_day ud join dws_new_mid_day nm   on ud.mid_id =nm.mid_id 
where ud.dt='2019-02-11' and nm.create_date=date_add('2019-02-11',-2)

union all
select  
    nm.mid_id,
    nm.user_id , 
    nm.version_code , 
    nm.version_name , 
    nm.lang , 
    nm.source, 
    nm.os, 
    nm.area, 
    nm.model, 
    nm.brand, 
    nm.sdk_version, 
    nm.gmail, 
    nm.height_width,
    nm.app_time,
    nm.network,
    nm.lng,
    nm.lat,
    nm.create_date,
    3 retention_day 
from  dws_uv_detail_day ud join dws_new_mid_day nm   on ud.mid_id =nm.mid_id 
where ud.dt='2019-02-11' and nm.create_date=date_add('2019-02-11',-3);

```

2）查询导入数据（每天计算前1,2,3天的新用户访问留存明细）

hive (gmall)> select retention_day , count() from dws_user_retention_day group by retention_day;

③ ADS层 留存用户数 ads_user_retention_day_count 直接count(  )即可 1）创建 ads_user_retention_day_count表：

```sql
hive (gmall)>
drop table if exists  `ads_user_retention_day_count`;
create  table  `ads_user_retention_day_count` 
(
   `create_date`       string  comment '设备新增日期',
   `retention_day`     int comment '截止当前日期留存天数',
   `retention_count`    bigint comment  '留存数量'
)  COMMENT '每日用户留存情况'
stored as  parquet
location '/warehouse/gmall/ads/ads_user_retention_day_count/';

```

导入数据 按创建日期create_date 和 留存天数retention_day进行分组group by；

```sql
hive (gmall)>
insert into table ads_user_retention_day_count 
select   
    create_date, 
    retention_day, 
    count() retention_count  
from dws_user_retention_day
where dt='2019-02-11' 
group by create_date,retention_day;

```

查询导入数据

hive (gmall)> select  from ads_user_retention_day_count;

---> 2019-02-10 1 112

④ 留存用户比率 retention_count / new_mid_count 即留存个数 / 新增个数 创建表 ads_user_retention_day_rate

```sql
hive (gmall)>
drop table if exists  `ads_user_retention_day_rate`;
create  table  `ads_user_retention_day_rate` 
(
     `stat_date`          string comment '统计日期',
     `create_date`       string  comment '设备新增日期',
     `retention_day`     int comment '截止当前日期留存天数',
     `retention_count`    bigint comment  '留存数量',
     `new_mid_count`     string  comment '当日设备新增数量',
     `retention_ratio`   decimal(10,2) comment '留存率'
)  COMMENT '每日用户留存情况'
stored as  parquet
location '/warehouse/gmall/ads/ads_user_retention_day_rate/';

```

导入数据

```
join ads_new_mid_countt --->每日新增设备表

```

```sql
hive (gmall)>
insert into table ads_user_retention_day_rate
select 
    '2019-02-11' , 
    ur.create_date,
    ur.retention_day, 
    ur.retention_count , 
    nc.new_mid_count,
    ur.retention_count/nc.new_mid_count100
from 
(
    select   
        create_date, 
        retention_day, 
        count() retention_count  
    from `dws_user_retention_day` 
    where dt='2019-02-11' 
    group by create_date,retention_day
)  ur join ads_new_mid_count nc on nc.create_date=ur.create_date;

```

查询导入数据

```
hive (gmall)>select  from ads_user_retention_day_rate;

```

2019-02-11 2019-02-10 1 112 442 25.34

## 需求四：沉默用户数

沉默用户：指的是只在安装当天启动过，且启动时间是在一周前

使用日活明细表dws_uv_detail_day作为DWS层数据

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwpEzP28l14HdeO9PJcHNJdcPwk5xheBPOW0eSPw9JECnYDMyqCXwmHcIKAiaVaLtphdawIMuw3VT1SlZWVQqQg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

建表语句

```sql
hive (gmall)>
drop table if exists ads_slient_count;
create external table ads_slient_count( 
    `dt` string COMMENT '统计日期',
    `slient_count` bigint COMMENT '沉默设备数'
) 
row format delimited fields terminated by '\t'
location '/warehouse/gmall/ads/ads_slient_count';

```

导入数据

```sql
hive (gmall)>
insert into table ads_slient_count
select 
    '2019-02-20' dt,
    count() slient_count
from 
(
    select mid_id
    from dws_uv_detail_day
    where dt<='2019-02-20'
    group by mid_id
    having count()=1 and min(dt)<date_add('2019-02-20',-7)
) t1;

```

## 需求五：本周回流用户数

本周回流=本周活跃-本周新增-上周活跃

使用日活明细表dws_uv_detail_day作为DWS层数据

本周回流(上周以前活跃过，上周没活跃，本周活跃了)=本周活跃-本周新增-上周活跃 本周回流=本周活跃left join 本周新增 left join 上周活跃，且本周新增id为null，上周活跃id为null；

建表：

```sql
hive (gmall)>
drop table if exists ads_back_count;
create external table ads_back_count( 
    `dt` string COMMENT '统计日期',
    `wk_dt` string COMMENT '统计日期所在周',
    `wastage_count` bigint COMMENT '回流设备数'
) 
row format delimited fields terminated by '\t'
location '/warehouse/gmall/ads/ads_back_count';

```

导入数据

```sql
hive (gmall)> 
insert into table ads_back_count
select 
   '2019-02-20' dt,
   concat(date_add(next_day('2019-02-20','MO'),-7),'_',date_add(next_day('2019-02-20','MO'),-1)) wk_dt,
   count()
from 
(
    select t1.mid_id
    from 
    (
        select    mid_id
        from dws_uv_detail_wk
        where wk_dt=concat(date_add(next_day('2019-02-20','MO'),-7),'_',date_add(next_day('2019-02-20','MO'),-1))
    )t1
    left join
    (
        select mid_id
        from dws_new_mid_day
        where create_date<=date_add(next_day('2019-02-20','MO'),-1) and create_date>=date_add(next_day('2019-02-20','MO'),-7)
    )t2
    on t1.mid_id=t2.mid_id
    left join
    (
        select mid_id
        from dws_uv_detail_wk
        where wk_dt=concat(date_add(next_day('2019-02-20','MO'),-72),'_',date_add(next_day('2019-02-20','MO'),-7-1))
    )t3
    on t1.mid_id=t3.mid_id
    where t2.mid_id is null and t3.mid_id is null
)t4;

```

## 需求六：流失用户数

流失用户：最近7天未登录我们称之为流失用户

使用日活明细表dws_uv_detail_day作为DWS层数据

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwpEzP28l14HdeO9PJcHNJdcPwk5xheBKrt484bND6Ij7DaUgpme4NTiafzXjWiaHOAB8DRWFITRhnEeVgfMZpwg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

建表语句

```sql
hive (gmall)>
drop table if exists ads_wastage_count;
create external table ads_wastage_count( 
    `dt` string COMMENT '统计日期',
    `wastage_count` bigint COMMENT '流失设备数'
) 
row format delimited fields terminated by '\t'
location '/warehouse/gmall/ads/ads_wastage_count';

```

导入数据

```sql
hive (gmall)>
insert into table ads_wastage_count
select
     '2019-02-20',
     count()
from 
(
    select mid_id
from dws_uv_detail_day
    group by mid_id
    having max(dt)<=date_add('2019-02-20',-7)
)t1;

```

## 需求七：最近连续3周活跃用户数

最近3周连续活跃的用户：通常是周一对前3周的数据做统计，该数据一周计算一次。

使用周活明细表dws_uv_detail_wk作为DWS层数据

![图片](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

建表语句

```sql
hive (gmall)>
drop table if exists ads_continuity_wk_count;
create external table ads_continuity_wk_count( 
    `dt` string COMMENT '统计日期,一般用结束周周日日期,如果每天计算一次,可用当天日期',
    `wk_dt` string COMMENT '持续时间',
    `continuity_count` bigint
) 
row format delimited fields terminated by '\t'
location '/warehouse/gmall/ads/ads_continuity_wk_count';


```

导入数据

```sql
hive (gmall)>
insert into table ads_continuity_wk_count
select 
     '2019-02-20',
     concat(date_add(next_day('2019-02-20','MO'),-73),'_',date_add(next_day('2019-02-20','MO'),-1)),
     count()
from 
(
    select mid_id
    from dws_uv_detail_wk
    where wk_dt>=concat(date_add(next_day('2019-02-20','MO'),-73),'_',date_add(next_day('2019-02-20','MO'),-72-1)) 
    and wk_dt<=concat(date_add(next_day('2019-02-20','MO'),-7),'_',date_add(next_day('2019-02-20','MO'),-1))
    group by mid_id
    having count()=3
)t1;

```

## 需求八：最近七天内连续三天活跃用户数

说明：最近7天内连续3天活跃用户数

使用日活明细表dws_uv_detail_day作为DWS层数据

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwpEzP28l14HdeO9PJcHNJdcPwk5xheB4KWXRib4UxgNMEfDibLFZ5aSDW6rTCsIPDUibe3DwvYfCdKEmiaS5kTmuQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

建表

```sql
hive (gmall)>
drop table if exists ads_continuity_uv_count;
create external table ads_continuity_uv_count( 
    `dt` string COMMENT '统计日期',
    `wk_dt` string COMMENT '最近7天日期',
    `continuity_count` bigint
) COMMENT '连续活跃设备数'
row format delimited fields terminated by '\t'
location '/warehouse/gmall/ads/ads_continuity_uv_count';

```

导入数据

```sql
hive (gmall)>
insert into table ads_continuity_uv_count
select
    '2019-02-12',
    concat(date_add('2019-02-12',-6),'_','2019-02-12'),
    count()
from
(
    select mid_id
    from
    (
        select mid_id      
        from
        (
            select 
                mid_id,
                date_sub(dt,rank) date_dif
            from
            (
                select 
                    mid_id,
                    dt,
                    rank() over(partition by mid_id order by dt) rank
                from dws_uv_detail_day
                where dt>=date_add('2019-02-12',-6) and dt<='2019-02-12'
            )t1
        )t2 
        group by mid_id,date_dif
        having count()>=3
    )t3 
    group by mid_id
)t4;

```

ODS层跟原始字段要一模一样；

DWD层 　　dwd_order_info订单表 　　dwd_order_detail订单详情(订单和商品) 　　dwd_user_info用户表 　　dwd_payment_info支付流水 　　dwd_sku_info商品表(增加分类)

每日用户行为宽表 dws_user_action

字段：user_id、order_count、order_amount、payment_count、payment_amount 、comment_count

```sql
drop table if exists dws_user_action;
create external table dws_user_action(
user_id string comment '用户id',
order_count bigint comment '用户下单数',
order_amount decimal(16, 2) comment '下单金额',
payment_count bigint comment '支付次数',
payment_amount decimal(16, 2) comment '支付金额',
comment_count bigint comment '评论次数'
)comment '每日用户行为宽表'
partitioned by(`dt` string)
stored as parquet
location '/warehouse/gmall/dws/dws_user_action/'
tblproperties("parquet.compression"="snappy");

```

导入数据

0占位符，第一个字段要有别名

```sql
with tmp_order as(
select user_id, count() order_count, sum(oi.total_amount) order_amount from dwd_order_info oi
where date_format(oi.create_time, 'yyyy-MM-dd')='2019-02-10' group by user_id
),
tmp_payment as(
select user_id, count() payment_count, sum(pi.total_amount) payment_amount from dwd_payment_info pi
where date_format(pi.payment_time, 'yyyy-MM-dd')='2019-02-10' group by user_id
),
tmp_comment as(
select user_id, count() comment_count from dwd_comment_log c
where date_format(c.dt, 'yyyy-MM-dd')='2019-02-10' group by user_id
)
insert overwrite table dws_user_action partition(dt='2019-02-10')
select user_actions.user_id, sum(user_actions.order_count), sum(user_actions.order_amount), 
sum(user_actions.payment_count),
sum(user_actions.payment_amount),
sum(user_actions.comment_count) from(
select user_id, order_count, order_amount, 0 payment_count, 0 payment_amount, 0 comment_count from tmp_order
union all select user_id, 0, 0, payment_count, payment_amount, 0 from tmp_payment
union all select user_id, 0, 0, 0, 0, comment_count from tmp_comment
) user_actions group by user_id;

```



## 需求九：GMV一段时间内的成交总额

GMV拍下订单金额；包括付款和未付款；

建表ads_gmv_sum_day语句：

```
drop table if exists ads_gmv_sum_day;
create table ads_gmv_sum_day(
`dt` string comment '统计日期',
`gmv_count` bigint comment '当日GMV订单个数',
`gmv_amount` decimal(16, 2) comment '当日GMV订单总额',
`gmv_payment` decimal(16, 2) comment '当日支付金额'
) comment 'GMV'
row format delimited fields terminated by '\t'
location '/warehouse/gmall/ads/ads_gmv_sum_day';

```

导入数据：from用户行为宽表dws_user_action

sum(order_count) gmv_count 、 sum(order_amount) gmv_amount 、sum(payment_amount) payment_amount 过滤日期，以dt分组；

```
insert into table ads_gmv_sum_day 
select '2019-02-10' dt, sum(order_count) gmv_count, sum(order_amount) gmv_amount, sum(payment_amount) gmv_payment
from dws_user_action where dt='2019-02-10' group by dt;

```

编写脚本：

```
#/bin/bash
APP=gmall
hive=/opt/module/hive/bin/hive
if [ -n "$1" ]; then
    do_date=$1
else
    do_date=`date -d "-1 day" +%F`
fi    
sql="
insert into table "$APP".ads_gmv_sum_day 
select '$do_date' dt, sum(order_count) gmv_count, sum(order_amount) gmv_amount, sum(payment_amount) gmv_payment
from "$APP".dws_user_action where dt='$do_date' group by dt;
"
$hive -e "$sql";

```

## 需求十：转化率=新增用户/日活用户

https://img2018.cnblogs.com/blog/1247221/201905/1247221-20190516210029788-275690435.png![图片](https://mmbiz.qpic.cn/mmbiz_png/JwpEzP28l15xaYyKjT9mccxft6FsOiaTnQSGnyialyZjcffINDYcIsUClmWfvDHchj3qskI62wWtGbg9fibZaGqicQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

```
ads_user_convert_day
  dt
  uv_m_count   当日活跃设备
  new_m_count  当日新增设备
  new_m_ratio  新增占日活比率

ads_uv_count      用户活跃数（在行为数仓中；） day_count dt
ads_new_mid_count 用户新增表（行为数仓中） new_mid_count create_date

```

建表ads_user_convert_day

```
drop table if exists ads_user_convert_day;
create table ads_user_convert_day(
`dt` string comment '统计日期',
`uv_m_count` bigint comment '当日活跃设备',
`new_m_count` bigint comment '当日新增设备',
`new_m_radio` decimal(10, 2) comment '当日新增占日活比率'
)comment '转化率'
row format delimited fields terminated by '\t'
location '/warehouse/gmall/ads/ads_user_convert_day/';

```

数据导入 cast(sum( uc.nmc)/sum( uc.dc)100 as decimal(10,2)) new_m_ratio ；使用union all

```
insert into table ads_user_convert_day select '2019-02-10', sum(uc.dc) sum_dc, sum(uc.nmc) sum_nmc, 
cast(sum(uc.nmc)/sum(uc.dc)  100 as decimal(10, 2)) new_m_radio
from(select day_count dc, 0 nmc from ads_uv_count where dt='2019-02-10'
union all select 0 dc, new_mid_count from ads_new_mid_count where create_date='2019-02-10'
)uc;

```

访问到下单转化率| 下单到支付转化率

```sql
ads_user_action_convert_day
dt
total_visitor_m_count                 总访问人数
order_u_count                        下单人数
visitor2order_convert_ratio         访问到下单转化率
payment_u_count                     支付人数
order2payment_convert_ratio            下单到支付转化率

dws_user_action （宽表中）
    user_id
    order_count
    order_amount
    payment_count
    payment_amount 
    comment_count
ads_uv_count 用户活跃数（行为数仓中）
    dt
    day_count 
    wk_count
    mn_count
    is_weekend
    is_monthend

```

建表

```sql
drop table if exists ads_user_action_convert_day;
create table ads_user_action_convert_day(
`dt` string comment '统计日期',
`total_visitor_m_count` bigint comment '总访问人数',
`order_u_count` bigint comment '下单人数',
`visitor2order_convert_radio` decimal(10, 2) comment '访问到下单转化率',
`payment_u_count` bigint comment '支付人数',
`order2payment_convert_radio` decimal(10, 2) comment '下单到支付的转化率'
)COMMENT '用户行为漏斗分析'
row format delimited  fields terminated by '\t' 
location '/warehouse/gmall/ads/ads_user_convert_day/'
;

```

插入数据

```sql
insert into table ads_user_action_convert_day
select '2019-02-10', uv.day_count, ua.order_count, 
cast(ua.order_count/uv.day_count  100 as decimal(10, 2)) visitor2order_convert_radio,
ua.payment_count,
cast(ua.payment_count/ua.order_count  100 as decimal(10, 2)) order2payment_convert_radio
from(
select sum(if(order_count>0, 1, 0)) order_count,
sum(if(payment_count>0, 1, 0)) payment_count
from dws_user_action where dt='2019-02-10'
)ua, ads_uv_count  uv where uv.dt='2019-02-10';

```

## 需求十一：品牌复购率

需求：以月为单位统计，购买2次以上商品的用户，用户购买商品明细表 dws_sale_detail_daycount：（宽表）建表dws_sale_detail_daycount

```sql
drop table if exists dws_sale_detail_daycount;

create external table dws_sale_detail_daycount(
user_id   string  comment '用户 id',
sku_id    string comment '商品 Id',
user_gender  string comment '用户性别',
user_age string  comment '用户年龄',
user_level string comment '用户等级',
order_price decimal(10,2) comment '商品价格',
sku_name string   comment '商品名称',
sku_tm_id string   comment '品牌id',
sku_category3_id string comment '商品三级品类id',
sku_category2_id string comment '商品二级品类id',
sku_category1_id string comment '商品一级品类id',
sku_category3_name string comment '商品三级品类名称',
sku_category2_name string comment '商品二级品类名称',
sku_category1_name string comment '商品一级品类名称',
spu_id  string comment '商品 spu',
sku_num  int comment '购买个数',
order_count string comment '当日下单单数',
order_amount string comment '当日下单金额'
) comment  '用户购买商品明细表'
partitioned by(`dt` string)
stored as parquet
location '/warehouse/gmall/dws/dws_sale_detail_daycount'
tblproperties("parquet.compression"="snappy");

```

数据导入

ods_order_detail订单详情表、dwd_user_info用户表、dwd_sku_info商品表

```sql
with tmp_detail as(
select user_id, sku_id, sum(sku_num) sku_num, count() order_count, sum(od.order_pricesku_num) order_amount
from ods_order_detail od where od.dt='2019-02-10' and user_id is not null group by user_id, sku_id
)
insert overwrite table dws_sale_detail_daycount partition(dt='2019-02-10')
select
tmp_detail.user_id,
tmp_detail.sku_id,
u.gender,
months_between('2019-02-10', u.birthday)/12 age,
u.user_level,
price,
sku_name,
tm_id,
category3_id ,  
category2_id ,  
category1_id ,  
category3_name ,  
category2_name ,  
category1_name ,  
spu_id,
tmp_detail.sku_num,
tmp_detail.order_count,
tmp_detail.order_amount 
from tmp_detail 
left join dwd_user_info u on u.id=tmp_detail.user_id and u.dt='2019-02-10'
left join dwd_sku_info s on s.id=tmp_detail.sku_id and s.dt='2019-02-10';

```

ADS层 品牌复购率报表分析 建表ads_sale_tm_category1_stat_mn

buycount 购买人数、buy_twice_last两次以上购买人数、

buy_twice_last_ratio '单次复购率'、

buy_3times_last '三次以上购买人数',

buy_3times_last_ratio 多次复购率'

```sql
drop table ads_sale_tm_category1_stat_mn;
create  table ads_sale_tm_category1_stat_mn
(   
    tm_id string comment '品牌id ' ,
    category1_id string comment '1级品类id ',
    category1_name string comment '1级品类名称 ',
    buycount   bigint comment  '购买人数',
    buy_twice_last bigint  comment '两次以上购买人数',
    buy_twice_last_ratio decimal(10,2)  comment  '单次复购率', 
    buy_3times_last   bigint comment   '三次以上购买人数',
    buy_3times_last_ratio decimal(10,2)  comment  '多次复购率' ,
    stat_mn string comment '统计月份',
    stat_date string comment '统计日期' 
)   COMMENT '复购率统计'
row format delimited  fields terminated by '\t' 
location '/warehouse/gmall/ads/ads_sale_tm_category1_stat_mn/'
;

```

插入数据

```sql
insert into table ads_sale_tm_category1_stat_mn
select mn.sku_tm_id,
mn.sku_category1_id,
mn.sku_category1_name,
sum(if(mn.order_count >= 1, 1, 0)) buycount,
sum(if(mn.order_count >= 2, 1, 0)) buyTwiceLast,
sum(if(mn.order_count >= 2, 1, 0)) / sum(if(mn.order_count >= 1, 1, 0)) buyTwiceLastRatio,
sum(if(mn.order_count >= 3, 1, 0)) buy3timeLast,
sum(if(mn.order_count >= 3, 1, 0)) / sum(if(mn.order_count >= 1, 1, 0)) buy3timeLastRadio,
date_format ('2019-02-10' ,'yyyy-MM') stat_mn,
'2019-02-10' stat_date
from (
select sd.sku_tm_id, sd.sku_category1_id, sd.sku_category1_name, user_id, sum(order_count) order_count
from dws_sale_detail_daycount sd where date_format(dt, 'yyyy-MM') <= date_format('2019-02-10', 'yyyy-MM')
group by sd.sku_tm_id, sd.sku_category1_id, user_id, sd.sku_category1_name
) mn
group by mn.sku_tm_id, mn.sku_category1_id, mn.sku_category1_name
;

```

数据导入脚本

1）在/home/kris/bin目录下创建脚本ads_sale.sh

[kris@hadoop101 bin]$ vim ads_sale.sh

```sql
#!/bin/bash

# 定义变量方便修改
APP=gmall
hive=/opt/module/hive/bin/hive

# 如果是输入的日期按照取输入日期；如果没输入日期取当前时间的前一天
if [ -n "$1" ] ;then
    do_date=$1
else 
    do_date=`date  -d "-1 day"  +%F`  
fi 

sql="

set hive.exec.dynamic.partition.mode=nonstrict;

insert into table "$APP".ads_sale_tm_category1_stat_mn
select   
    mn.sku_tm_id,
    mn.sku_category1_id,
    mn.sku_category1_name,
    sum(if(mn.order_count>=1,1,0)) buycount,
    sum(if(mn.order_count>=2,1,0)) buyTwiceLast,
    sum(if(mn.order_count>=2,1,0))/sum( if(mn.order_count>=1,1,0)) buyTwiceLastRatio,
    sum(if(mn.order_count>=3,1,0))  buy3timeLast  ,
    sum(if(mn.order_count>=3,1,0))/sum( if(mn.order_count>=1,1,0)) buy3timeLastRatio ,
    date_format('$do_date' ,'yyyy-MM') stat_mn,
    '$do_date' stat_date
from 
(     
    select od.sku_tm_id, 
        od.sku_category1_id,
        od.sku_category1_name,  
        user_id , 
        sum(order_count) order_count
    from  "$APP".dws_sale_detail_daycount  od 
    where date_format(dt,'yyyy-MM')<=date_format('$do_date' ,'yyyy-MM')
    group by od.sku_tm_id, od.sku_category1_id, user_id, od.sku_category1_name
) mn
group by mn.sku_tm_id, mn.sku_category1_id, mn.sku_category1_name;

"
$hive -e "$sql"

增加脚本执行权限
[kris@hadoop101 bin]$ chmod 777 ads_sale.sh
执行脚本导入数据
[kris@hadoop101 bin]$ ads_sale.sh 2019-02-11
查看导入数据
hive (gmall)>select  from ads_sale_tm_category1_stat_mn limit 2;

```

品牌复购率结果输出到MySQL

1）在MySQL中创建ads_sale_tm_category1_stat_mn表

```sql
create  table ads_sale_tm_category1_stat_mn
(   
    tm_id varchar(200) comment '品牌id ' ,
    category1_id varchar(200) comment '1级品类id ',
    category1_name varchar(200) comment '1级品类名称 ',
    buycount   varchar(200) comment  '购买人数',
    buy_twice_last varchar(200) comment '两次以上购买人数',
    buy_twice_last_ratio varchar(200) comment  '单次复购率', 
    buy_3times_last   varchar(200) comment   '三次以上购买人数',
    buy_3times_last_ratio varchar(200)  comment  '多次复购率' ,
    stat_mn varchar(200) comment '统计月份',
    stat_date varchar(200) comment '统计日期' 
)

```

2）编写Sqoop导出脚本

在/home/kris/bin目录下创建脚本sqoop_export.sh

[kris@hadoop101 bin]$ vim sqoop_export.sh

```sql
#!/bin/bash

db_name=gmall

export_data() {
/opt/module/sqoop/bin/sqoop export \
--connect "jdbc:mysql://hadoop101:3306/${db_name}?useUnicode=true&characterEncoding=utf-8"  \
--username root \
--password 123456 \
--table $1 \
--num-mappers 1 \
--export-dir /warehouse/$db_name/ads/$1 \
--input-fields-terminated-by "\t"  \
--update-key "tm_id,category1_id,stat_mn,stat_date" \
--update-mode allowinsert \
--input-null-string '\\N'    \
--input-null-non-string '\\N'  
}

case $1 in
  "ads_sale_tm_category1_stat_mn")
     export_data "ads_sale_tm_category1_stat_mn"
;;
   "all")
     export_data "ads_sale_tm_category1_stat_mn"
;;
esac

```

3）执行Sqoop导出脚本

[kris@hadoop101 bin]$ chmod 777 sqoop_export.sh

[kris@hadoop101 bin]$ sqoop_export.sh all

4）在MySQL中查看结果

SELECT  FROM ads_sale_tm_category1_stat_mn;

## 需求十二：求每个等级的用户对应的复购率前十的商品排行

1）每个等级，每种商品，买一次的用户数，买两次的用户数=》得出复购率

2）利用开窗函数，取每个等级的前十

3）形成脚本

用户购买明细宽表 dws_sale_detail_daycount

① t1--按user_leval, sku_id, user_id统计下单次数

```sql
select 
    user_level, 
    sku_id, 
    user_id, 
    sum(order_count) order_count_sum
from dws_sale_detail_daycount
where date_format(dt, 'yyyy-MM') = date_format('2019-02-13', 'yyyy-MM')
group by user_level, sku_id, user_id limit 10;

```

② t2 --求出每个等级，每种商品，买一次的用户数，买两次的用户数 得出复购率

```sql
select 
    t1.user_level,
    t1.sku_id,
    sum(if(t1.order_count_sum > 0, 1, 0)) buyOneCount,
    sum(if(t1.order_count_sum > 1, 1, 0)) buyTwiceCount,
    sum(if(t1.order_count_sum > 1, 1, 0)) / sum(if(t1.order_count_sum > 0, 1, 0))  100 buyTwiceCountRatio,
    '2019-02-13' stat_date
from(
select 
    user_level, 
    sku_id, 
    user_id, 
    sum(order_count) order_count_sum
from dws_sale_detail_daycount
where date_format(dt, 'yyyy-MM') = date_format('2019-02-13', 'yyyy-MM')
group by user_level, sku_id, user_id
) t1
group by t1.user_level, t1.sku_id;

```

③ t3 --按用户等级分区，复购率排序

```sql
select
    t2.user_level,
    t2.sku_id,
    t2.buyOneCount,
    t2.buyTwiceCount,
    t2.buyTwiceCountRatio,
    t2.stat_date
from(
select 
    t1.user_level,
    t1.sku_id,
    sum(if(t1.order_count_sum > 0, 1, 0)) buyOneCount,
    sum(if(t1.order_count_sum > 1, 1, 0)) buyTwiceCount,
    sum(if(t1.order_count_sum > 1, 1, 0)) / sum(if(t1.order_count_sum > 0, 1, 0))  100 buyTwiceCountRatio,
    '2019-02-13' stat_date
from(
select 
    user_level, 
    sku_id, 
    user_id, 
    sum(order_count) order_count_sum
from dws_sale_detail_daycount
where date_format(dt, 'yyyy-MM') = date_format('2019-02-13', 'yyyy-MM')
group by user_level, sku_id, user_id
) t1
group by t1.user_level, t1.sku_id
)t2

```

④ -分区排序 rank()

```sql
select
    t2.user_level,
    t2.sku_id,
    t2.buyOneCount,
    t2.buyTwiceCount,
    t2.buyTwiceCountRatio,
rank() over(partition by t2.sku_id order by t2.buyTwiceCount) rankNo
from(
select 
    t1.user_level,
    t1.sku_id,
    sum(if(t1.order_count_sum > 0, 1, 0)) buyOneCount,
    sum(if(t1.order_count_sum > 1, 1, 0)) buyTwiceCount,
    sum(if(t1.order_count_sum > 1, 1, 0)) / sum(if(t1.order_count_sum > 0, 1, 0))  100 buyTwiceCountRatio,
    '2019-02-13' stat_date
from(
select 
    user_level, 
    sku_id, 
    user_id, 
    sum(order_count) order_count_sum
from dws_sale_detail_daycount
where date_format(dt, 'yyyy-MM') = date_format('2019-02-13', 'yyyy-MM')
group by user_level, sku_id, user_id
) t1
group by t1.user_level, t1.sku_id
)t2

```

⑤ 作为子查询取前10

```sql
select t3.user_level, t3.sku_id, t3.buyOneCount, t3.buyTwiceCount, t3.buyTwiceCountRatio, t3.rankNo
from(
select
    t2.user_level,
    t2.sku_id,
    t2.buyOneCount,
    t2.buyTwiceCount,
    t2.buyTwiceCountRatio,
rank() over(partition by t2.sku_id order by t2.buyTwiceCount) rankNo
from(
select 
    t1.user_level,
    t1.sku_id,
    sum(if(t1.order_count_sum > 0, 1, 0)) buyOneCount,
    sum(if(t1.order_count_sum > 1, 1, 0)) buyTwiceCount,
    sum(if(t1.order_count_sum > 1, 1, 0)) / sum(if(t1.order_count_sum > 0, 1, 0))  100 buyTwiceCountRatio,
    '2019-02-13' stat_date
from(
select 
    user_level, 
    sku_id, 
    user_id, 
    sum(order_count) order_count_sum
from dws_sale_detail_daycount
where date_format(dt, 'yyyy-MM') = date_format('2019-02-13', 'yyyy-MM')
group by user_level, sku_id, user_id
) t1
group by t1.user_level, t1.sku_id
)t2
) t3 where rankNo <= 10;

```



# 实时数仓的建设

## 一、 实时数仓的理论

### 1.实时需求日趋迫切

目前各大公司的产品需求和内部决策对于数据实时性的要求越来越迫切， 需要实时数仓的能⼒来赋能 。传统离 线数仓的数据时效性是 T+1，调度频率以天为单位，⽆法⽀撑实时场景的数据需求 。即使能将调度频率设置成 ⼩时，也只能解决部分时效性要求不高的场景，对于实效性要求很高的场景还是⽆法优雅的⽀撑 。因此实时使 用数据的问题必须得到有效解决。

### 2.实时技术日趋

实时计算框架已经经历了三代发展，分别是：Storm 、SparkStreaming 、Flink，计算框架越来越成熟。

⼀⽅⾯， 实时任务的开发已经能通过编写 SQL 的⽅式来完成，在技术层⾯能很好地继承离线数仓的架构设计 思想；

另⼀⽅⾯ ，在线数据开发平台所提供的功能对实时任务开发 、调试 、运维的⽀持也⽇渐趋于成熟， 开发成本逐 步降低，有助于去做这件事。

## 二、实时数仓建设目的

### 1.解决传统数仓的问题

从目前数仓建设的现状来看， 实时数仓是⼀个容易让⼈产生混淆的概念，根据传统经验分析，数仓有⼀个重要 的功能， 即能够记录历史 。通常，数仓都是希望从业务上线的第⼀天开始有数据，然后⼀直记录到现在。

但实时流处理技术， ⼜是强调当前处理状态的⼀个技术，结合当前⼀线大⼚的建设经验和滴滴在该领域的建设 现状，我们尝试把公司内实时数仓建设的目的定位为， 以数仓建设理论和实时技术，解决由于当前离线数仓数 据时效性低解决不了的问题。

现阶段我们要建设实时数仓的主要原因是：

公司业务对于数据的实时性越来越迫切， 需要有实时数据来辅助完成决策；

实时数据建设没有规范，数据可用性较差，⽆法形成数仓体系， 资源大量浪费；

数据平台⼯具对整体实时开发的⽀持也⽇渐趋于成熟， 开发成本降低。

### 2.实时数仓的应用场景

实时 OLAP 分析；

实时数据看板；

实时业务监控；

实时数据接⼝服务。

## 三、 实时数仓的过去现在和未来

1991年，比尔·恩门（Bill Inmon）出版了他的第一本关于数据仓库的书《Building the Data Warehouse》，标志着数据仓库概念的确立。

我们所常说的企业数据仓库Enterprise Data Warehouse (EDW) ，就是一个用于聚合不同来源的数据（比如事务系统、关系数据库和操作数据库），然后方便进行数据访问、分析和报告的系统（例如销售交易数据、移动应用数据和CRM数据），只要数据汇集到数仓中，整个企业都访问和使用，从而方便大家来全面的了解业务。我们的数据工程师和业务分析师可以将这些不同来源的相关数据应用于商业智能（BI）和人工智能（AI）等方面，以便带来更好的预测，并最终为我们作出更好的业务决策。

### 1.企业为什么需要实时数据仓库

传统意义上的数据仓库主要处理T+1数据，即今天产生的数据分析结果明天才能看到，T+1的概念来源于股票交易，是一种股票交易制度，即当日买进的股票要到下一个交易日才能卖出。

随着互联网以及很多行业线上业务的快速发展，让数据体量以前所未有的速度增长，数据时效性在企业运营中的重要性日益凸现，企业对海量数据的处理有了更高要求，如非结构化数据处理、快速批处理、实时数据处理、全量数据挖掘等。由于传统数据仓库侧重结构化数据，建模路径较长，面对大规模数据处理能力有限，企业急需提升大数据处理时效，以更经济的方式发掘数据价值。

数据的实时处理能力也成为企业提升竞争力的一大因素。

### 2.数据处理流程

在了解数仓如何实时处理之前，我们先来了解数据的分层。每个企业根据自己的业务需求可以分成不同的层次，但是最基础的分层思想，理论上数据分为三个层：贴源层（ODS)、数据仓库层（DW）、数据服务层(APP/DWA)。基于这个基础分层之上满足不同的业务需求。

- ODS：Operation Data Store，也称为贴源层。数据仓库源头系统的数据表通常会原封不动的存储一份，这称为ODS层，是后续数据仓库加工数据的来源。

- DW数据分层，由下到上一般分为DWD，DWB，DWS。

- - DWD：Data Warehouse Details 细节数据层，是业务层与数据仓库的隔离层。主要对ODS数据层做一些数据清洗(去除空值、脏数据、超过极限范)和规范化的操作。
  - DWB：Data Warehouse Base 数据基础层，存储的是客观数据，一般用作中间层，可以认为是大量指标的数据层。
  - DWS：Data Warehouse Service 数据服务层，基于DWB上的基础数据，主要是对用户行为进行轻度聚合，整合汇总成分析某一个主题域的服务数据层，一般是宽表。用于提供后续的业务查询，OLAP分析，数据分发等。

- 数据服务层/应用层(APP/DWA)：该层主要是提供数据产品和数据分析使用的数据，我们通过说的报表数据，或者说那种大宽表，一般就放在这里。



### 3.实时数仓的常见方案

当前，数据仓库被分为离线数仓和实时数仓，离线数仓一般是传统的T+1型数据ETL方案，而实时数仓一般是分钟级甚至是秒级ETL方案。并且，离线数仓和实时数仓的底层架构也不一样，离线数仓一般采用传统大数据架构模式搭建，而实时数仓则采用Lambda、Kappa等架构搭建。

### 4.LAMBDA & KAPPA 实时架构

目前，实时处理有两种典型的架构：Lambda 和 Kappa 架构。出于历史原因，这两种架构的产生和发展都具有一定局限性。

Lambda架构：在离线大数据架构的基础上增加新链路用于实时数据处理，需要维护离线处理和实时处理两套代码；

Lambda 架构通过把数据分解为服务层（Serving Layer）、速度层（Speed Layer，亦即流处理层）、批处理层（Batch Layer）三层来解决不同数据集的数据需求。在批处理层主要对离线数据进行处理，将接入的数据进行预处理和存储，查询直接在预处理结果上进行，不需再进行完整的计算，最后以批视图的形式提供给业务应用。

在实际生产环境中的部署通常可以参见下图，一般要通过一系列不同的存储和计算引擎 (HBase、Druid、Hive、Presto、Redis 等) 复杂协同才能满足业务的实时需求，此外多个存储之间需要通过数据同步任务保持大致的同步。Lambda 架构在实际落地过程中极其复杂，使整个业务的开发耗费了大量的时间。

​    ![图片](https://mmbiz.qpic.cn/mmbiz_png/D551c6SkFJ0eCvbX6HCRcBDBepFtUBNvRysj6abqNoFZiaqWhz5Yriafmj0kDqeaxuoMQaT36pDYkt9EnxsrfibRQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**缺点：**

(1) 由多个引擎和系统组合而成，批处理 (Batch)、流处理 (Streaming) 以及合并查询 (Merged Query) 的实现需要使用不同的开发语言，造成开发、维护和学习成本较高；

(2) 数据在不同的视图 (View) 中存储多份，浪费存储空间，数据一致性的问题难以解决。

Kappa架构：希望做到批流合一，离线处理和实时处理整合成一套代码，减小运维成本。Kappa 架构在 Lambda 架构的基础上移除了批处理层，利用流计算的分布式特征，加大流数据的时间窗口，统一批处理和流处理，处理后的数据可以直接给到业务层使用。因为在 Kappa 架构下，作业处理的是所有历史数据和当前数据，其产生的结果我们称之为实时批视图（Realtime_Batch_View）。

Kappa 架构的流处理系统通常使用 Spark Streaming 或者 Flink 等实现，服务层通常使用MySQL 或 HBase 等实现。

​    ![图片](https://mmbiz.qpic.cn/mmbiz_png/D551c6SkFJ0eCvbX6HCRcBDBepFtUBNv76jKW4hQszQ7qFX8L51U2KMA4chibejh41Zsg411GRq4qN1O1elRxVQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

Kappa 架构部署图

**缺点：**

(1) 依赖 Kafka 等消息队列来保存所有历史，而Kafka 难以实现数据的更新和纠错，发生故障或者升级时需要重做所有历史，周期较长；

(2) Kappa 依然是针对不可变更数据，无法实时汇集多个可变数据源形成的数据集快照，不适合即席查询。

因为上述的缺点，Kappa架构在现实中很少被应用。

### 5.湖仓一体能否解决实时问题？

时下热门的湖仓一体能否解决实时问题呢？湖仓一体有何标准？Gartner 认为湖仓一体是将数据湖的灵活性和数仓的易用性、规范性、高性能结合起来的融合架构，无数据孤岛。

作为数据湖和数据仓库的完美结合，新一代的湖仓一体架构重点关注和解决了近年来数字化转型带来的业务需求和技术难点，具体包括如下以下方面：

1. 实时性成为了提升企业竞争力的核心手段。目前的湖、仓、或者湖仓分体都是基于 T+1 设计的，面对 T+0 的实时按需分析，用户的需求无法满足。
2. 所有用户（BI 用户、数据科学家等）可以共享同一份数据，避免数据孤岛。
3. 超高并发能力，支持数十万用户使用复杂分析查询并发访问同一份数据。
4. 传统 Hadoop 在事务支持等方面的不足被大家诟病，在高速发展之后未能延续热度，持续引领数据管理，因此事务支持在湖仓一体架构中应得到改善和提升。
5. 云原生数据库已经逐渐成熟，基于存算分离技术，可以给用户带来多种价值：降低技术门槛、减少维护成本、提升用户体验、节省资源费用，已成为了湖仓一体落地的重要法门。
6. 为释放数据价值提升企业智能化水平，数据科学家等用户角色必须通过多种类型数据进行全域数据挖掘，包括但不限于历史的、实时的、在线的、离线的、内部的、外部的、结构化的、非结构化数据。

### 6.云原生数据仓库 + Omega实时架构 实现实时湖仓

**云原生数据库实现完全的存算分离**

云原生数据库如 OushuDB 和 Snowflake 突破了传统 MPP 和 Hadoop 的局限性，实现了存算完全分离，计算和存储可部署在不同物理集群，并通过虚拟计算集群技术实现了高并发，同时保障事务支持，成为湖仓一体实现的关键技术。

以 OushuDB 为例，实现了存算分离的云原生架构，并通过虚拟计算集群技术在数十万节点的超大规模集群上实现了高并发，保障事务支持，提供实时能力，一份数据再无数据孤岛。

**基于Omega实时框架的湖仓方案**

我们前面提到，既然 Kappa 架构实际落地困难，Lambda 架构又很难保障数据的一致性，两个架构又都很难处理可变更数据（如关系数据库中不停变化的实时数据），那么自然需要一种新的架构满足企业实时分析的全部需求，这就是 Omega 全实时架构，Omega 架构由偶数科技根据其在各行业的实践提出，同时满足实时流处理、实时按需分析和离线分析。

Omega 架构由流数据处理系统和实时数仓构成。相比 Lambda 和 Kappa，Omega 架构新引入了实时数仓和快照视图 (Snapshot View) 的概念，快照视图是归集了可变更数据源和不可变更数据源后形成的 T+0 实时快照，可以理解为所有数据源在实时数仓中的镜像和历史，随着源库的变化实时变化。

因此，实时查询可以通过存储于实时数仓的快照视图得以实现。实时快照提供的场景可以分为两大类：一类是多个源库汇集后的跨库查询，比如一个保险用户的权益视图；另一类是任意时间粒度的分析查询，比如最近 5 分钟的交易量、最近 10 分钟的信用卡开卡量等等。

另外，任意时间点的历史数据都可以通过 T+0 快照得到（为了节省存储，T+0 快照可以拉链形式存储在实时数仓 ODS 中，所以快照视图可以理解为实时拉链），这样离线查询可以在实时数仓中完成，离线查询结果可以包含最新的实时数据，完全不再需要通过传统MPP+Hadoop湖仓分体组合来处理离线跑批及分析查询。

​        ![图片](https://mmbiz.qpic.cn/mmbiz_png/D551c6SkFJ0eCvbX6HCRcBDBepFtUBNvIDibUcqkzEgibnoQmicFIYD1icLa8L51Rps5CPibAD1SUtzoeKjQU6rCyLQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)Omega 架构逻辑图

流处理系统既可以实现实时连续的流处理，也可以实现 Kappa 架构中的批流一体，但与Kappa 架构不同的是，OushuDB 实时数仓存储来自 Kafka 的全部历史数据（详见下图），而在 Kappa 架构中源端采集后通常存储在 Kafka 中。

​        ![图片](https://mmbiz.qpic.cn/mmbiz_png/D551c6SkFJ0eCvbX6HCRcBDBepFtUBNvGfUhM7QvDhfCR6Dw1ClHyH4SES0B1ddkDeEHibPn76sQ5wSpoYaBEDQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

Omega 架构部署图

因此，当需要流处理版本变更的时候，流处理引擎不再需要访问 Kafka，而是访问实时数仓 OushuDB 获得所有历史数据，规避了 Kafka 难以实现数据更新和纠错的问题，大幅提高效率。此外，整个服务层也可以在实时数仓中实现，而无需额外引入 MySQL、HBase 等组件，极大简化了数据架构，实现了湖仓市一体（数据湖、数仓、集市一体）。实现了全实时 Omega 架构的湖仓一体，我们也称之为实时湖仓一体。

​        ![图片](https://mmbiz.qpic.cn/mmbiz_png/D551c6SkFJ0eCvbX6HCRcBDBepFtUBNvFRibcREm3MptuNDBAibetdAibiaVH91h69VEXcQdlRFkJZ3DGQoqPbZOyQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

Omega vs. Lambda vs. Kappa

### **结语：**

面对复杂多变的新业务场景，随着数据技术不断成熟，新的实时技术栈会出现，数据技术也会经历分离与融合。目前，融合的趋势比较明显，如实时湖仓一体，将实时处理能力融入数据仓库中。不论企业如何选型实时数仓，数据平台技术栈的建设一般都应该遵循三条基本原则：

1. 架构层面要保持灵活开放，支持多种技术兼容性并存。目前，企业已经部署了多个系统，有自己的一套架构体系，技术融合落地时需要最大化利用企业原有IT资产，保护客户投资。
2. 有效利用资源，降本增效。原来传统的技术栈，所有资源参与计算，造成IT资源浪费。比如，云原生资源池化，可以实现资源隔离与动态管理，便于最大化利用资源。
3. 满足更高的用户体验。从用户角度来看，在技术条件具备的前提下，比如高性能、高并发、实时性更强，便具备了更强的信息加工能力，能够在很短的时间内满足用户各种各样的数据服务需求，提升用户体验。



随着实时分析场景日益增多，实时数仓等具备实时处理能力的产品与解决方案将会得到更广泛的应用。

## 四、实时数仓建设方案

一、实时技术及架构
二、业务痛点
三、数据特点与应用场景
四、实时数仓架构设计
五、基于Flink的实时数仓应用案例

**正文开始：**

### 一、实时技术及架构

#### 1. 实时计算技术选型

目前，市面上已经开源的实时技术还是很多的，比较通用的有Storm、Spark Streaming以及Flink，技术同学在做选型时要根据公司的具体业务来进行部署。

美团外卖依托于美团整体的基础数据体系建设，从技术成熟度来讲，公司前几年主要用的是Storm。当时的Storm，在性能稳定性、可靠性以及扩展性上也是无可替代的。但随着Flink越来越成熟，从技术性能上以及框架设计优势上已经超越了Storm，从趋势来讲就像Spark替代MR一样，Storm也会慢慢被Flink替代。当然，从Storm迁移到Flink会有一个过程，我们目前有一些老的任务仍然运行在Storm上，也在不断推进任务迁移。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazHaGgVYN6a8Zclictic7QLazMicrQ9CNuA4yc80SCD9N9HZbWNNEcyDnvw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

具体Storm和Flink的对比可以参考上图表格。

#### 2. 实时架构

**① Lambda架构**

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazhCdLic0brVscgDkfeJzjo5yI1zUick9NdYKicLd8kDImfoVaJPSAem4FA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

Lambda是比较经典的一款架构，以前实时的场景不是很多，以离线为主，当附加了实时场景后，由于离线和实时的时效性不同，导致技术生态是不一样的。而Lambda架构相当于附加了一条实时生产链路，在应用层面进行一个整合，双路生产，各自独立。在业务应用中，顺理成章成为了一种被采用的方式。

双路生产会存在一些问题，比如加工逻辑Double，开发运维也会Double，资源同样会变成两个资源链路。因为存在以上问题，所以又演进了一个Kappa架构。

**② Kappa架构**

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazAE8Wib2lCroHtRtWbFxEiaI2OYcywhm4oZlJjjTNHYHsDI0aP22eFJQA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

Kappa从架构设计来讲，比较简单，生产统一，一套逻辑同时生产离线和实时。但是在实际应用场景有比较大的局限性，在业内直接用Kappa架构生产落地的案例不多见，且场景比较单一。这些问题在美团外卖这边同样会遇到，我们也会有自己的一些思考，将会在后面的章节进行阐述。

### 二、业务痛点

首先，在外卖业务上，我们遇到了一些问题和挑战。在业务早期，为了满足业务需要，一般是Case By Case地先把需求完成。业务对于实时性要求是比较高的，从时效性的维度来说，没有进行中间层沉淀的机会。在这种场景下，一般是拿到业务逻辑直接嵌入，这是能想到的简单有效的方法，在业务发展初期这种开发模式也比较常见。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazoJOnIs3qr64nXveR18zcIwpXhPw0FF90UnfVAqVv4VOyibib88eN9WAw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

如上图所示，拿到数据源后，我们会经过数据清洗、扩维，通过Storm或Flink进行业务逻辑处理，最后直接进行业务输出。把这个环节拆开来看，数据源端会重复引用相同的数据源，后面进行清洗、过滤、扩维等操作，都要重复做一遍。唯一不同的是业务的代码逻辑是不一样的，如果业务较少，这种模式还可以接受，但当后续业务量上去后，会出现谁开发谁运维的情况，维护工作量会越来越大，作业无法形成统一管理。而且所有人都在申请资源，导致资源成本急速膨胀，资源不能集约有效利用，因此要思考如何从整体来进行实时数据的建设。

### 三、数据特点与应用场景

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazZNuHkIIDhmLDVrjYuOP4MMwfhPoOVUXAiaQND0lfyLlK3WVMp7X4SeA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

那么如何来构建实时数仓呢？首先要进行拆解，有哪些数据，有哪些场景，这些场景有哪些共同特点，对于外卖场景来说一共有两大类，日志类和业务类。

- **日志类**：数据量特别大，半结构化，嵌套比较深。日志类的数据有个很大的特点，日志流一旦形成是不会变的，通过埋点的方式收集平台所有的日志，统一进行采集分发，就像一颗树，树根非常大，推到前端应用的时候，相当于从树根到树枝分叉的过程（从1到n的分解过程）。如果所有的业务都从根上找数据，看起来路径最短，但包袱太重，数据检索效率低。日志类数据一般用于生产监控和用户行为分析，时效性要求比较高，时间窗口一般是5min或10min，或截止到当前的一个状态，主要的应用是实时大屏和实时特征，例如用户每一次点击行为都能够立刻感知到等需求。
- **业务类**：主要是业务交易数据，业务系统一般是自成体系的，以Binlog日志的形式往下分发，业务系统都是事务型的，主要采用范式建模方式。特点是结构化，主体非常清晰，但数据表较多，需要多表关联才能表达完整业务，因此是一个n到1的集成加工过程。

而业务类实时处理，主要面临的以下几个难点：

- **业务的多状态性**：业务过程从开始到结束是不断变化的，比如从下单->支付->配送，业务库是在原始基础上进行变更的，Binlog会产生很多变化的日志。而业务分析更加关注最终状态，由此产生数据回撤计算的问题，例如10点下单，13点取消，但希望在10点减掉取消单。
- **业务集成**：业务分析数据一般无法通过单一主体表达，往往是很多表进行关联，才能得到想要的信息，在实时流中进行数据的合流对齐，往往需要较大的缓存处理且复杂。
- **分析是批量的，处理过程是流式的**：对单一数据，无法形成分析，因此分析对象一定是批量的，而数据加工是逐条的。

日志类和业务类的场景一般是同时存在的，交织在一起，无论是Lambda架构还是Kappa架构，单一的应用都会有一些问题。因此针对场景来选择架构与实践才更有意义。

### 四、实时数仓架构设计

#### 1. 实时架构：流批结合的探索

基于以上问题，我们有自己的思考。通过流批结合的方式来应对不同的业务场景。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazJHicz8E9Ngibxz4VsPX7agNW4iaQfXe4d77RgwK2SaxwpMsiaQI8VZ45Lg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

如上图所示，数据从日志统一采集到消息队列，再到数据流的ETL过程，作为基础数据流的建设是统一的。之后对于日志类实时特征，实时大屏类应用走实时流计算。对于Binlog类业务分析走实时OLAP批处理。

流式处理分析业务的痛点是什么？对于范式业务，Storm和Flink都需要很大的外存，来实现数据流之间的业务对齐，需要大量的计算资源。且由于外存的限制，必须进行窗口的限定策略，最终可能放弃一些数据。计算之后，一般是存到Redis里做查询支撑，且KV存储在应对分析类查询场景中也有较多局限。

实时OLAP怎么实现？有没有一种自带存储的实时计算引擎，当实时数据来了之后，可以灵活的在一定范围内自由计算，并且有一定的数据承载能力，同时支持分析查询响应呢？随着技术的发展，目前MPP引擎发展非常迅速，性能也在飞快提升，所以在这种场景下就有了一种新的可能。这里我们使用的是Doris引擎。

这种想法在业内也已经有实践，且成为一个重要探索方向。阿里基于ADB的实时OLAP方案等。

#### 2. 实时数仓架构设计

从整个实时数仓架构来看，首先考虑的是如何管理所有的实时数据，资源如何有效整合，数据如何进行建设。

从方法论来讲，实时和离线是非常相似的。离线数仓早期的时候也是Case By Case，当数据规模涨到一定量的时候才会考虑如何治理。分层是一种非常有效的数据治理方式，所以在实时数仓如何进行管理的问题上，首先考虑的也是分层的处理逻辑，具体内容如下：

- **数据源**：在数据源的层面，离线和实时在数据源是一致的，主要分为日志类和业务类，日志类又包括用户日志、DB日志以及服务器日志等。
- **实时明细层**：在明细层，为了解决重复建设的问题，要进行统一构建，利用离线数仓的模式，建设统一的基础明细数据层，按照主题进行管理，明细层的目的是给下游提供直接可用的数据，因此要对基础层进行统一的加工，比如清洗、过滤、扩维等。
- **汇总层**：汇总层通过Flink或Storm的简洁算子直接可以算出结果，并且形成汇总指标池，所有的指标都统一在汇总层加工，所有人按照统一的规范管理建设，形成可复用的汇总结果。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazXFJicedtFgiboWUttofkvrMH0PTXMQVxRt1dKFKxJvI6DzMv9n705Z1Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

总结起来，从整个实时数仓的建设角度来讲，首先数据建设的层次化要先建出来，先搭框架，然后定规范，每一层加工到什么程度，每一层用什么样的方式，当规范定义出来后，便于在生产上进行标准化的加工。由于要保证时效性，设计的时候，层次不能太多，对于实时性要求比较高的场景，基本可以走上图左侧的数据流，对于批量处理的需求，可以从实时明细层导入到实时OLAP引擎里，基于OLAP引擎自身的计算和查询能力进行快速的回撤计算，如上图右侧的数据流。

#### 3. 实时OLAP方案

**问题**

- **Binlog业务还原复杂**：业务变化很多，需要某个时间点的变化，因此需要进行排序，并且数据要存起来，这对于内存和CPU的资源消耗都是非常大的。
- **Binlog业务关联复杂**：流式计算里，流和流之间的关联，对于业务逻辑的表达是非常困难的。

**解决方案**

通过带计算能力的OLAP引擎来解决，不需要把一个流进行逻辑化映射，只需要解决数据实时稳定的入库问题。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazBgkOzSrRuVxGIBcfFTVO5AUhbxkEFdPhRicgiaPYU9FO5e4icWHKfttWg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

我们这边采用的是Doris作为高性能的OLAP引擎，由于业务数据产生的结果和结果之间还需要进行衍生计算，Doris可以利用Unique模型或聚合模型快速还原业务，还原业务的同时还可以进行汇总层的聚合，也是为了复用而设计。应用层可以是物理的，也可以是逻辑化视图。

这种模式重在解决业务回撤计算，比如业务状态改变，需要在历史的某个点将值变更，这种场景用流计算的成本非常大，OLAP模式可以很好的解决这个问题。

### 五、基于Flink的实时数仓应用案例

#### 1. 实时平台初期架构

在实时数据系统建设初期，由于对实时数据的需求较少，形成不了完整的数据体系。我们采用的是“一路到底”的开发模式：通过在实时计算平台上部署 Storm 作业处理实时数据队列来提取数据指标，直接推送到实时应用服务中。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazxa7MBYOLuCaialG4pxvicsCrgC4Yrqayibiad1YBU6zz1C5Lr2m21MOoNQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)图1 初期实时数据架构

但是，随着产品和业务人员对实时数据需求的不断增多，新的挑战也随之发生。

1. 数据指标越来越多，“烟囱式”的开发导致代码耦合问题严重。
2. 需求越来越多，有的需要明细数据，有的需要 OLAP 分析。单一的开发模式难以应付多种需求。
3. 缺少完善的监控系统，无法在对业务产生影响之前发现并修复问题。

#### 2. 实时数据仓库的构建

为解决以上问题，我们根据生产离线数据的经验，选择使用分层设计方案来建设实时数据仓库，其分层架构如下图所示：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazsiauUZWPpRTQ4MfgdrpJ69Uuufs6BeaVrjQf56B9QbH9WYQad75bGhA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)图2 实时数仓数据分层架构

该方案由以下四层构成：

1. ODS 层：Binlog 和流量日志以及各业务实时队列。
2. 数据明细层：业务领域整合提取事实数据，离线全量和实时变化数据构建实时维度数据。
3. 数据汇总层：使用宽表模型对明细数据补充维度数据，对共性指标进行汇总。
4. App 层：为了具体需求而构建的应用层，通过 RPC 框架对外提供服务。

通过多层设计我们可以将处理数据的流程沉淀在各层完成。比如在数据明细层统一完成数据的过滤、清洗、规范、脱敏流程；在数据汇总层加工共性的多维指标汇总数据。提高了代码的复用率和整体生产效率。同时各层级处理的任务类型相似，可以采用统一的技术方案优化性能，使数仓技术架构更简洁。

#### 3. 技术选型

##### 1) 存储引擎的调研

实时数仓在设计中不同于离线数仓在各层级使用同种储存方案，比如都存储在 Hive 、DB 中的策略。首先对中间过程的表，采用将结构化的数据通过消息队列存储和高速 KV 存储混合的方案。实时计算引擎可以通过监听消息消费消息队列内的数据，进行实时计算。而在高速 KV 存储上的数据则可以用于快速关联计算，比如维度数据。其次在应用层上，针对数据使用特点配置存储方案直接写入。避免了离线数仓应用层同步数据流程带来的处理延迟。为了解决不同类型的实时数据需求，合理的设计各层级存储方案，我们调研了美团内部使用比较广泛的几种存储方案。存储方案列表如下：

| 方案          | 优势                                                         | 劣势                                                         |
| :------------ | :----------------------------------------------------------- | :----------------------------------------------------------- |
| MySQL         | 1. 具有完备的事务功能，可以对数据进行更新。2. 支持 SQL，开发成本低。 | 1. 横向扩展成本大，存储容易成为瓶颈；2. 实时数据的更新和查询频率都很高，线上单个实时应用请求就有 1000+ QPS；使用 MySQL 成本太高。 |
| Elasticsearch | 1. 吞吐量大，单个机器可以支持 2500+ QPS，并且集群可以快速横向扩展。2. Term 查询时响应速度很快，单个机器在 2000+ QPS时，查询延迟在 20 ms以内。 | 1. 没有原生的 SQL 支持，查询 DSL 有一定的学习门槛；2. 进行聚合运算时性能下降明显。 |
| Druid         | 1. 支持超大数据量，通过 Kafka 获取实时数据时，单个作业可支持 6W+ QPS；2. 可以在数据导入时通过预计算对数据进行汇总，减少的数据存储。提高了实际处理数据的效率；3. 有很多开源 OLAP 分析框架。实现如 Superset。 | 1. 预聚合导致无法支持明细的查询；2. 无法支持 Join 操作；3. Append-only 不支持数据的修改。只能以 Segment 为单位进行替换。 |
| Cellar        | 1. 支持超大数据量，采用内存加分布式存储的架构，存储性价比很高；2. 吞吐性能好，经测试处理 3W+ QPS 读写请求时，平均延迟在 1ms左右；通过异步读写线上最高支持 10W+ QPS。 | 1. 接口仅支持 KV，Map，List 以及原子加减等；2. 单个 Key 值不得超过 1KB ，而 Value 的值超过 100KB 时则性能下降明显。 |

根据不同业务场景，实时数仓各个模型层次使用的存储方案大致如下：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazpWncTs2MhXZEAfDdViavc6s3JSO7MBWdpVW2654hxznHSK4iaBVZgqxA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)图3 实时数仓存储分层架构

1. 数据明细层 对于维度数据部分场景下关联的频率可达 10w+ TPS，我们选择 Cellar（美团内部存储系统） 作为存储，封装维度服务为实时数仓提供维度数据。
2. 数据汇总层 对于通用的汇总指标，需要进行历史数据关联的数据，采用和维度数据一样的方案通过 Cellar 作为存储，用服务的方式进行关联操作。
3. 数据应用层 应用层设计相对复杂，再对比了几种不同存储方案后。我们制定了以数据读写频率 1000 QPS 为分界的判断依据。对于读写平均频率高于 1000 QPS 但查询不太复杂的实时应用，比如商户实时的经营数据。采用 Cellar 为存储，提供实时数据服务。对于一些查询复杂的和需要明细列表的应用，使用 Elasticsearch 作为存储则更为合适。而一些查询频率低，比如一些内部运营的数据。Druid 通过实时处理消息构建索引，并通过预聚合可以快速的提供实时数据 OLAP 分析功能。对于一些历史版本的数据产品进行实时化改造时，也可以使用 MySQL 存储便于产品迭代。

##### 2) 计算引擎的调研

在实时平台建设初期我们使用 Storm 引擎来进行实时数据处理。Storm 引擎虽然在灵活性和性能上都表现不错。但是由于 API 过于底层，在数据开发过程中需要对一些常用的数据操作进行功能实现。比如表关联、聚合等，产生了很多额外的开发工作，不仅引入了很多外部依赖比如缓存，而且实际使用时性能也不是很理想。同时 Storm 内的数据对象 Tuple 支持的功能也很简单，通常需要将其转换为 Java 对象来处理。对于这种基于代码定义的数据模型，通常我们只能通过文档来进行维护。不仅需要额外的维护工作，同时在增改字段时也很麻烦。综合来看使用 Storm 引擎构建实时数仓难度较大。我们需要一个新的实时处理方案，要能够实现：

1. 提供高级 API，支持常见的数据操作比如关联聚合，最好是能支持 SQL。
2. 具有状态管理和自动支持久化方案，减少对存储的依赖。
3. 便于接入元数据服务，避免通过代码管理数据结构。
4. 处理性能至少要和 Storm 一致。

我们对主要的实时计算引擎进行了技术调研。总结了各类引擎特性如下表所示：实时计算方案列表如下：

| 项目/引擎 | Storm                                       | Flink                                                        | spark-treaming                                               |
| :-------: | :------------------------------------------ | :----------------------------------------------------------- | :----------------------------------------------------------- |
|    API    | 灵活的底层 API 和具有事务保证的 Trident API | 流 API 和更加适合数据开发的 Table API 和 Flink SQL 支持      | 流 API 和 Structured-Streaming API 同时也可以使用更适合数据开发的 Spark SQL |
| 容错机制  | ACK 机制                                    | State 分布式快照保存点                                       | RDD 保存点                                                   |
| 状态管理  | Trident State状态管理                       | Key State 和 Operator State两种 State 可以使用，支持多种持久化方案 | 有 UpdateStateByKey 等 API 进行带状态的变更，支持多种持久化方案 |
| 处理模式  | 单条流式处理                                | 单条流式处理                                                 | Mic batch处理                                                |
|   延迟    | 毫秒级                                      | 毫秒级                                                       | 秒级                                                         |
| 语义保障  | At Least Once，Exactly Once                 | Exactly Once，At Least Once                                  | At Least Once                                                |

从调研结果来看，Flink 和 Spark Streaming 的 API 、容错机制与状态持久化机制都可以解决一部分我们目前使用 Storm 中遇到的问题。但 Flink 在数据延迟上和 Storm 更接近，对现有应用影响最小。而且在公司内部的测试中 Flink 的吞吐性能对比 Storm 有十倍左右提升。综合考量我们选定 Flink 引擎作为实时数仓的开发引擎。更加引起我们注意的是，Flink 的 Table 抽象和 SQL 支持。虽然使用 Strom 引擎也可以处理结构化数据。但毕竟依旧是基于消息的处理 API ，在代码层层面上不能完全享受操作结构化数据的便利。而 Flink 不仅支持了大量常用的 SQL 语句，基本覆盖了我们的开发场景。而且 Flink 的 Table 可以通过 TableSchema 进行管理，支持丰富的数据类型和数据结构以及数据源。可以很容易的和现有的元数据管理系统或配置管理系统结合。通过下图我们可以清晰的看出 Storm 和 Flink 在开发统过程中的区别。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazdPxklbg5XstnYNhNeNfyKl5xm9XjXsux2cCp3Ukea90HTAcWC85NkA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)图4 Flink - Storm 对比图

在使用 Storm 开发时处理逻辑与实现需要固化在 Bolt 的代码。Flink 则可以通过 SQL 进行开发，代码可读性更高，逻辑的实现由开源框架来保证可靠高效，对特定场景的优化只要修改 Flink SQL 优化器功能实现即可，而不影响逻辑代码。使我们可以把更多的精力放到到数据开发中，而不是逻辑的实现。当需要离线数据和实时数据口径统一的场景时，我们只需对离线口径的 SQL 脚本稍加改造即可，极大地提高了开发效率。同时对比图中 Flink 和 Storm 使用的数据模型，Storm 需要通过一个 Java 的 Class 去定义数据结构，Flink Table 则可以通过元数据来定义。可以很好的和数据开发中的元数据，数据治理等系统结合，提高开发效率。

#### 4. Flink使用心得

在利用 Flink-Table 构建实时数据仓库过程中。我们针对一些构建数据仓库的常用操作，比如数据指标的维度扩充，数据按主题关联，以及数据的聚合运算通过 Flink 来实现总结了一些使用心得。

##### 1) 维度扩充

数据指标的维度扩充，我们采用的是通过维度服务获取维度信息。虽然基于 Cellar 的维度服务通常的响应延迟可以在 1ms 以下。但是为了进一步优化 Flink 的吞吐，我们对维度数据的关联全部采用了异步接口访问的方式，避免了使用 RPC 调用影响数据吞吐。对于一些数据量很大的流，比如流量日志数据量在 10W 条/秒这个量级。在关联 UDF 的时候内置了缓存机制，可以根据命中率和时间对缓存进行淘汰，配合用关联的 Key 值进行分区，显著减少了对外部服务的请求次数，有效的减少了处理延迟和对外部系统的压力。

##### 2) 数据关联

数据主题合并，本质上就是多个数据源的关联，简单的来说就是 Join 操作。Flink 的 Table 是建立在无限流这个概念上的。在进行 Join 操作时并不能像离线数据一样对两个完整的表进行关联。采用的是在窗口时间内对数据进行关联的方案，相当于从两个数据流中各自截取一段时间的数据进行 Join 操作。有点类似于离线数据通过限制分区来进行关联。同时需要注意 Flink 关联表时必须有至少一个“等于”关联条件，因为等号两边的值会用来分组。由于 Flink 会缓存窗口内的全部数据来进行关联，缓存的数据量和关联的窗口大小成正比。因此 Flink 的关联查询，更适合处理一些可以通过业务规则限制关联数据时间范围的场景。比如关联下单用户购买之前 30 分钟内的浏览日志。过大的窗口不仅会消耗更多的内存，同时会产生更大的 Checkpoint ，导致吞吐下降或 Checkpoint 超时。在实际生产中可以使用 RocksDB 和启用增量保存点模式，减少 Checkpoint 过程对吞吐产生影响。对于一些需要关联窗口期很长的场景，比如关联的数据可能是几天以前的数据。对于这些历史数据，我们可以将其理解为是一种已经固定不变的”维度”。可以将需要被关联的历史数据采用和维度数据一致的处理方法：”缓存 + 离线”数据方式存储，用接口的方式进行关联。另外需要注意 Flink 对多表关联是直接顺序链接的，因此需要注意先进行结果集小的关联。

##### 3) 聚合运算

使用聚合运算时，Flink 对常见的聚合运算如求和、极值、均值等都有支持。美中不足的是对于 Distinct 的支持，Flink-1.6 之前的采用的方案是通过先对去重字段进行分组再聚合实现。对于需要对多个字段去重聚合的场景，只能分别计算再进行关联处理效率很低。为此我们开发了自定义的 UDAF，实现了 MapView 精确去重、BloomFilter 非精确去重、 HyperLogLog 超低内存去重方案应对各种实时去重场景。但是在使用自定义的 UDAF 时，需要注意 RocksDBStateBackend 模式对于较大的 Key 进行更新操作时序列化和反序列化耗时很多。可以考虑使用 FsStateBackend 模式替代。另外要注意的一点 Flink 框架在计算比如 Rank 这样的分析函数时，需要缓存每个分组窗口下的全部数据才能进行排序，会消耗大量内存。建议在这种场景下优先转换为 TopN 的逻辑，看是否可以解决需求。下图展示一个完整的使用 Flink 引擎生产一张实时数据表的过程：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zFk0ibZxzglN09IBR9a86biazFxWeOMB1m3OW25qPPgqtM7vAjOHtAlm8GgTt17Jy7hqoiaiaZl4icPOicg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)图5 实时计算流程图

#### 5. 实时数仓成果

通过使用实时数仓代替原有流程，我们将数据生产中的各个流程抽象到实时数仓的各层当中。实现了全部实时数据应用的数据源统一，保证了应用数据指标、维度的口径的一致。在几次数据口径发生修改的场景中，我们通过对仓库明细和汇总进行改造，在完全不用修改应用代码的情况下就完成全部应用的口径切换。在开发过程中通过严格的把控数据分层、主题域划分、内容组织标准规范和命名规则。使数据开发的链路更为清晰，减少了代码的耦合。再配合上使用 Flink SQL 进行开发，代码加简洁。单个作业的代码量从平均 300+ 行的 JAVA 代码 ，缩减到几十行的 SQL 脚本。项目的开发时长也大幅减短，一人日开发多个实时数据指标情况也不少见。除此以外我们通过针对数仓各层级工作内容的不同特点，可以进行针对性的性能优化和参数配置。比如 ODS 层主要进行数据的解析、过滤等操作，不需要 RPC 调用和聚合运算。我们针对数据解析过程进行优化，减少不必要的 JSON 字段解析，并使用更高效的 JSON 包。在资源分配上，单个 CPU 只配置 1GB 的内存即可满需求。而汇总层主要则主要进行聚合与关联运算，可以通过优化聚合算法、内外存共同运算来提高性能、减少成本。资源配置上也会分配更多的内存，避免内存溢出。通过这些优化手段，虽然相比原有流程实时数仓的生产链路更长，但数据延迟并没有明显增加。同时实时数据应用所使用的计算资源也有明显减少。

#### 6. 展望

我们的目标是将实时仓库建设成可以和离线仓库数据准确性，一致性媲美的数据系统。为商家，业务人员以及美团用户提供及时可靠的数据服务。同时作为到餐实时数据的统一出口，为集团其他业务部门助力。未来我们将更加关注在数据可靠性和实时数据指标管理。建立完善的数据监控，数据血缘检测，交叉检查机制。及时对异常数据或数据延迟进行监控和预警。同时优化开发流程，降低开发实时数据学习成本。让更多有实时数据需求的人，可以自己动手解决问题
